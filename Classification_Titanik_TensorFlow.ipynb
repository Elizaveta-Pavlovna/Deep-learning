{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b771b5bd-1b67-418b-b7b4-8175339d6d17"
      },
      "source": [
        "# Лабораторная работа. Антоненко Елизавета. ИТМО"
      ],
      "id": "b771b5bd-1b67-418b-b7b4-8175339d6d17"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9f0f099-9236-41e6-a985-69758dbae2dd"
      },
      "source": [
        "# Описание набора данных\n",
        "В данной работе целью исследования будет набор данных Titanic. Данный набор содержит информацию о различных пассажирах корабля \"Титаник\", затонувшего в ночь на 15-е апреля 1912 года. Некоторое количество пассажиров спаслось, чему способствовало множество различных факторов, включая их пол, возраст, на какой палубе находилась их кабина, социальный статус, и т.д. Мы предлагаем вам натренировать нейронную сеть для бинарной классификации, способную предсказывать вероятность спасения человека на основе его данных.  \n",
        "\n",
        "Набор данных состоит из различных признаков, описывающих информацию о пассажирах. Каждая строка таблицы - отдельный пассажир, вся информация о нем содержится в его строке. В столбце survived находится бинарная метка (0 или 1), означающая, спасся ли человек с корабля (1) или нет (0). Вашей задачей является изучить набор данных, корректно определить решаемую задачу, а затем построить модель, которая будет способна предсказывать вероятность спасения и посчитать F1-метрику на тестовом наборе данных."
      ],
      "id": "f9f0f099-9236-41e6-a985-69758dbae2dd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50f63729"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "id": "50f63729"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e1a6d18-31e6-41f0-9e12-019c41fe828c"
      },
      "outputs": [],
      "source": [
        "(ds_train_tf, ds_test_tf), ds_info = tfds.load(\n",
        "    name='titanic',\n",
        "    split=['train[:90%]', 'train[90%:]'],\n",
        "    #as_supervised=True,\n",
        "    with_info=True\n",
        ")"
      ],
      "id": "0e1a6d18-31e6-41f0-9e12-019c41fe828c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUCQ0Z08_DoO",
        "outputId": "7bff1b12-c89b-4013-ee98-b4514e00ff2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1178"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ],
      "source": [
        "len(ds_train_tf)"
      ],
      "id": "NUCQ0Z08_DoO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ff561ff-9506-41c1-bf34-159eb302d97e"
      },
      "source": [
        "По умолчанию библиотека загружает данные в формате TensorFlow Dataset. Этот формат позволяет оперировать данными на жестком диске без предварительной загрузки их в память, что позволят обучать модели на данных, превышающих размер оперативной памяти вашего устройства.\n",
        "\n",
        "Набор данных Titanic является достаточно небольшим набором и мы уверены, что оперативной памяти вашего устройства хватит для хранения его целиком, поэтому это в данный момент не играет решающей роли. Однако, вам будет полезно научиться работать с ним.\n",
        "\n",
        "Примеры использования и различных функций этого формата данных вы можете найти в документации или Jupyter Notebook'е данного курса, описывающем работу с библиотекой Keras."
      ],
      "id": "0ff561ff-9506-41c1-bf34-159eb302d97e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "710905d4-a25f-42d4-94a2-6d75369ad559"
      },
      "source": [
        "Давайте выведем первую строку тренировочного набора данных для ознакомления."
      ],
      "id": "710905d4-a25f-42d4-94a2-6d75369ad559"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "n0jEeLlX4GJ_",
        "outputId": "1f19b781-bfed-4dac-c486-85db106da50d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    age        boat  body       cabin  embarked     fare  \\\n",
              "0  30.0  b'Unknown'    -1  b'Unknown'         2  13.0000   \n",
              "1  37.0  b'Unknown'    98  b'Unknown'         2   7.9250   \n",
              "2  28.0        b'9'    -1  b'Unknown'         2  13.0000   \n",
              "3  18.0  b'Unknown'    -1  b'Unknown'         2  73.5000   \n",
              "4  -1.0  b'Unknown'    -1  b'Unknown'         0   7.8958   \n",
              "\n",
              "                                home.dest                               name  \\\n",
              "0                           b'Sarnia, ON'       b'McCrie, Mr. James Matthew'   \n",
              "1  b'Ruotsinphytaa, Finland New York, NY'  b'Gustafsson, Mr. Anders Vilhelm'   \n",
              "2                                b'Spain'       b'Reynaldo, Ms. Encarnacion'   \n",
              "3                   b'Lyndhurst, England'       b'Davies, Mr. Charles Henry'   \n",
              "4                              b'Unknown'          b'Gheorgheff, Mr. Stanio'   \n",
              "\n",
              "   parch  pclass  sex  sibsp  survived           ticket  \n",
              "0      0       1    0      0         0        b'233478'  \n",
              "1      0       2    0      2         0       b'3101276'  \n",
              "2      0       1    1      0         1        b'230434'  \n",
              "3      0       1    0      0         0  b'S.O.C. 14879'  \n",
              "4      0       2    0      0         0        b'349254'  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-000a0bf5-2040-46a9-b173-84602cf44b5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>boat</th>\n",
              "      <th>body</th>\n",
              "      <th>cabin</th>\n",
              "      <th>embarked</th>\n",
              "      <th>fare</th>\n",
              "      <th>home.dest</th>\n",
              "      <th>name</th>\n",
              "      <th>parch</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>survived</th>\n",
              "      <th>ticket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30.0</td>\n",
              "      <td>b'Unknown'</td>\n",
              "      <td>-1</td>\n",
              "      <td>b'Unknown'</td>\n",
              "      <td>2</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>b'Sarnia, ON'</td>\n",
              "      <td>b'McCrie, Mr. James Matthew'</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>b'233478'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37.0</td>\n",
              "      <td>b'Unknown'</td>\n",
              "      <td>98</td>\n",
              "      <td>b'Unknown'</td>\n",
              "      <td>2</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>b'Ruotsinphytaa, Finland New York, NY'</td>\n",
              "      <td>b'Gustafsson, Mr. Anders Vilhelm'</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>b'3101276'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28.0</td>\n",
              "      <td>b'9'</td>\n",
              "      <td>-1</td>\n",
              "      <td>b'Unknown'</td>\n",
              "      <td>2</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>b'Spain'</td>\n",
              "      <td>b'Reynaldo, Ms. Encarnacion'</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>b'230434'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18.0</td>\n",
              "      <td>b'Unknown'</td>\n",
              "      <td>-1</td>\n",
              "      <td>b'Unknown'</td>\n",
              "      <td>2</td>\n",
              "      <td>73.5000</td>\n",
              "      <td>b'Lyndhurst, England'</td>\n",
              "      <td>b'Davies, Mr. Charles Henry'</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>b'S.O.C. 14879'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>b'Unknown'</td>\n",
              "      <td>-1</td>\n",
              "      <td>b'Unknown'</td>\n",
              "      <td>0</td>\n",
              "      <td>7.8958</td>\n",
              "      <td>b'Unknown'</td>\n",
              "      <td>b'Gheorgheff, Mr. Stanio'</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>b'349254'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-000a0bf5-2040-46a9-b173-84602cf44b5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-000a0bf5-2040-46a9-b173-84602cf44b5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-000a0bf5-2040-46a9-b173-84602cf44b5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ],
      "source": [
        "ds_train = tfds.as_dataframe(ds_train_tf.take(len(ds_train_tf)), ds_info)\n",
        "ds_test = tfds.as_dataframe(ds_test_tf.take(len(ds_test_tf)), ds_info)\n",
        "ds_train.head()"
      ],
      "id": "n0jEeLlX4GJ_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CkW813-mFKp",
        "outputId": "e76be71f-e341-402e-d9d0-c1c6e43406ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1178, 14), (131, 14))"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ],
      "source": [
        "ds_train.shape, ds_test.shape"
      ],
      "id": "4CkW813-mFKp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56moUUS_R5p1"
      },
      "source": [
        "# Предобработка данных"
      ],
      "id": "56moUUS_R5p1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AFxIiKTh1Iv",
        "outputId": "0d008b1e-169e-44df-e007-fc87c380477d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age            99\n",
              "boat           28\n",
              "body          112\n",
              "cabin         178\n",
              "embarked        4\n",
              "fare          271\n",
              "home.dest     350\n",
              "name         1176\n",
              "parch           8\n",
              "pclass          3\n",
              "sex             2\n",
              "sibsp           7\n",
              "survived        2\n",
              "ticket        855\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ],
      "source": [
        "ds_train.nunique()"
      ],
      "id": "-AFxIiKTh1Iv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI0EeWCvmPQZ"
      },
      "outputs": [],
      "source": [
        "# Удаляем 'name', потому что в столбце для каждого наблюдения свое уникальное значение, поэтому данный параметр не несет никакой информации.\n",
        "ds_train = ds_train.drop(['name'], axis=1)\n",
        "ds_test = ds_test.drop(['name'], axis=1)"
      ],
      "id": "TI0EeWCvmPQZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay9LFqn31GG0"
      },
      "source": [
        "### Анализ NULL и UNKNOWN значений"
      ],
      "id": "Ay9LFqn31GG0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFho7-jwnS2H",
        "outputId": "b12dab1d-09f1-403b-d890-dfb823965080"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age          False\n",
              "boat         False\n",
              "body         False\n",
              "cabin        False\n",
              "embarked     False\n",
              "fare         False\n",
              "home.dest    False\n",
              "parch        False\n",
              "pclass       False\n",
              "sex          False\n",
              "sibsp        False\n",
              "survived     False\n",
              "ticket       False\n",
              "Name: 13, dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ],
      "source": [
        "# True in ds_train.isnull()\n",
        "ds_train.isnull().iloc[ds_train.shape[1],]\n",
        "#ds_test.isnull().iloc[ds_test.shape[1],]"
      ],
      "id": "sFho7-jwnS2H"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5nleLlg1WlZ"
      },
      "source": [
        "**Вывод**: Null-значения отсутствуют."
      ],
      "id": "L5nleLlg1WlZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mml2Eqx0uYD",
        "outputId": "b42f48b4-281b-4891-9349-65295b44b6c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Unknown'                    504\n",
              "b'New York, NY'                61\n",
              "b'London'                      14\n",
              "b'Paris, France'                9\n",
              "b'Montreal, PQ'                 9\n",
              "                             ... \n",
              "b'London  Vancouver, BC'        1\n",
              "b'Southsea, Hants'              1\n",
              "b'Columbus, OH'                 1\n",
              "b'Cornwall / Houghton, MI'      1\n",
              "b'?Havana, Cuba'                1\n",
              "Name: home.dest, Length: 350, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ],
      "source": [
        "ds_train['home.dest'].value_counts()"
      ],
      "id": "6Mml2Eqx0uYD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo7sSPKn6EDg"
      },
      "outputs": [],
      "source": [
        "ds_train['home.dest'] = ds_train['home.dest'].astype('string')\n",
        "ds_train.loc[(ds_train['home.dest'] == \"b'Unknown'\"), 'home.dest'] = \"b'New York, NY'\"\n",
        "\n",
        "ds_test['home.dest'] = ds_test['home.dest'].astype('string')\n",
        "ds_test.loc[(ds_test['home.dest'] == \"b'Unknown'\"), 'home.dest'] = \"b'New York, NY'\""
      ],
      "id": "qo7sSPKn6EDg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiYDQtmHoB2e",
        "outputId": "d247c470-510f-4721-be20-4dfc73c27eb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Unknown'    736\n",
              "b'13'          37\n",
              "b'C'           33\n",
              "b'15'          31\n",
              "b'14'          29\n",
              "b'4'           27\n",
              "b'10'          27\n",
              "b'5'           27\n",
              "b'3'           24\n",
              "b'11'          23\n",
              "b'8'           22\n",
              "b'16'          21\n",
              "b'7'           21\n",
              "b'6'           20\n",
              "b'D'           19\n",
              "b'9'           19\n",
              "b'12'          18\n",
              "b'2'           13\n",
              "b'A'           10\n",
              "b'B'            8\n",
              "b'1'            4\n",
              "b'5 7'          2\n",
              "b'13 15'        2\n",
              "b'C D'          1\n",
              "b'15 16'        1\n",
              "b'5 9'          1\n",
              "b'13 15 B'      1\n",
              "b'8 10'         1\n",
              "Name: boat, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ],
      "source": [
        "ds_train['boat'].value_counts()"
      ],
      "id": "kiYDQtmHoB2e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHxEt7wv0rt7",
        "outputId": "57740caf-7a65-4bb5-a7c8-f55b03fdb3b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Unknown'        905\n",
              "b'C23 C25 C27'      6\n",
              "b'G6'               5\n",
              "b'D'                4\n",
              "b'F2'               4\n",
              "                 ... \n",
              "b'E49'              1\n",
              "b'B30'              1\n",
              "b'D46'              1\n",
              "b'C104'             1\n",
              "b'D43'              1\n",
              "Name: cabin, Length: 178, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ],
      "source": [
        "ds_train['cabin'].value_counts()"
      ],
      "id": "JHxEt7wv0rt7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YerqNv7f1jtX"
      },
      "source": [
        "**Вывод**: В столбцах 'boat' и 'cabin' Unknown значения содержатся более чем у половины наблюдений, поэтому можно сделать вывод, что данные параметры не принесут много информации для обучения, а заменить их медианным значением не имеет смысла, но мы рассмотрим 2 датасета. Один с медианными значениями вместо Unknown, другой без данных столбцов."
      ],
      "id": "YerqNv7f1jtX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPH8UHHv2kNi",
        "outputId": "bb07bbd1-b800-4c86-e950-18aa5c28b9fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1178, 11), (131, 11))"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ],
      "source": [
        "ds_train = ds_train.drop(['boat'], axis=1).drop(['cabin'], axis=1)\n",
        "ds_test = ds_test.drop(['boat'], axis=1).drop(['cabin'], axis=1)\n",
        "ds_train.shape, ds_test.shape"
      ],
      "id": "GPH8UHHv2kNi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaFq2thOCrzs"
      },
      "source": [
        "### Приведение к одному типу данных"
      ],
      "id": "iaFq2thOCrzs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrhvYvRP-nvs",
        "outputId": "2662798c-0171-4f8d-96b5-88a82065d184"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age          float32\n",
              "body           int32\n",
              "embarked       int64\n",
              "fare         float32\n",
              "home.dest     string\n",
              "parch          int32\n",
              "pclass         int64\n",
              "sex            int64\n",
              "sibsp          int32\n",
              "survived       int64\n",
              "ticket        object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ],
      "source": [
        "ds_train.dtypes"
      ],
      "id": "QrhvYvRP-nvs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL4Ii079Cy6z"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "ds_train['home.dest'] = labelencoder.fit_transform(ds_train['home.dest'])\n",
        "ds_train['ticket'] = labelencoder.fit_transform(ds_train['ticket'])\n",
        "\n",
        "ds_train['age'] = ds_train['age'].astype(int)\n",
        "ds_train['fare'] = ds_train['fare'].astype(int)\n",
        "ds_train['body'] = ds_train['body'].astype(int)\n",
        "ds_train['parch'] = ds_train['parch'].astype(int)\n",
        "ds_train['sibsp'] = ds_train['sibsp'].astype(int)\n",
        "\n",
        "\n",
        "ds_test['home.dest'] = labelencoder.fit_transform(ds_test['home.dest'])\n",
        "ds_test['ticket'] = labelencoder.fit_transform(ds_test['ticket'])\n",
        "\n",
        "ds_test['age'] = ds_test['age'].astype(int)\n",
        "ds_test['fare'] = ds_test['fare'].astype(int)\n",
        "ds_test['body'] = ds_test['body'].astype(int)\n",
        "ds_test['parch'] = ds_test['parch'].astype(int)\n",
        "ds_test['sibsp'] = ds_test['sibsp'].astype(int)"
      ],
      "id": "SL4Ii079Cy6z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiRGrhs5DnQ0",
        "outputId": "cccd71a3-07ac-4216-fdb1-d60cac22dc89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age          int64\n",
              "body         int64\n",
              "embarked     int64\n",
              "fare         int64\n",
              "home.dest    int64\n",
              "parch        int64\n",
              "pclass       int64\n",
              "sex          int64\n",
              "sibsp        int64\n",
              "survived     int64\n",
              "ticket       int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ],
      "source": [
        "ds_train.dtypes"
      ],
      "id": "IiRGrhs5DnQ0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "GlLTvh-gCw__",
        "outputId": "ed692d6c-dfaa-425f-a52f-b663ebff32b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  body  embarked  fare  home.dest  parch  pclass  sex  sibsp  survived  \\\n",
              "0   30    -1         2    13        271      0       1    0      0         0   \n",
              "1   37    98         2     7        266      0       2    0      2         0   \n",
              "2   28    -1         2    13        283      0       1    1      0         1   \n",
              "3   18    -1         2    73        208      0       1    0      0         0   \n",
              "4   -1    -1         0     7        230      0       2    0      0         0   \n",
              "\n",
              "   ticket  \n",
              "0     141  \n",
              "1     307  \n",
              "2     138  \n",
              "3     780  \n",
              "4     491  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfd4696a-83af-439c-9a31-5a4059916e83\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>body</th>\n",
              "      <th>embarked</th>\n",
              "      <th>fare</th>\n",
              "      <th>home.dest</th>\n",
              "      <th>parch</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>survived</th>\n",
              "      <th>ticket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>271</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>98</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>266</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>283</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>73</td>\n",
              "      <td>208</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>230</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>491</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfd4696a-83af-439c-9a31-5a4059916e83')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dfd4696a-83af-439c-9a31-5a4059916e83 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dfd4696a-83af-439c-9a31-5a4059916e83');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ],
      "source": [
        "ds_train.head()"
      ],
      "id": "GlLTvh-gCw__"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnBHRHI7EZ6e"
      },
      "source": [
        "### Обработка столбца 'age'"
      ],
      "id": "SnBHRHI7EZ6e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMXvwrqTEh8C",
        "outputId": "a4e8d4c6-31a0-474f-d994-d3797054e72c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1     230\n",
              " 24     44\n",
              " 30     40\n",
              " 22     39\n",
              " 18     37\n",
              "      ... \n",
              " 80      1\n",
              " 74      1\n",
              " 66      1\n",
              " 67      1\n",
              " 76      1\n",
              "Name: age, Length: 74, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ],
      "source": [
        "ds_train['age'].value_counts()"
      ],
      "id": "lMXvwrqTEh8C"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmjPYqaVEpBT"
      },
      "source": [
        "Значение \"-1\" у возраста быть не может. Заменим на среднее.\n"
      ],
      "id": "HmjPYqaVEpBT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O32MQf_AEwAV"
      },
      "outputs": [],
      "source": [
        "mean_age = ds_train.loc[(ds_train['age'] > 0), 'age'].mean().astype(int)\n",
        "ds_train.loc[(ds_train['age'] < 0), 'age'] = mean_age\n",
        "\n",
        "mean_age_test = ds_test.loc[(ds_test['age'] > 0), 'age'].mean().astype(int)\n",
        "ds_test.loc[(ds_test['age'] < 0), 'age'] = mean_age_test"
      ],
      "id": "O32MQf_AEwAV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz6RSv6NFwyn"
      },
      "source": [
        "### Еще раз посмотрим на переменные в ds_train"
      ],
      "id": "Jz6RSv6NFwyn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "x3m59SbR-44E",
        "outputId": "520f505b-fcb7-4988-de59-b659990cdc67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               age         body     embarked         fare    home.dest  \\\n",
              "count  1178.000000  1178.000000  1178.000000  1178.000000  1178.000000   \n",
              "mean     30.076401    14.517827     1.491511    33.488115   206.258065   \n",
              "std      13.013917    56.815028     0.820518    52.891501    75.892915   \n",
              "min       0.000000    -1.000000     0.000000    -1.000000     0.000000   \n",
              "25%      23.000000    -1.000000     1.000000     7.000000   188.000000   \n",
              "50%      30.000000    -1.000000     2.000000    14.000000   230.000000   \n",
              "75%      35.750000    -1.000000     2.000000    31.000000   230.000000   \n",
              "max      80.000000   328.000000     3.000000   512.000000   348.000000   \n",
              "\n",
              "             parch       pclass          sex        sibsp     survived  \\\n",
              "count  1178.000000  1178.000000  1178.000000  1178.000000  1178.000000   \n",
              "mean      0.379457     1.279287     0.357385     0.498302     0.384550   \n",
              "std       0.842470     0.844350     0.479433     1.046293     0.486695   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     2.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     2.000000     1.000000     1.000000     1.000000   \n",
              "max       9.000000     2.000000     1.000000     8.000000     1.000000   \n",
              "\n",
              "            ticket  \n",
              "count  1178.000000  \n",
              "mean    427.971986  \n",
              "std     256.106383  \n",
              "min       0.000000  \n",
              "25%     195.250000  \n",
              "50%     427.500000  \n",
              "75%     670.750000  \n",
              "max     854.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b984ff49-123a-4bc0-9d52-ea1ae33f04f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>body</th>\n",
              "      <th>embarked</th>\n",
              "      <th>fare</th>\n",
              "      <th>home.dest</th>\n",
              "      <th>parch</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>survived</th>\n",
              "      <th>ticket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1178.000000</td>\n",
              "      <td>1178.000000</td>\n",
              "      <td>1178.000000</td>\n",
              "      <td>1178.000000</td>\n",
              "      <td>1178.000000</td>\n",
              "      <td>1178.000000</td>\n",
              "      <td>1178.000000</td>\n",
              "      <td>1178.000000</td>\n",
              "      <td>1178.000000</td>\n",
              "      <td>1178.000000</td>\n",
              "      <td>1178.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>30.076401</td>\n",
              "      <td>14.517827</td>\n",
              "      <td>1.491511</td>\n",
              "      <td>33.488115</td>\n",
              "      <td>206.258065</td>\n",
              "      <td>0.379457</td>\n",
              "      <td>1.279287</td>\n",
              "      <td>0.357385</td>\n",
              "      <td>0.498302</td>\n",
              "      <td>0.384550</td>\n",
              "      <td>427.971986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>13.013917</td>\n",
              "      <td>56.815028</td>\n",
              "      <td>0.820518</td>\n",
              "      <td>52.891501</td>\n",
              "      <td>75.892915</td>\n",
              "      <td>0.842470</td>\n",
              "      <td>0.844350</td>\n",
              "      <td>0.479433</td>\n",
              "      <td>1.046293</td>\n",
              "      <td>0.486695</td>\n",
              "      <td>256.106383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>188.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>30.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>230.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>427.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.750000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>230.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>670.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>328.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>512.000000</td>\n",
              "      <td>348.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>854.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b984ff49-123a-4bc0-9d52-ea1ae33f04f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b984ff49-123a-4bc0-9d52-ea1ae33f04f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b984ff49-123a-4bc0-9d52-ea1ae33f04f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 206
        }
      ],
      "source": [
        "ds_train.describe()"
      ],
      "id": "x3m59SbR-44E"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3rY0XckGNzq"
      },
      "source": [
        "Наши выходные данные - столбец survived. Проверим на взвешенность."
      ],
      "id": "g3rY0XckGNzq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySVyUf58GJNS",
        "outputId": "fb4a938a-f7a4-4ba4-a2ba-8d400db5e91e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    725\n",
              "1    453\n",
              "Name: survived, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ],
      "source": [
        "ds_train['survived'].value_counts()"
      ],
      "id": "ySVyUf58GJNS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwgJhAXmrgfQ"
      },
      "source": [
        "### Матрица корреляции"
      ],
      "id": "LwgJhAXmrgfQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "qVIjOU_FrJeW",
        "outputId": "84d37e5f-3fe3-495e-d277-2915a5fac2dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1368x864 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "corr = ds_train.corr()\n",
        "plt.figure(figsize=(19, 12))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
        "plt.show()"
      ],
      "id": "qVIjOU_FrJeW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4Almfomrs2O"
      },
      "source": [
        "**Вывод**: нет пар с высоким коэффициентом корреляции (>0.7)"
      ],
      "id": "k4Almfomrs2O"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkeZ7y6meks5"
      },
      "source": [
        "# Обучение"
      ],
      "id": "hkeZ7y6meks5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обучение с параметрами, выбранными вручную"
      ],
      "metadata": {
        "id": "4qxpaQ9b_-bj"
      },
      "id": "4qxpaQ9b_-bj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Uj30ztv9qDlE",
        "outputId": "ad8f8adf-cf05-4b9a-d509-59cd09028c64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age  body  embarked  fare  home.dest  parch  pclass  sex  sibsp  \\\n",
              "0      30    -1         2    13        271      0       1    0      0   \n",
              "1      37    98         2     7        266      0       2    0      2   \n",
              "2      28    -1         2    13        283      0       1    1      0   \n",
              "3      18    -1         2    73        208      0       1    0      0   \n",
              "4      30    -1         0     7        230      0       2    0      0   \n",
              "...   ...   ...       ...   ...        ...    ...     ...  ...    ...   \n",
              "1173   30    -1         2     7        230      0       2    0      0   \n",
              "1174   38    -1         0    71        230      0       0    1      1   \n",
              "1175   41    -1         0    15        230      0       1    0      0   \n",
              "1176   29    -1         2     9        230      0       2    0      0   \n",
              "1177   13    -1         2    31        306      2       2    0      4   \n",
              "\n",
              "      survived  \n",
              "0            0  \n",
              "1            0  \n",
              "2            1  \n",
              "3            0  \n",
              "4            0  \n",
              "...        ...  \n",
              "1173         0  \n",
              "1174         1  \n",
              "1175         0  \n",
              "1176         1  \n",
              "1177         0  \n",
              "\n",
              "[1178 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59dbb726-2f78-4d2b-bf58-6bf940373e29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>body</th>\n",
              "      <th>embarked</th>\n",
              "      <th>fare</th>\n",
              "      <th>home.dest</th>\n",
              "      <th>parch</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>271</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>98</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>266</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>283</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>73</td>\n",
              "      <td>208</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>230</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1173</th>\n",
              "      <td>30</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>230</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1174</th>\n",
              "      <td>38</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>71</td>\n",
              "      <td>230</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1175</th>\n",
              "      <td>41</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1176</th>\n",
              "      <td>29</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>230</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1177</th>\n",
              "      <td>13</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>31</td>\n",
              "      <td>306</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1178 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59dbb726-2f78-4d2b-bf58-6bf940373e29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59dbb726-2f78-4d2b-bf58-6bf940373e29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59dbb726-2f78-4d2b-bf58-6bf940373e29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ],
      "source": [
        "ds_train.iloc[:, :-1]"
      ],
      "id": "Uj30ztv9qDlE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcHhATwVpneh",
        "outputId": "c894bd79-a078-4362-9003-9cf979537d8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1178, 10), (131, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ],
      "source": [
        "X_train = ds_train.drop(['survived'], axis=1).values\n",
        "y_train = ds_train['survived'].values\n",
        "\n",
        "X_test = ds_test.drop(['survived'], axis=1).values\n",
        "y_test = ds_test['survived'].values\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "id": "WcHhATwVpneh"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, shuffle= True)\n",
        "X_train.shape, X_valid.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn1aoK9DGrRi",
        "outputId": "21f56ed4-1bbe-49e5-83f6-5b801af1ade5"
      },
      "id": "wn1aoK9DGrRi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1060, 10), (118, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KknSisJeoAn"
      },
      "outputs": [],
      "source": [
        "# Стандартизуем\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)\n",
        "X_valid = sc.fit_transform(X_valid)"
      ],
      "id": "-KknSisJeoAn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpwfqyNdeoCv"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import activations, layers, optimizers, losses, metrics"
      ],
      "id": "fpwfqyNdeoCv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMtnAMG3eoFf",
        "outputId": "d397708b-6425-4344-f5c9-9f5d6576046f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_76\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_224 (Dense)           (None, 16)                176       \n",
            "                                                                 \n",
            " dense_225 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_226 (Dense)           (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "classifier = Sequential()\n",
        "classifier.add(layers.Dense(16, input_dim = X_train.shape[1], activation = 'relu'))\n",
        "classifier.add(layers.Dense(8, activation = 'relu'))\n",
        "classifier.add(layers.Dense(1, activation = 'sigmoid'))\n",
        "classifier.summary()"
      ],
      "id": "BMtnAMG3eoFf"
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "classifier.fit(X_train, y_train, epochs = 50, validation_data = (X_valid, y_valid), shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkAXN_FDJNzb",
        "outputId": "e1ad32b0-5f02-41bb-b356-002e87166ef9"
      },
      "id": "OkAXN_FDJNzb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "34/34 [==============================] - 2s 25ms/step - loss: 0.6645 - accuracy: 0.5887 - val_loss: 0.6484 - val_accuracy: 0.6271\n",
            "Epoch 2/50\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.6258 - accuracy: 0.6604 - val_loss: 0.6135 - val_accuracy: 0.6610\n",
            "Epoch 3/50\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.6000 - accuracy: 0.6792 - val_loss: 0.5855 - val_accuracy: 0.7119\n",
            "Epoch 4/50\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.5789 - accuracy: 0.6991 - val_loss: 0.5607 - val_accuracy: 0.7627\n",
            "Epoch 5/50\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.5605 - accuracy: 0.7170 - val_loss: 0.5373 - val_accuracy: 0.7966\n",
            "Epoch 6/50\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.5432 - accuracy: 0.7377 - val_loss: 0.5114 - val_accuracy: 0.8051\n",
            "Epoch 7/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.5246 - accuracy: 0.7604 - val_loss: 0.4862 - val_accuracy: 0.8220\n",
            "Epoch 8/50\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.5065 - accuracy: 0.7783 - val_loss: 0.4586 - val_accuracy: 0.8390\n",
            "Epoch 9/50\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.4872 - accuracy: 0.7896 - val_loss: 0.4304 - val_accuracy: 0.8475\n",
            "Epoch 10/50\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.4700 - accuracy: 0.7934 - val_loss: 0.4078 - val_accuracy: 0.8559\n",
            "Epoch 11/50\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.4561 - accuracy: 0.8038 - val_loss: 0.3900 - val_accuracy: 0.8559\n",
            "Epoch 12/50\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.4454 - accuracy: 0.8057 - val_loss: 0.3763 - val_accuracy: 0.8475\n",
            "Epoch 13/50\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.4357 - accuracy: 0.8066 - val_loss: 0.3631 - val_accuracy: 0.8644\n",
            "Epoch 14/50\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.4290 - accuracy: 0.8075 - val_loss: 0.3564 - val_accuracy: 0.8390\n",
            "Epoch 15/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.4245 - accuracy: 0.8104 - val_loss: 0.3502 - val_accuracy: 0.8475\n",
            "Epoch 16/50\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.4203 - accuracy: 0.8151 - val_loss: 0.3451 - val_accuracy: 0.8475\n",
            "Epoch 17/50\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.8113 - val_loss: 0.3454 - val_accuracy: 0.8559\n",
            "Epoch 18/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.4138 - accuracy: 0.8151 - val_loss: 0.3427 - val_accuracy: 0.8475\n",
            "Epoch 19/50\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8142 - val_loss: 0.3420 - val_accuracy: 0.8475\n",
            "Epoch 20/50\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.4097 - accuracy: 0.8142 - val_loss: 0.3394 - val_accuracy: 0.8559\n",
            "Epoch 21/50\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.4082 - accuracy: 0.8151 - val_loss: 0.3359 - val_accuracy: 0.8559\n",
            "Epoch 22/50\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.4064 - accuracy: 0.8160 - val_loss: 0.3389 - val_accuracy: 0.8644\n",
            "Epoch 23/50\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8179 - val_loss: 0.3355 - val_accuracy: 0.8644\n",
            "Epoch 24/50\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.4033 - accuracy: 0.8142 - val_loss: 0.3319 - val_accuracy: 0.8559\n",
            "Epoch 25/50\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.8160 - val_loss: 0.3331 - val_accuracy: 0.8729\n",
            "Epoch 26/50\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.4011 - accuracy: 0.8151 - val_loss: 0.3313 - val_accuracy: 0.8729\n",
            "Epoch 27/50\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8189 - val_loss: 0.3292 - val_accuracy: 0.8644\n",
            "Epoch 28/50\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.8208 - val_loss: 0.3297 - val_accuracy: 0.8729\n",
            "Epoch 29/50\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.3977 - accuracy: 0.8179 - val_loss: 0.3269 - val_accuracy: 0.8814\n",
            "Epoch 30/50\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8236 - val_loss: 0.3312 - val_accuracy: 0.8729\n",
            "Epoch 31/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.3961 - accuracy: 0.8170 - val_loss: 0.3270 - val_accuracy: 0.8644\n",
            "Epoch 32/50\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.3950 - accuracy: 0.8208 - val_loss: 0.3249 - val_accuracy: 0.8729\n",
            "Epoch 33/50\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.3941 - accuracy: 0.8208 - val_loss: 0.3274 - val_accuracy: 0.8644\n",
            "Epoch 34/50\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.3937 - accuracy: 0.8226 - val_loss: 0.3253 - val_accuracy: 0.8729\n",
            "Epoch 35/50\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.3927 - accuracy: 0.8236 - val_loss: 0.3304 - val_accuracy: 0.8644\n",
            "Epoch 36/50\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.3915 - accuracy: 0.8255 - val_loss: 0.3288 - val_accuracy: 0.8814\n",
            "Epoch 37/50\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.3913 - accuracy: 0.8283 - val_loss: 0.3270 - val_accuracy: 0.8644\n",
            "Epoch 38/50\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.3899 - accuracy: 0.8236 - val_loss: 0.3252 - val_accuracy: 0.8729\n",
            "Epoch 39/50\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.3909 - accuracy: 0.8283 - val_loss: 0.3257 - val_accuracy: 0.8729\n",
            "Epoch 40/50\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.3891 - accuracy: 0.8274 - val_loss: 0.3255 - val_accuracy: 0.8644\n",
            "Epoch 41/50\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.3892 - accuracy: 0.8283 - val_loss: 0.3277 - val_accuracy: 0.8814\n",
            "Epoch 42/50\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.3879 - accuracy: 0.8274 - val_loss: 0.3259 - val_accuracy: 0.8814\n",
            "Epoch 43/50\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.3880 - accuracy: 0.8283 - val_loss: 0.3275 - val_accuracy: 0.8729\n",
            "Epoch 44/50\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.3868 - accuracy: 0.8283 - val_loss: 0.3261 - val_accuracy: 0.8729\n",
            "Epoch 45/50\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.3864 - accuracy: 0.8274 - val_loss: 0.3257 - val_accuracy: 0.8729\n",
            "Epoch 46/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.3866 - accuracy: 0.8217 - val_loss: 0.3266 - val_accuracy: 0.8729\n",
            "Epoch 47/50\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8264 - val_loss: 0.3255 - val_accuracy: 0.8814\n",
            "Epoch 48/50\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.3865 - accuracy: 0.8245 - val_loss: 0.3243 - val_accuracy: 0.8814\n",
            "Epoch 49/50\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.3853 - accuracy: 0.8264 - val_loss: 0.3259 - val_accuracy: 0.8898\n",
            "Epoch 50/50\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.8208 - val_loss: 0.3255 - val_accuracy: 0.8814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnIFRizSW4BB"
      },
      "source": [
        "### Подбор гиперпараметров с помощью Optuna"
      ],
      "id": "BnIFRizSW4BB"
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install optuna"
      ],
      "metadata": {
        "id": "6II9E0NxAgXy"
      },
      "id": "6II9E0NxAgXy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f2i091XW_A1"
      },
      "outputs": [],
      "source": [
        "import optuna"
      ],
      "id": "4f2i091XW_A1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLR3TjwKXDs2"
      },
      "outputs": [],
      "source": [
        "def optuna_objective(trial: optuna.trial.Trial):\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            layers.Dense(\n",
        "                units=trial.suggest_int('l1_neurons', 8, 16),\n",
        "                input_dim=X_train.shape[1],\n",
        "                activation=trial.suggest_categorical('l1_activation', ['sigmoid', 'relu'])\n",
        "            ),\n",
        "            layers.Dense(\n",
        "                units=trial.suggest_int('l2_neurons', 2, 8),\n",
        "                activation=trial.suggest_categorical('l2_activation', ['sigmoid', 'relu'])\n",
        "            ),\n",
        "            layers.Dense(1, activation = 'sigmoid')\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer = 'adam',\n",
        "        loss = 'binary_crossentropy',\n",
        "        metrics = ['accuracy']\n",
        "    )\n",
        "    \n",
        "    history = model.fit(X_train, y_train, epochs = 50, verbose = 0, validation_data = (X_valid, y_valid), shuffle=True)\n",
        "    accuracy = history.history['val_accuracy'][-1]\n",
        "    return accuracy"
      ],
      "id": "PLR3TjwKXDs2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cycbUBo-YTuF",
        "outputId": "d50f46b5-0669-489a-eeaa-2a40c7ed4211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-04 15:07:09,743]\u001b[0m A new study created in memory with name: no-name-a9e84559-8423-4034-9c22-1f72985da291\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction='maximize')"
      ],
      "id": "cycbUBo-YTuF"
    },
    {
      "cell_type": "code",
      "source": [
        "study.optimize(optuna_objective, n_trials = 20)"
      ],
      "metadata": {
        "id": "j-sxcdNeLS3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b47476-b16d-4b7c-ed42-40528913b25a"
      },
      "id": "j-sxcdNeLS3_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-04 15:07:21,853]\u001b[0m Trial 0 finished with value: 0.8305084705352783 and parameters: {'l1_neurons': 16, 'l1_activation': 'sigmoid', 'l2_neurons': 4, 'l2_activation': 'relu'}. Best is trial 0 with value: 0.8305084705352783.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:07:32,767]\u001b[0m Trial 1 finished with value: 0.8220338821411133 and parameters: {'l1_neurons': 14, 'l1_activation': 'sigmoid', 'l2_neurons': 6, 'l2_activation': 'sigmoid'}. Best is trial 0 with value: 0.8305084705352783.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:07:39,369]\u001b[0m Trial 2 finished with value: 0.8305084705352783 and parameters: {'l1_neurons': 13, 'l1_activation': 'sigmoid', 'l2_neurons': 5, 'l2_activation': 'relu'}. Best is trial 0 with value: 0.8305084705352783.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:07:45,795]\u001b[0m Trial 3 finished with value: 0.8220338821411133 and parameters: {'l1_neurons': 14, 'l1_activation': 'sigmoid', 'l2_neurons': 3, 'l2_activation': 'relu'}. Best is trial 0 with value: 0.8305084705352783.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:07:56,777]\u001b[0m Trial 4 finished with value: 0.8559321761131287 and parameters: {'l1_neurons': 16, 'l1_activation': 'relu', 'l2_neurons': 5, 'l2_activation': 'sigmoid'}. Best is trial 4 with value: 0.8559321761131287.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:08:07,770]\u001b[0m Trial 5 finished with value: 0.8305084705352783 and parameters: {'l1_neurons': 15, 'l1_activation': 'relu', 'l2_neurons': 5, 'l2_activation': 'sigmoid'}. Best is trial 4 with value: 0.8559321761131287.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:08:14,351]\u001b[0m Trial 6 finished with value: 0.8305084705352783 and parameters: {'l1_neurons': 11, 'l1_activation': 'sigmoid', 'l2_neurons': 6, 'l2_activation': 'sigmoid'}. Best is trial 4 with value: 0.8559321761131287.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:08:21,042]\u001b[0m Trial 7 finished with value: 0.8559321761131287 and parameters: {'l1_neurons': 15, 'l1_activation': 'relu', 'l2_neurons': 2, 'l2_activation': 'sigmoid'}. Best is trial 4 with value: 0.8559321761131287.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:08:31,978]\u001b[0m Trial 8 finished with value: 0.8559321761131287 and parameters: {'l1_neurons': 11, 'l1_activation': 'sigmoid', 'l2_neurons': 5, 'l2_activation': 'relu'}. Best is trial 4 with value: 0.8559321761131287.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:08:38,523]\u001b[0m Trial 9 finished with value: 0.8135592937469482 and parameters: {'l1_neurons': 10, 'l1_activation': 'sigmoid', 'l2_neurons': 2, 'l2_activation': 'sigmoid'}. Best is trial 4 with value: 0.8559321761131287.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:08:45,083]\u001b[0m Trial 10 finished with value: 0.8389830589294434 and parameters: {'l1_neurons': 9, 'l1_activation': 'relu', 'l2_neurons': 8, 'l2_activation': 'sigmoid'}. Best is trial 4 with value: 0.8559321761131287.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:08:55,997]\u001b[0m Trial 11 finished with value: 0.8559321761131287 and parameters: {'l1_neurons': 16, 'l1_activation': 'relu', 'l2_neurons': 2, 'l2_activation': 'sigmoid'}. Best is trial 4 with value: 0.8559321761131287.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:09:05,497]\u001b[0m Trial 12 finished with value: 0.8474576473236084 and parameters: {'l1_neurons': 16, 'l1_activation': 'relu', 'l2_neurons': 8, 'l2_activation': 'sigmoid'}. Best is trial 4 with value: 0.8559321761131287.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:09:13,574]\u001b[0m Trial 13 finished with value: 0.8389830589294434 and parameters: {'l1_neurons': 13, 'l1_activation': 'relu', 'l2_neurons': 3, 'l2_activation': 'sigmoid'}. Best is trial 4 with value: 0.8559321761131287.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:09:20,512]\u001b[0m Trial 14 finished with value: 0.8305084705352783 and parameters: {'l1_neurons': 15, 'l1_activation': 'relu', 'l2_neurons': 7, 'l2_activation': 'sigmoid'}. Best is trial 4 with value: 0.8559321761131287.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:09:27,237]\u001b[0m Trial 15 finished with value: 0.8559321761131287 and parameters: {'l1_neurons': 8, 'l1_activation': 'relu', 'l2_neurons': 3, 'l2_activation': 'sigmoid'}. Best is trial 4 with value: 0.8559321761131287.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:09:38,217]\u001b[0m Trial 16 finished with value: 0.8644067645072937 and parameters: {'l1_neurons': 14, 'l1_activation': 'relu', 'l2_neurons': 4, 'l2_activation': 'sigmoid'}. Best is trial 16 with value: 0.8644067645072937.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:09:49,217]\u001b[0m Trial 17 finished with value: 0.8644067645072937 and parameters: {'l1_neurons': 13, 'l1_activation': 'relu', 'l2_neurons': 4, 'l2_activation': 'sigmoid'}. Best is trial 16 with value: 0.8644067645072937.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:09:55,388]\u001b[0m Trial 18 finished with value: 0.8474576473236084 and parameters: {'l1_neurons': 12, 'l1_activation': 'relu', 'l2_neurons': 4, 'l2_activation': 'relu'}. Best is trial 16 with value: 0.8644067645072937.\u001b[0m\n",
            "\u001b[32m[I 2022-11-04 15:10:06,321]\u001b[0m Trial 19 finished with value: 0.8389830589294434 and parameters: {'l1_neurons': 13, 'l1_activation': 'relu', 'l2_neurons': 4, 'l2_activation': 'sigmoid'}. Best is trial 16 with value: 0.8644067645072937.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_params"
      ],
      "metadata": {
        "id": "92a4L35zLW6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8ca07d-ae98-4659-a50f-10fb5e0f3092"
      },
      "id": "92a4L35zLW6U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l1_neurons': 14,\n",
              " 'l1_activation': 'relu',\n",
              " 'l2_neurons': 4,\n",
              " 'l2_activation': 'sigmoid'}"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Качество модели на тестовом наборе"
      ],
      "metadata": {
        "id": "b6Kwvg8lUYaT"
      },
      "id": "b6Kwvg8lUYaT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нашли лучшие параметры, теперь посмотрим модель и проверим ее на тестовом наборе"
      ],
      "metadata": {
        "id": "6Qp24yNaUS-4"
      },
      "id": "6Qp24yNaUS-4"
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential()\n",
        "classifier.add(layers.Dense(14, input_dim = X_train.shape[1], activation = 'relu'))\n",
        "classifier.add(layers.Dense(4, activation = 'sigmoid'))\n",
        "classifier.add(layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "classifier.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "classifier.fit(X_train, y_train, epochs = 50, validation_data = (X_valid, y_valid), shuffle=True, verbose = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWB1jJ7jND_G",
        "outputId": "34de88df-7eda-49c7-b6ec-c095a51649f3"
      },
      "id": "SWB1jJ7jND_G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "34/34 [==============================] - 1s 8ms/step - loss: 0.6559 - accuracy: 0.6057 - val_loss: 0.6435 - val_accuracy: 0.6102\n",
            "Epoch 2/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.6236 - val_loss: 0.6295 - val_accuracy: 0.6186\n",
            "Epoch 3/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.6396 - val_loss: 0.6141 - val_accuracy: 0.6441\n",
            "Epoch 4/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6155 - accuracy: 0.6557 - val_loss: 0.5982 - val_accuracy: 0.6695\n",
            "Epoch 5/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.6943 - val_loss: 0.5818 - val_accuracy: 0.7203\n",
            "Epoch 6/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.7151 - val_loss: 0.5645 - val_accuracy: 0.7373\n",
            "Epoch 7/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.7321 - val_loss: 0.5482 - val_accuracy: 0.7712\n",
            "Epoch 8/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.7481 - val_loss: 0.5313 - val_accuracy: 0.7966\n",
            "Epoch 9/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7642 - val_loss: 0.5171 - val_accuracy: 0.7966\n",
            "Epoch 10/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7717 - val_loss: 0.5026 - val_accuracy: 0.8220\n",
            "Epoch 11/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7821 - val_loss: 0.4895 - val_accuracy: 0.8220\n",
            "Epoch 12/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7849 - val_loss: 0.4778 - val_accuracy: 0.8390\n",
            "Epoch 13/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7915 - val_loss: 0.4675 - val_accuracy: 0.8475\n",
            "Epoch 14/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7915 - val_loss: 0.4572 - val_accuracy: 0.8559\n",
            "Epoch 15/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7972 - val_loss: 0.4488 - val_accuracy: 0.8475\n",
            "Epoch 16/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.8009 - val_loss: 0.4412 - val_accuracy: 0.8475\n",
            "Epoch 17/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7962 - val_loss: 0.4343 - val_accuracy: 0.8390\n",
            "Epoch 18/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.8000 - val_loss: 0.4286 - val_accuracy: 0.8305\n",
            "Epoch 19/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.8000 - val_loss: 0.4227 - val_accuracy: 0.8305\n",
            "Epoch 20/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.8038 - val_loss: 0.4192 - val_accuracy: 0.8390\n",
            "Epoch 21/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.8047 - val_loss: 0.4151 - val_accuracy: 0.8390\n",
            "Epoch 22/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.8057 - val_loss: 0.4114 - val_accuracy: 0.8390\n",
            "Epoch 23/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.8057 - val_loss: 0.4074 - val_accuracy: 0.8390\n",
            "Epoch 24/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.8075 - val_loss: 0.4036 - val_accuracy: 0.8390\n",
            "Epoch 25/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.8075 - val_loss: 0.4005 - val_accuracy: 0.8390\n",
            "Epoch 26/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.8075 - val_loss: 0.3967 - val_accuracy: 0.8390\n",
            "Epoch 27/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.8113 - val_loss: 0.3946 - val_accuracy: 0.8390\n",
            "Epoch 28/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.8104 - val_loss: 0.3923 - val_accuracy: 0.8305\n",
            "Epoch 29/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.8113 - val_loss: 0.3903 - val_accuracy: 0.8305\n",
            "Epoch 30/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.8104 - val_loss: 0.3878 - val_accuracy: 0.8220\n",
            "Epoch 31/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.8151 - val_loss: 0.3849 - val_accuracy: 0.8390\n",
            "Epoch 32/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.8189 - val_loss: 0.3833 - val_accuracy: 0.8220\n",
            "Epoch 33/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.8160 - val_loss: 0.3822 - val_accuracy: 0.8220\n",
            "Epoch 34/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.8160 - val_loss: 0.3807 - val_accuracy: 0.8305\n",
            "Epoch 35/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8170 - val_loss: 0.3789 - val_accuracy: 0.8220\n",
            "Epoch 36/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.8113 - val_loss: 0.3743 - val_accuracy: 0.8220\n",
            "Epoch 37/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8170 - val_loss: 0.3739 - val_accuracy: 0.8220\n",
            "Epoch 38/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.8160 - val_loss: 0.3734 - val_accuracy: 0.8220\n",
            "Epoch 39/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.8160 - val_loss: 0.3720 - val_accuracy: 0.8305\n",
            "Epoch 40/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.8142 - val_loss: 0.3713 - val_accuracy: 0.8220\n",
            "Epoch 41/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.8189 - val_loss: 0.3708 - val_accuracy: 0.8305\n",
            "Epoch 42/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.8151 - val_loss: 0.3684 - val_accuracy: 0.8305\n",
            "Epoch 43/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8160 - val_loss: 0.3685 - val_accuracy: 0.8305\n",
            "Epoch 44/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8189 - val_loss: 0.3676 - val_accuracy: 0.8305\n",
            "Epoch 45/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8170 - val_loss: 0.3671 - val_accuracy: 0.8305\n",
            "Epoch 46/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8160 - val_loss: 0.3651 - val_accuracy: 0.8305\n",
            "Epoch 47/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8208 - val_loss: 0.3649 - val_accuracy: 0.8305\n",
            "Epoch 48/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8208 - val_loss: 0.3651 - val_accuracy: 0.8305\n",
            "Epoch 49/50\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8170 - val_loss: 0.3644 - val_accuracy: 0.8390\n",
            "Epoch 50/50\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.8179 - val_loss: 0.3632 - val_accuracy: 0.8390\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f16e4ac13d0>"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = classifier.predict(X_test).tolist()\n",
        "se = pd.Series(prediction)\n",
        "y_test_pred = se.str.get(0)\n",
        "[y_test.shape, y_test_pred.shape]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYYcHR1xRKaa",
        "outputId": "4e75d709-806c-480d-a58f-7e592225df26"
      },
      "id": "AYYcHR1xRKaa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(131,), (131,)]"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_class(y_test_pred):\n",
        "  for i in range(len(y_test_pred)):\n",
        "    if y_test_pred[i] >= 0.5:\n",
        "      y_test_pred[i] = 1\n",
        "    else:\n",
        "      y_test_pred[i] = 0\n",
        "  return y_test_pred"
      ],
      "metadata": {
        "id": "PCtFt7boRjRK"
      },
      "id": "PCtFt7boRjRK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = choose_class(y_test_pred)"
      ],
      "metadata": {
        "id": "oSAN1UDpRzqS"
      },
      "id": "oSAN1UDpRzqS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print('Accuracy на тестовой выборке', accuracy_score(y_test, y_test_pred, normalize=True))\n",
        "print(' ')\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EQP0eEnRhxl",
        "outputId": "bed3bf3e-6c98-4756-f6a0-7402ece03984"
      },
      "id": "4EQP0eEnRhxl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy на тестовой выборке 0.7938931297709924\n",
            " \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.84        84\n",
            "           1       0.74      0.66      0.70        47\n",
            "\n",
            "    accuracy                           0.79       131\n",
            "   macro avg       0.78      0.76      0.77       131\n",
            "weighted avg       0.79      0.79      0.79       131\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод**: 0.79 - очень неплохой результат!"
      ],
      "metadata": {
        "id": "5oCM8U7UUF-3"
      },
      "id": "5oCM8U7UUF-3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnnKapRpWeyk"
      },
      "source": [
        "### Подбор гиперпараметров \"optimizer\", \"epochs\", \"batch_size\" с помощью GridSearchCV"
      ],
      "id": "FnnKapRpWeyk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Возьмем лучшие параметры, посчитанные с помощью optuna"
      ],
      "metadata": {
        "id": "PE2RllprUn7H"
      },
      "id": "PE2RllprUn7H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac57iyLxaIIM"
      },
      "outputs": [],
      "source": [
        "def build_classifier(optimizer):\n",
        "  classifier = Sequential()\n",
        "  classifier.add(Dense(14, input_dim = X_train.shape[1], activation = 'relu'))\n",
        "  classifier.add(Dense(4, activation = 'sigmoid'))\n",
        "  classifier.add(Dense(1, activation = 'sigmoid'))\n",
        "  classifier.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "  return classifier"
      ],
      "id": "ac57iyLxaIIM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al8wjGSBaKXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "295d96b1-1b7b-48bc-c0bb-7adbb531865e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "classifier = KerasClassifier(build_fn = build_classifier)"
      ],
      "id": "al8wjGSBaKXn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1vo3t7UXIR0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "id": "H1vo3t7UXIR0"
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "7GLU15LyES43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f65ce1aa-f334-4327-b03e-c0a742931c7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5084 - accuracy: 0.8042 - val_loss: 0.4853 - val_accuracy: 0.8390\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.8066 - val_loss: 0.4669 - val_accuracy: 0.8475\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4814 - accuracy: 0.8066 - val_loss: 0.4523 - val_accuracy: 0.8390\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.8160 - val_loss: 0.4392 - val_accuracy: 0.8390\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.8219 - val_loss: 0.4286 - val_accuracy: 0.8390\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.8219 - val_loss: 0.4197 - val_accuracy: 0.8390\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.8196 - val_loss: 0.4131 - val_accuracy: 0.8305\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.8196 - val_loss: 0.4052 - val_accuracy: 0.8390\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.8231 - val_loss: 0.4007 - val_accuracy: 0.8475\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.8219 - val_loss: 0.3946 - val_accuracy: 0.8390\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.8196 - val_loss: 0.3912 - val_accuracy: 0.8475\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4389 - accuracy: 0.8219 - val_loss: 0.3882 - val_accuracy: 0.8475\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.8231 - val_loss: 0.3860 - val_accuracy: 0.8475\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.8184 - val_loss: 0.3826 - val_accuracy: 0.8475\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.8243 - val_loss: 0.3796 - val_accuracy: 0.8475\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.8231 - val_loss: 0.3766 - val_accuracy: 0.8559\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.8219 - val_loss: 0.3750 - val_accuracy: 0.8559\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.8196 - val_loss: 0.3733 - val_accuracy: 0.8559\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.8196 - val_loss: 0.3710 - val_accuracy: 0.8475\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4277 - accuracy: 0.8208 - val_loss: 0.3700 - val_accuracy: 0.8559\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4266 - accuracy: 0.8219 - val_loss: 0.3683 - val_accuracy: 0.8559\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4260 - accuracy: 0.8184 - val_loss: 0.3675 - val_accuracy: 0.8390\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.8208 - val_loss: 0.3650 - val_accuracy: 0.8475\n",
            "Epoch 31/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8219 - val_loss: 0.3637 - val_accuracy: 0.8475\n",
            "Epoch 32/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.8219 - val_loss: 0.3630 - val_accuracy: 0.8559\n",
            "Epoch 33/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.8243 - val_loss: 0.3619 - val_accuracy: 0.8559\n",
            "Epoch 34/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.8196 - val_loss: 0.3611 - val_accuracy: 0.8475\n",
            "Epoch 35/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.8243 - val_loss: 0.3598 - val_accuracy: 0.8390\n",
            "Epoch 36/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4195 - accuracy: 0.8267 - val_loss: 0.3587 - val_accuracy: 0.8305\n",
            "Epoch 37/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.8243 - val_loss: 0.3574 - val_accuracy: 0.8390\n",
            "Epoch 38/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.8219 - val_loss: 0.3570 - val_accuracy: 0.8305\n",
            "Epoch 39/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.8302 - val_loss: 0.3564 - val_accuracy: 0.8390\n",
            "Epoch 40/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8278 - val_loss: 0.3547 - val_accuracy: 0.8305\n",
            "Epoch 41/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8278 - val_loss: 0.3540 - val_accuracy: 0.8220\n",
            "Epoch 42/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8290 - val_loss: 0.3548 - val_accuracy: 0.8390\n",
            "Epoch 43/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8290 - val_loss: 0.3524 - val_accuracy: 0.8305\n",
            "Epoch 44/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8278 - val_loss: 0.3515 - val_accuracy: 0.8305\n",
            "Epoch 45/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8290 - val_loss: 0.3509 - val_accuracy: 0.8220\n",
            "Epoch 46/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8219 - val_loss: 0.3502 - val_accuracy: 0.8305\n",
            "Epoch 47/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8243 - val_loss: 0.3506 - val_accuracy: 0.8390\n",
            "Epoch 48/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8278 - val_loss: 0.3491 - val_accuracy: 0.8390\n",
            "Epoch 49/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4099 - accuracy: 0.8267 - val_loss: 0.3484 - val_accuracy: 0.8305\n",
            "Epoch 50/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4098 - accuracy: 0.8290 - val_loss: 0.3468 - val_accuracy: 0.8390\n",
            "Epoch 51/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8278 - val_loss: 0.3463 - val_accuracy: 0.8390\n",
            "Epoch 52/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.8314 - val_loss: 0.3469 - val_accuracy: 0.8390\n",
            "Epoch 53/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.8278 - val_loss: 0.3455 - val_accuracy: 0.8390\n",
            "Epoch 54/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8290 - val_loss: 0.3454 - val_accuracy: 0.8390\n",
            "Epoch 55/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8314 - val_loss: 0.3441 - val_accuracy: 0.8390\n",
            "Epoch 56/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8267 - val_loss: 0.3437 - val_accuracy: 0.8390\n",
            "Epoch 57/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8255 - val_loss: 0.3442 - val_accuracy: 0.8475\n",
            "Epoch 58/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8278 - val_loss: 0.3434 - val_accuracy: 0.8475\n",
            "Epoch 59/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4043 - accuracy: 0.8290 - val_loss: 0.3424 - val_accuracy: 0.8559\n",
            "Epoch 60/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8290 - val_loss: 0.3423 - val_accuracy: 0.8475\n",
            "Epoch 61/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8255 - val_loss: 0.3417 - val_accuracy: 0.8559\n",
            "Epoch 62/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8267 - val_loss: 0.3411 - val_accuracy: 0.8644\n",
            "Epoch 63/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8267 - val_loss: 0.3399 - val_accuracy: 0.8644\n",
            "Epoch 64/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8255 - val_loss: 0.3395 - val_accuracy: 0.8644\n",
            "Epoch 65/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.8255 - val_loss: 0.3397 - val_accuracy: 0.8559\n",
            "Epoch 66/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8267 - val_loss: 0.3393 - val_accuracy: 0.8559\n",
            "Epoch 67/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8219 - val_loss: 0.3392 - val_accuracy: 0.8559\n",
            "Epoch 68/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8255 - val_loss: 0.3387 - val_accuracy: 0.8559\n",
            "Epoch 69/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8290 - val_loss: 0.3376 - val_accuracy: 0.8559\n",
            "Epoch 70/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8267 - val_loss: 0.3370 - val_accuracy: 0.8559\n",
            "Epoch 71/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8278 - val_loss: 0.3359 - val_accuracy: 0.8559\n",
            "Epoch 72/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8255 - val_loss: 0.3359 - val_accuracy: 0.8644\n",
            "Epoch 73/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8278 - val_loss: 0.3352 - val_accuracy: 0.8644\n",
            "Epoch 74/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8278 - val_loss: 0.3348 - val_accuracy: 0.8644\n",
            "Epoch 75/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8278 - val_loss: 0.3346 - val_accuracy: 0.8559\n",
            "Epoch 76/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8290 - val_loss: 0.3336 - val_accuracy: 0.8644\n",
            "Epoch 77/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8267 - val_loss: 0.3328 - val_accuracy: 0.8644\n",
            "Epoch 78/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8290 - val_loss: 0.3339 - val_accuracy: 0.8390\n",
            "Epoch 79/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8290 - val_loss: 0.3327 - val_accuracy: 0.8475\n",
            "Epoch 80/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8290 - val_loss: 0.3320 - val_accuracy: 0.8390\n",
            "Epoch 81/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8314 - val_loss: 0.3313 - val_accuracy: 0.8644\n",
            "Epoch 82/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8290 - val_loss: 0.3317 - val_accuracy: 0.8475\n",
            "Epoch 83/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3950 - accuracy: 0.8267 - val_loss: 0.3317 - val_accuracy: 0.8644\n",
            "Epoch 84/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8290 - val_loss: 0.3300 - val_accuracy: 0.8644\n",
            "Epoch 85/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8314 - val_loss: 0.3305 - val_accuracy: 0.8390\n",
            "Epoch 86/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8314 - val_loss: 0.3312 - val_accuracy: 0.8390\n",
            "Epoch 87/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8337 - val_loss: 0.3299 - val_accuracy: 0.8475\n",
            "Epoch 88/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8278 - val_loss: 0.3277 - val_accuracy: 0.8475\n",
            "Epoch 89/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8325 - val_loss: 0.3285 - val_accuracy: 0.8475\n",
            "Epoch 90/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8314 - val_loss: 0.3283 - val_accuracy: 0.8475\n",
            "Epoch 91/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8290 - val_loss: 0.3269 - val_accuracy: 0.8559\n",
            "Epoch 92/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8314 - val_loss: 0.3271 - val_accuracy: 0.8559\n",
            "Epoch 93/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8349 - val_loss: 0.3262 - val_accuracy: 0.8559\n",
            "Epoch 94/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8314 - val_loss: 0.3263 - val_accuracy: 0.8475\n",
            "Epoch 95/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8325 - val_loss: 0.3245 - val_accuracy: 0.8475\n",
            "Epoch 96/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8302 - val_loss: 0.3262 - val_accuracy: 0.8475\n",
            "Epoch 97/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8290 - val_loss: 0.3252 - val_accuracy: 0.8559\n",
            "Epoch 98/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8337 - val_loss: 0.3257 - val_accuracy: 0.8559\n",
            "Epoch 99/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8314 - val_loss: 0.3248 - val_accuracy: 0.8559\n",
            "Epoch 100/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8314 - val_loss: 0.3242 - val_accuracy: 0.8559\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Epoch 1/100\n",
            "43/43 [==============================] - 1s 12ms/step - loss: 0.7197 - accuracy: 0.4222 - val_loss: 0.7011 - val_accuracy: 0.4915\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6749 - accuracy: 0.5979 - val_loss: 0.6620 - val_accuracy: 0.6610\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6437 - accuracy: 0.7017 - val_loss: 0.6322 - val_accuracy: 0.7542\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6185 - accuracy: 0.7311 - val_loss: 0.6076 - val_accuracy: 0.7797\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5965 - accuracy: 0.7547 - val_loss: 0.5829 - val_accuracy: 0.7712\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5761 - accuracy: 0.7642 - val_loss: 0.5595 - val_accuracy: 0.7797\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5568 - accuracy: 0.7748 - val_loss: 0.5364 - val_accuracy: 0.7966\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5388 - accuracy: 0.7842 - val_loss: 0.5145 - val_accuracy: 0.7966\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5222 - accuracy: 0.7854 - val_loss: 0.4947 - val_accuracy: 0.8051\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5078 - accuracy: 0.7913 - val_loss: 0.4769 - val_accuracy: 0.8305\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7936 - val_loss: 0.4615 - val_accuracy: 0.8220\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7972 - val_loss: 0.4481 - val_accuracy: 0.8390\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.8054 - val_loss: 0.4370 - val_accuracy: 0.8305\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4713 - accuracy: 0.8066 - val_loss: 0.4282 - val_accuracy: 0.8305\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4662 - accuracy: 0.8031 - val_loss: 0.4199 - val_accuracy: 0.8220\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.8042 - val_loss: 0.4137 - val_accuracy: 0.8305\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.8042 - val_loss: 0.4077 - val_accuracy: 0.8305\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.8078 - val_loss: 0.4027 - val_accuracy: 0.8305\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.8066 - val_loss: 0.3977 - val_accuracy: 0.8305\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.8090 - val_loss: 0.3935 - val_accuracy: 0.8390\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.8101 - val_loss: 0.3890 - val_accuracy: 0.8305\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4449 - accuracy: 0.8078 - val_loss: 0.3861 - val_accuracy: 0.8390\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.8101 - val_loss: 0.3829 - val_accuracy: 0.8475\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.8101 - val_loss: 0.3799 - val_accuracy: 0.8475\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.8125 - val_loss: 0.3775 - val_accuracy: 0.8475\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4379 - accuracy: 0.8101 - val_loss: 0.3737 - val_accuracy: 0.8559\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.8113 - val_loss: 0.3718 - val_accuracy: 0.8559\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.8125 - val_loss: 0.3706 - val_accuracy: 0.8475\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4334 - accuracy: 0.8113 - val_loss: 0.3676 - val_accuracy: 0.8475\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4320 - accuracy: 0.8125 - val_loss: 0.3660 - val_accuracy: 0.8559\n",
            "Epoch 31/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4309 - accuracy: 0.8125 - val_loss: 0.3649 - val_accuracy: 0.8475\n",
            "Epoch 32/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.8137 - val_loss: 0.3633 - val_accuracy: 0.8475\n",
            "Epoch 33/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4285 - accuracy: 0.8137 - val_loss: 0.3625 - val_accuracy: 0.8390\n",
            "Epoch 34/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.8149 - val_loss: 0.3607 - val_accuracy: 0.8475\n",
            "Epoch 35/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.8160 - val_loss: 0.3607 - val_accuracy: 0.8475\n",
            "Epoch 36/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.8149 - val_loss: 0.3587 - val_accuracy: 0.8475\n",
            "Epoch 37/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.8196 - val_loss: 0.3582 - val_accuracy: 0.8559\n",
            "Epoch 38/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8219 - val_loss: 0.3572 - val_accuracy: 0.8644\n",
            "Epoch 39/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.8172 - val_loss: 0.3559 - val_accuracy: 0.8475\n",
            "Epoch 40/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8196 - val_loss: 0.3556 - val_accuracy: 0.8559\n",
            "Epoch 41/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8196 - val_loss: 0.3542 - val_accuracy: 0.8559\n",
            "Epoch 42/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.8231 - val_loss: 0.3533 - val_accuracy: 0.8475\n",
            "Epoch 43/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4187 - accuracy: 0.8243 - val_loss: 0.3520 - val_accuracy: 0.8559\n",
            "Epoch 44/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.8255 - val_loss: 0.3521 - val_accuracy: 0.8559\n",
            "Epoch 45/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8255 - val_loss: 0.3511 - val_accuracy: 0.8644\n",
            "Epoch 46/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8278 - val_loss: 0.3495 - val_accuracy: 0.8644\n",
            "Epoch 47/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8302 - val_loss: 0.3487 - val_accuracy: 0.8644\n",
            "Epoch 48/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8290 - val_loss: 0.3485 - val_accuracy: 0.8644\n",
            "Epoch 49/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8290 - val_loss: 0.3467 - val_accuracy: 0.8729\n",
            "Epoch 50/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8314 - val_loss: 0.3472 - val_accuracy: 0.8644\n",
            "Epoch 51/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8314 - val_loss: 0.3466 - val_accuracy: 0.8559\n",
            "Epoch 52/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8302 - val_loss: 0.3471 - val_accuracy: 0.8559\n",
            "Epoch 53/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8302 - val_loss: 0.3471 - val_accuracy: 0.8644\n",
            "Epoch 54/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8267 - val_loss: 0.3456 - val_accuracy: 0.8644\n",
            "Epoch 55/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8290 - val_loss: 0.3442 - val_accuracy: 0.8559\n",
            "Epoch 56/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.8243 - val_loss: 0.3448 - val_accuracy: 0.8644\n",
            "Epoch 57/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8290 - val_loss: 0.3439 - val_accuracy: 0.8559\n",
            "Epoch 58/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8290 - val_loss: 0.3450 - val_accuracy: 0.8559\n",
            "Epoch 59/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8314 - val_loss: 0.3435 - val_accuracy: 0.8559\n",
            "Epoch 60/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8290 - val_loss: 0.3439 - val_accuracy: 0.8559\n",
            "Epoch 61/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8302 - val_loss: 0.3441 - val_accuracy: 0.8559\n",
            "Epoch 62/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8302 - val_loss: 0.3436 - val_accuracy: 0.8559\n",
            "Epoch 63/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8290 - val_loss: 0.3431 - val_accuracy: 0.8559\n",
            "Epoch 64/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4056 - accuracy: 0.8314 - val_loss: 0.3424 - val_accuracy: 0.8559\n",
            "Epoch 65/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8302 - val_loss: 0.3416 - val_accuracy: 0.8559\n",
            "Epoch 66/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.8325 - val_loss: 0.3421 - val_accuracy: 0.8559\n",
            "Epoch 67/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8302 - val_loss: 0.3417 - val_accuracy: 0.8559\n",
            "Epoch 68/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8314 - val_loss: 0.3413 - val_accuracy: 0.8559\n",
            "Epoch 69/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8337 - val_loss: 0.3413 - val_accuracy: 0.8559\n",
            "Epoch 70/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8361 - val_loss: 0.3419 - val_accuracy: 0.8475\n",
            "Epoch 71/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8314 - val_loss: 0.3413 - val_accuracy: 0.8475\n",
            "Epoch 72/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8361 - val_loss: 0.3396 - val_accuracy: 0.8559\n",
            "Epoch 73/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8325 - val_loss: 0.3397 - val_accuracy: 0.8475\n",
            "Epoch 74/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8337 - val_loss: 0.3402 - val_accuracy: 0.8559\n",
            "Epoch 75/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8361 - val_loss: 0.3387 - val_accuracy: 0.8559\n",
            "Epoch 76/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8373 - val_loss: 0.3401 - val_accuracy: 0.8475\n",
            "Epoch 77/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8373 - val_loss: 0.3398 - val_accuracy: 0.8390\n",
            "Epoch 78/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8361 - val_loss: 0.3398 - val_accuracy: 0.8559\n",
            "Epoch 79/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8373 - val_loss: 0.3404 - val_accuracy: 0.8390\n",
            "Epoch 80/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8384 - val_loss: 0.3389 - val_accuracy: 0.8305\n",
            "Epoch 81/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8361 - val_loss: 0.3399 - val_accuracy: 0.8390\n",
            "Epoch 82/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8373 - val_loss: 0.3398 - val_accuracy: 0.8475\n",
            "Epoch 83/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8373 - val_loss: 0.3390 - val_accuracy: 0.8305\n",
            "Epoch 84/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8361 - val_loss: 0.3393 - val_accuracy: 0.8390\n",
            "Epoch 85/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8396 - val_loss: 0.3386 - val_accuracy: 0.8305\n",
            "Epoch 86/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8361 - val_loss: 0.3391 - val_accuracy: 0.8305\n",
            "Epoch 87/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8361 - val_loss: 0.3386 - val_accuracy: 0.8390\n",
            "Epoch 88/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8349 - val_loss: 0.3394 - val_accuracy: 0.8390\n",
            "Epoch 89/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8384 - val_loss: 0.3392 - val_accuracy: 0.8305\n",
            "Epoch 90/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8384 - val_loss: 0.3389 - val_accuracy: 0.8305\n",
            "Epoch 91/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8396 - val_loss: 0.3384 - val_accuracy: 0.8390\n",
            "Epoch 92/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8384 - val_loss: 0.3391 - val_accuracy: 0.8305\n",
            "Epoch 93/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8396 - val_loss: 0.3391 - val_accuracy: 0.8390\n",
            "Epoch 94/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8373 - val_loss: 0.3400 - val_accuracy: 0.8390\n",
            "Epoch 95/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8396 - val_loss: 0.3393 - val_accuracy: 0.8390\n",
            "Epoch 96/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8443 - val_loss: 0.3409 - val_accuracy: 0.8305\n",
            "Epoch 97/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3914 - accuracy: 0.8384 - val_loss: 0.3402 - val_accuracy: 0.8390\n",
            "Epoch 98/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8373 - val_loss: 0.3399 - val_accuracy: 0.8305\n",
            "Epoch 99/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8384 - val_loss: 0.3396 - val_accuracy: 0.8220\n",
            "Epoch 100/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8396 - val_loss: 0.3410 - val_accuracy: 0.8475\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/100\n",
            "43/43 [==============================] - 1s 12ms/step - loss: 0.7667 - accuracy: 0.6167 - val_loss: 0.7471 - val_accuracy: 0.6102\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.7214 - accuracy: 0.6167 - val_loss: 0.7036 - val_accuracy: 0.6102\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6862 - accuracy: 0.6167 - val_loss: 0.6721 - val_accuracy: 0.6102\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6590 - accuracy: 0.6167 - val_loss: 0.6441 - val_accuracy: 0.6102\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6351 - accuracy: 0.6167 - val_loss: 0.6173 - val_accuracy: 0.6102\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6133 - accuracy: 0.6167 - val_loss: 0.5921 - val_accuracy: 0.6102\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5926 - accuracy: 0.6238 - val_loss: 0.5688 - val_accuracy: 0.6356\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5732 - accuracy: 0.6651 - val_loss: 0.5466 - val_accuracy: 0.7119\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5556 - accuracy: 0.7193 - val_loss: 0.5268 - val_accuracy: 0.7627\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5401 - accuracy: 0.7606 - val_loss: 0.5088 - val_accuracy: 0.8051\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5267 - accuracy: 0.7795 - val_loss: 0.4944 - val_accuracy: 0.8051\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5157 - accuracy: 0.7889 - val_loss: 0.4801 - val_accuracy: 0.8305\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5064 - accuracy: 0.8019 - val_loss: 0.4695 - val_accuracy: 0.8559\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4984 - accuracy: 0.8078 - val_loss: 0.4599 - val_accuracy: 0.8559\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.8113 - val_loss: 0.4508 - val_accuracy: 0.8475\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.8090 - val_loss: 0.4438 - val_accuracy: 0.8475\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4803 - accuracy: 0.8042 - val_loss: 0.4373 - val_accuracy: 0.8390\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.8066 - val_loss: 0.4322 - val_accuracy: 0.8390\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.8031 - val_loss: 0.4275 - val_accuracy: 0.8390\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.8031 - val_loss: 0.4235 - val_accuracy: 0.8475\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.8066 - val_loss: 0.4186 - val_accuracy: 0.8559\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4630 - accuracy: 0.8078 - val_loss: 0.4152 - val_accuracy: 0.8475\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4605 - accuracy: 0.8066 - val_loss: 0.4115 - val_accuracy: 0.8475\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.8090 - val_loss: 0.4084 - val_accuracy: 0.8475\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.8090 - val_loss: 0.4055 - val_accuracy: 0.8390\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.8090 - val_loss: 0.4025 - val_accuracy: 0.8390\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.8101 - val_loss: 0.3994 - val_accuracy: 0.8390\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.8125 - val_loss: 0.3968 - val_accuracy: 0.8475\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.8113 - val_loss: 0.3942 - val_accuracy: 0.8475\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.8137 - val_loss: 0.3920 - val_accuracy: 0.8390\n",
            "Epoch 31/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4463 - accuracy: 0.8125 - val_loss: 0.3905 - val_accuracy: 0.8390\n",
            "Epoch 32/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.8125 - val_loss: 0.3886 - val_accuracy: 0.8390\n",
            "Epoch 33/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.8125 - val_loss: 0.3871 - val_accuracy: 0.8305\n",
            "Epoch 34/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.8125 - val_loss: 0.3857 - val_accuracy: 0.8475\n",
            "Epoch 35/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.8125 - val_loss: 0.3837 - val_accuracy: 0.8305\n",
            "Epoch 36/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.8137 - val_loss: 0.3831 - val_accuracy: 0.8475\n",
            "Epoch 37/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.8160 - val_loss: 0.3824 - val_accuracy: 0.8305\n",
            "Epoch 38/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.8137 - val_loss: 0.3803 - val_accuracy: 0.8390\n",
            "Epoch 39/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.8172 - val_loss: 0.3786 - val_accuracy: 0.8390\n",
            "Epoch 40/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.8160 - val_loss: 0.3780 - val_accuracy: 0.8475\n",
            "Epoch 41/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4342 - accuracy: 0.8149 - val_loss: 0.3758 - val_accuracy: 0.8390\n",
            "Epoch 42/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.8149 - val_loss: 0.3751 - val_accuracy: 0.8475\n",
            "Epoch 43/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.8172 - val_loss: 0.3725 - val_accuracy: 0.8559\n",
            "Epoch 44/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.8184 - val_loss: 0.3718 - val_accuracy: 0.8559\n",
            "Epoch 45/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.8208 - val_loss: 0.3707 - val_accuracy: 0.8559\n",
            "Epoch 46/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.8208 - val_loss: 0.3688 - val_accuracy: 0.8559\n",
            "Epoch 47/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.8219 - val_loss: 0.3677 - val_accuracy: 0.8559\n",
            "Epoch 48/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.8196 - val_loss: 0.3664 - val_accuracy: 0.8559\n",
            "Epoch 49/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4259 - accuracy: 0.8196 - val_loss: 0.3655 - val_accuracy: 0.8559\n",
            "Epoch 50/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4247 - accuracy: 0.8219 - val_loss: 0.3633 - val_accuracy: 0.8559\n",
            "Epoch 51/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.8196 - val_loss: 0.3625 - val_accuracy: 0.8644\n",
            "Epoch 52/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.8219 - val_loss: 0.3604 - val_accuracy: 0.8644\n",
            "Epoch 53/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.8208 - val_loss: 0.3602 - val_accuracy: 0.8729\n",
            "Epoch 54/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8243 - val_loss: 0.3584 - val_accuracy: 0.8644\n",
            "Epoch 55/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.8255 - val_loss: 0.3561 - val_accuracy: 0.8729\n",
            "Epoch 56/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8219 - val_loss: 0.3561 - val_accuracy: 0.8729\n",
            "Epoch 57/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8255 - val_loss: 0.3539 - val_accuracy: 0.8729\n",
            "Epoch 58/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8231 - val_loss: 0.3538 - val_accuracy: 0.8729\n",
            "Epoch 59/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8219 - val_loss: 0.3520 - val_accuracy: 0.8729\n",
            "Epoch 60/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8231 - val_loss: 0.3507 - val_accuracy: 0.8644\n",
            "Epoch 61/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8255 - val_loss: 0.3509 - val_accuracy: 0.8644\n",
            "Epoch 62/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8219 - val_loss: 0.3490 - val_accuracy: 0.8644\n",
            "Epoch 63/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8267 - val_loss: 0.3482 - val_accuracy: 0.8729\n",
            "Epoch 64/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8255 - val_loss: 0.3475 - val_accuracy: 0.8644\n",
            "Epoch 65/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8231 - val_loss: 0.3475 - val_accuracy: 0.8729\n",
            "Epoch 66/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8243 - val_loss: 0.3464 - val_accuracy: 0.8644\n",
            "Epoch 67/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8267 - val_loss: 0.3452 - val_accuracy: 0.8729\n",
            "Epoch 68/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8231 - val_loss: 0.3449 - val_accuracy: 0.8729\n",
            "Epoch 69/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8255 - val_loss: 0.3432 - val_accuracy: 0.8729\n",
            "Epoch 70/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8231 - val_loss: 0.3436 - val_accuracy: 0.8729\n",
            "Epoch 71/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4079 - accuracy: 0.8267 - val_loss: 0.3426 - val_accuracy: 0.8729\n",
            "Epoch 72/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8267 - val_loss: 0.3420 - val_accuracy: 0.8729\n",
            "Epoch 73/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8290 - val_loss: 0.3414 - val_accuracy: 0.8729\n",
            "Epoch 74/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8290 - val_loss: 0.3408 - val_accuracy: 0.8814\n",
            "Epoch 75/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4058 - accuracy: 0.8302 - val_loss: 0.3399 - val_accuracy: 0.8814\n",
            "Epoch 76/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8255 - val_loss: 0.3402 - val_accuracy: 0.8729\n",
            "Epoch 77/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8278 - val_loss: 0.3389 - val_accuracy: 0.8644\n",
            "Epoch 78/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8243 - val_loss: 0.3392 - val_accuracy: 0.8729\n",
            "Epoch 79/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8208 - val_loss: 0.3386 - val_accuracy: 0.8729\n",
            "Epoch 80/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8208 - val_loss: 0.3385 - val_accuracy: 0.8729\n",
            "Epoch 81/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8231 - val_loss: 0.3385 - val_accuracy: 0.8644\n",
            "Epoch 82/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8255 - val_loss: 0.3372 - val_accuracy: 0.8729\n",
            "Epoch 83/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8219 - val_loss: 0.3381 - val_accuracy: 0.8644\n",
            "Epoch 84/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8243 - val_loss: 0.3377 - val_accuracy: 0.8644\n",
            "Epoch 85/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8208 - val_loss: 0.3381 - val_accuracy: 0.8644\n",
            "Epoch 86/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8255 - val_loss: 0.3374 - val_accuracy: 0.8644\n",
            "Epoch 87/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8219 - val_loss: 0.3389 - val_accuracy: 0.8644\n",
            "Epoch 88/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8208 - val_loss: 0.3369 - val_accuracy: 0.8644\n",
            "Epoch 89/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8243 - val_loss: 0.3359 - val_accuracy: 0.8644\n",
            "Epoch 90/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8208 - val_loss: 0.3362 - val_accuracy: 0.8644\n",
            "Epoch 91/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8255 - val_loss: 0.3371 - val_accuracy: 0.8644\n",
            "Epoch 92/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8231 - val_loss: 0.3349 - val_accuracy: 0.8644\n",
            "Epoch 93/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8267 - val_loss: 0.3386 - val_accuracy: 0.8644\n",
            "Epoch 94/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8231 - val_loss: 0.3371 - val_accuracy: 0.8644\n",
            "Epoch 95/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8267 - val_loss: 0.3389 - val_accuracy: 0.8644\n",
            "Epoch 96/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8196 - val_loss: 0.3381 - val_accuracy: 0.8644\n",
            "Epoch 97/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8231 - val_loss: 0.3370 - val_accuracy: 0.8644\n",
            "Epoch 98/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8278 - val_loss: 0.3368 - val_accuracy: 0.8729\n",
            "Epoch 99/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8255 - val_loss: 0.3357 - val_accuracy: 0.8644\n",
            "Epoch 100/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8255 - val_loss: 0.3371 - val_accuracy: 0.8644\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Epoch 1/100\n",
            "43/43 [==============================] - 1s 12ms/step - loss: 0.6605 - accuracy: 0.6002 - val_loss: 0.6468 - val_accuracy: 0.6695\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.6378 - accuracy: 0.6521 - val_loss: 0.6239 - val_accuracy: 0.6949\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6166 - accuracy: 0.6875 - val_loss: 0.6002 - val_accuracy: 0.7034\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5955 - accuracy: 0.7158 - val_loss: 0.5754 - val_accuracy: 0.7797\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5749 - accuracy: 0.7642 - val_loss: 0.5517 - val_accuracy: 0.7966\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5562 - accuracy: 0.7677 - val_loss: 0.5298 - val_accuracy: 0.8136\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5390 - accuracy: 0.7901 - val_loss: 0.5096 - val_accuracy: 0.8305\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.8031 - val_loss: 0.4920 - val_accuracy: 0.8220\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5123 - accuracy: 0.8054 - val_loss: 0.4782 - val_accuracy: 0.8220\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5022 - accuracy: 0.8054 - val_loss: 0.4652 - val_accuracy: 0.8390\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.8031 - val_loss: 0.4546 - val_accuracy: 0.8305\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4865 - accuracy: 0.8007 - val_loss: 0.4462 - val_accuracy: 0.8305\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.7995 - val_loss: 0.4369 - val_accuracy: 0.8305\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4750 - accuracy: 0.7995 - val_loss: 0.4307 - val_accuracy: 0.8305\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.8054 - val_loss: 0.4246 - val_accuracy: 0.8390\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.8019 - val_loss: 0.4196 - val_accuracy: 0.8390\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.8031 - val_loss: 0.4150 - val_accuracy: 0.8559\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.8042 - val_loss: 0.4107 - val_accuracy: 0.8559\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.8078 - val_loss: 0.4078 - val_accuracy: 0.8644\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.8090 - val_loss: 0.4039 - val_accuracy: 0.8644\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.8101 - val_loss: 0.4012 - val_accuracy: 0.8559\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.8090 - val_loss: 0.3980 - val_accuracy: 0.8644\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.8137 - val_loss: 0.3955 - val_accuracy: 0.8390\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.8101 - val_loss: 0.3925 - val_accuracy: 0.8390\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.8125 - val_loss: 0.3898 - val_accuracy: 0.8475\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.8149 - val_loss: 0.3875 - val_accuracy: 0.8390\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.8113 - val_loss: 0.3859 - val_accuracy: 0.8390\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.8149 - val_loss: 0.3834 - val_accuracy: 0.8475\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4395 - accuracy: 0.8160 - val_loss: 0.3818 - val_accuracy: 0.8390\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4380 - accuracy: 0.8160 - val_loss: 0.3801 - val_accuracy: 0.8475\n",
            "Epoch 31/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.8149 - val_loss: 0.3781 - val_accuracy: 0.8390\n",
            "Epoch 32/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.8196 - val_loss: 0.3760 - val_accuracy: 0.8475\n",
            "Epoch 33/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.8160 - val_loss: 0.3749 - val_accuracy: 0.8390\n",
            "Epoch 34/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.8208 - val_loss: 0.3737 - val_accuracy: 0.8220\n",
            "Epoch 35/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4311 - accuracy: 0.8172 - val_loss: 0.3716 - val_accuracy: 0.8305\n",
            "Epoch 36/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.8231 - val_loss: 0.3704 - val_accuracy: 0.8305\n",
            "Epoch 37/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8196 - val_loss: 0.3694 - val_accuracy: 0.8305\n",
            "Epoch 38/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.8243 - val_loss: 0.3694 - val_accuracy: 0.8305\n",
            "Epoch 39/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.8231 - val_loss: 0.3675 - val_accuracy: 0.8390\n",
            "Epoch 40/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8219 - val_loss: 0.3680 - val_accuracy: 0.8305\n",
            "Epoch 41/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8219 - val_loss: 0.3654 - val_accuracy: 0.8305\n",
            "Epoch 42/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.8219 - val_loss: 0.3642 - val_accuracy: 0.8305\n",
            "Epoch 43/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.8219 - val_loss: 0.3628 - val_accuracy: 0.8305\n",
            "Epoch 44/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.8243 - val_loss: 0.3628 - val_accuracy: 0.8390\n",
            "Epoch 45/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4184 - accuracy: 0.8243 - val_loss: 0.3619 - val_accuracy: 0.8305\n",
            "Epoch 46/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8231 - val_loss: 0.3609 - val_accuracy: 0.8305\n",
            "Epoch 47/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8219 - val_loss: 0.3599 - val_accuracy: 0.8305\n",
            "Epoch 48/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8208 - val_loss: 0.3589 - val_accuracy: 0.8305\n",
            "Epoch 49/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8267 - val_loss: 0.3573 - val_accuracy: 0.8305\n",
            "Epoch 50/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8243 - val_loss: 0.3562 - val_accuracy: 0.8220\n",
            "Epoch 51/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8231 - val_loss: 0.3547 - val_accuracy: 0.8220\n",
            "Epoch 52/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8243 - val_loss: 0.3542 - val_accuracy: 0.8220\n",
            "Epoch 53/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8255 - val_loss: 0.3543 - val_accuracy: 0.8305\n",
            "Epoch 54/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8243 - val_loss: 0.3526 - val_accuracy: 0.8305\n",
            "Epoch 55/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8243 - val_loss: 0.3533 - val_accuracy: 0.8220\n",
            "Epoch 56/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.8243 - val_loss: 0.3533 - val_accuracy: 0.8390\n",
            "Epoch 57/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8267 - val_loss: 0.3505 - val_accuracy: 0.8475\n",
            "Epoch 58/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8255 - val_loss: 0.3505 - val_accuracy: 0.8475\n",
            "Epoch 59/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8278 - val_loss: 0.3500 - val_accuracy: 0.8475\n",
            "Epoch 60/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8290 - val_loss: 0.3488 - val_accuracy: 0.8559\n",
            "Epoch 61/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8278 - val_loss: 0.3492 - val_accuracy: 0.8559\n",
            "Epoch 62/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8267 - val_loss: 0.3497 - val_accuracy: 0.8559\n",
            "Epoch 63/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8267 - val_loss: 0.3473 - val_accuracy: 0.8644\n",
            "Epoch 64/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8255 - val_loss: 0.3467 - val_accuracy: 0.8475\n",
            "Epoch 65/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8278 - val_loss: 0.3460 - val_accuracy: 0.8644\n",
            "Epoch 66/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8302 - val_loss: 0.3471 - val_accuracy: 0.8729\n",
            "Epoch 67/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8290 - val_loss: 0.3457 - val_accuracy: 0.8559\n",
            "Epoch 68/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8325 - val_loss: 0.3448 - val_accuracy: 0.8559\n",
            "Epoch 69/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8314 - val_loss: 0.3433 - val_accuracy: 0.8559\n",
            "Epoch 70/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8302 - val_loss: 0.3440 - val_accuracy: 0.8559\n",
            "Epoch 71/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8278 - val_loss: 0.3440 - val_accuracy: 0.8559\n",
            "Epoch 72/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8325 - val_loss: 0.3437 - val_accuracy: 0.8644\n",
            "Epoch 73/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8267 - val_loss: 0.3437 - val_accuracy: 0.8729\n",
            "Epoch 74/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8349 - val_loss: 0.3436 - val_accuracy: 0.8729\n",
            "Epoch 75/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8290 - val_loss: 0.3421 - val_accuracy: 0.8729\n",
            "Epoch 76/100\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.8314 - val_loss: 0.3431 - val_accuracy: 0.8729\n",
            "Epoch 77/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8243 - val_loss: 0.3425 - val_accuracy: 0.8729\n",
            "Epoch 78/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8267 - val_loss: 0.3437 - val_accuracy: 0.8729\n",
            "Epoch 79/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8314 - val_loss: 0.3414 - val_accuracy: 0.8644\n",
            "Epoch 80/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8337 - val_loss: 0.3405 - val_accuracy: 0.8729\n",
            "Epoch 81/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8290 - val_loss: 0.3429 - val_accuracy: 0.8729\n",
            "Epoch 82/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8302 - val_loss: 0.3408 - val_accuracy: 0.8729\n",
            "Epoch 83/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8314 - val_loss: 0.3400 - val_accuracy: 0.8644\n",
            "Epoch 84/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8278 - val_loss: 0.3417 - val_accuracy: 0.8729\n",
            "Epoch 85/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8325 - val_loss: 0.3402 - val_accuracy: 0.8644\n",
            "Epoch 86/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8278 - val_loss: 0.3407 - val_accuracy: 0.8644\n",
            "Epoch 87/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8302 - val_loss: 0.3406 - val_accuracy: 0.8644\n",
            "Epoch 88/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8290 - val_loss: 0.3398 - val_accuracy: 0.8644\n",
            "Epoch 89/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8267 - val_loss: 0.3400 - val_accuracy: 0.8559\n",
            "Epoch 90/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8302 - val_loss: 0.3397 - val_accuracy: 0.8644\n",
            "Epoch 91/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.8314 - val_loss: 0.3404 - val_accuracy: 0.8644\n",
            "Epoch 92/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.8325 - val_loss: 0.3384 - val_accuracy: 0.8644\n",
            "Epoch 93/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3905 - accuracy: 0.8267 - val_loss: 0.3402 - val_accuracy: 0.8644\n",
            "Epoch 94/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8302 - val_loss: 0.3392 - val_accuracy: 0.8644\n",
            "Epoch 95/100\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8302 - val_loss: 0.3388 - val_accuracy: 0.8644\n",
            "Epoch 96/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8290 - val_loss: 0.3387 - val_accuracy: 0.8644\n",
            "Epoch 97/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.8278 - val_loss: 0.3379 - val_accuracy: 0.8644\n",
            "Epoch 98/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8302 - val_loss: 0.3380 - val_accuracy: 0.8644\n",
            "Epoch 99/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.8302 - val_loss: 0.3383 - val_accuracy: 0.8644\n",
            "Epoch 100/100\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.8314 - val_loss: 0.3392 - val_accuracy: 0.8644\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 1s 14ms/step - loss: 0.6553 - accuracy: 0.6038 - val_loss: 0.6434 - val_accuracy: 0.6017\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6373 - accuracy: 0.6108 - val_loss: 0.6258 - val_accuracy: 0.6441\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.6219 - accuracy: 0.6474 - val_loss: 0.6076 - val_accuracy: 0.6695\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.6067 - accuracy: 0.7028 - val_loss: 0.5897 - val_accuracy: 0.7119\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5920 - accuracy: 0.7252 - val_loss: 0.5702 - val_accuracy: 0.7542\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5774 - accuracy: 0.7441 - val_loss: 0.5514 - val_accuracy: 0.7627\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5631 - accuracy: 0.7583 - val_loss: 0.5333 - val_accuracy: 0.7881\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5495 - accuracy: 0.7712 - val_loss: 0.5155 - val_accuracy: 0.8136\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5362 - accuracy: 0.7783 - val_loss: 0.4989 - val_accuracy: 0.8305\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.7866 - val_loss: 0.4846 - val_accuracy: 0.8390\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5136 - accuracy: 0.7877 - val_loss: 0.4724 - val_accuracy: 0.8390\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5052 - accuracy: 0.7913 - val_loss: 0.4619 - val_accuracy: 0.8559\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4980 - accuracy: 0.8007 - val_loss: 0.4527 - val_accuracy: 0.8475\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4914 - accuracy: 0.8019 - val_loss: 0.4447 - val_accuracy: 0.8390\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.8042 - val_loss: 0.4376 - val_accuracy: 0.8475\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4806 - accuracy: 0.8090 - val_loss: 0.4319 - val_accuracy: 0.8475\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.8113 - val_loss: 0.4271 - val_accuracy: 0.8559\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.8090 - val_loss: 0.4214 - val_accuracy: 0.8559\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.8054 - val_loss: 0.4176 - val_accuracy: 0.8559\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.8101 - val_loss: 0.4142 - val_accuracy: 0.8559\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.8113 - val_loss: 0.4101 - val_accuracy: 0.8559\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.8125 - val_loss: 0.4060 - val_accuracy: 0.8475\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.8160 - val_loss: 0.4025 - val_accuracy: 0.8475\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.8149 - val_loss: 0.3999 - val_accuracy: 0.8475\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.8184 - val_loss: 0.3974 - val_accuracy: 0.8475\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4498 - accuracy: 0.8160 - val_loss: 0.3946 - val_accuracy: 0.8475\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4479 - accuracy: 0.8196 - val_loss: 0.3924 - val_accuracy: 0.8475\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.8196 - val_loss: 0.3895 - val_accuracy: 0.8475\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.8172 - val_loss: 0.3882 - val_accuracy: 0.8475\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.8172 - val_loss: 0.3846 - val_accuracy: 0.8559\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.8184 - val_loss: 0.3830 - val_accuracy: 0.8559\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.8196 - val_loss: 0.3818 - val_accuracy: 0.8644\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4370 - accuracy: 0.8208 - val_loss: 0.3790 - val_accuracy: 0.8644\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.8208 - val_loss: 0.3782 - val_accuracy: 0.8644\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.8219 - val_loss: 0.3767 - val_accuracy: 0.8644\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.8243 - val_loss: 0.3738 - val_accuracy: 0.8644\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4309 - accuracy: 0.8243 - val_loss: 0.3732 - val_accuracy: 0.8644\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.8243 - val_loss: 0.3717 - val_accuracy: 0.8729\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.8255 - val_loss: 0.3704 - val_accuracy: 0.8814\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.8243 - val_loss: 0.3682 - val_accuracy: 0.8729\n",
            "Epoch 41/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8278 - val_loss: 0.3668 - val_accuracy: 0.8729\n",
            "Epoch 42/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.8278 - val_loss: 0.3667 - val_accuracy: 0.8644\n",
            "Epoch 43/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.8278 - val_loss: 0.3635 - val_accuracy: 0.8729\n",
            "Epoch 44/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.8290 - val_loss: 0.3634 - val_accuracy: 0.8729\n",
            "Epoch 45/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.8290 - val_loss: 0.3617 - val_accuracy: 0.8729\n",
            "Epoch 46/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.8302 - val_loss: 0.3618 - val_accuracy: 0.8729\n",
            "Epoch 47/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8267 - val_loss: 0.3606 - val_accuracy: 0.8729\n",
            "Epoch 48/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8314 - val_loss: 0.3593 - val_accuracy: 0.8729\n",
            "Epoch 49/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.8314 - val_loss: 0.3595 - val_accuracy: 0.8729\n",
            "Epoch 50/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8302 - val_loss: 0.3584 - val_accuracy: 0.8729\n",
            "Epoch 51/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4150 - accuracy: 0.8302 - val_loss: 0.3566 - val_accuracy: 0.8729\n",
            "Epoch 52/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8325 - val_loss: 0.3548 - val_accuracy: 0.8729\n",
            "Epoch 53/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8267 - val_loss: 0.3547 - val_accuracy: 0.8729\n",
            "Epoch 54/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8314 - val_loss: 0.3542 - val_accuracy: 0.8729\n",
            "Epoch 55/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8290 - val_loss: 0.3511 - val_accuracy: 0.8729\n",
            "Epoch 56/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8278 - val_loss: 0.3506 - val_accuracy: 0.8729\n",
            "Epoch 57/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8337 - val_loss: 0.3493 - val_accuracy: 0.8729\n",
            "Epoch 58/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.8314 - val_loss: 0.3483 - val_accuracy: 0.8729\n",
            "Epoch 59/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.8314 - val_loss: 0.3474 - val_accuracy: 0.8644\n",
            "Epoch 60/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4080 - accuracy: 0.8278 - val_loss: 0.3472 - val_accuracy: 0.8644\n",
            "Epoch 61/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.8314 - val_loss: 0.3451 - val_accuracy: 0.8729\n",
            "Epoch 62/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8278 - val_loss: 0.3451 - val_accuracy: 0.8644\n",
            "Epoch 63/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8290 - val_loss: 0.3446 - val_accuracy: 0.8644\n",
            "Epoch 64/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8349 - val_loss: 0.3410 - val_accuracy: 0.8729\n",
            "Epoch 65/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8302 - val_loss: 0.3406 - val_accuracy: 0.8644\n",
            "Epoch 66/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8349 - val_loss: 0.3411 - val_accuracy: 0.8644\n",
            "Epoch 67/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.8361 - val_loss: 0.3414 - val_accuracy: 0.8644\n",
            "Epoch 68/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8373 - val_loss: 0.3405 - val_accuracy: 0.8644\n",
            "Epoch 69/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4024 - accuracy: 0.8373 - val_loss: 0.3398 - val_accuracy: 0.8644\n",
            "Epoch 70/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8373 - val_loss: 0.3388 - val_accuracy: 0.8814\n",
            "Epoch 71/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8373 - val_loss: 0.3383 - val_accuracy: 0.8644\n",
            "Epoch 72/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8349 - val_loss: 0.3389 - val_accuracy: 0.8644\n",
            "Epoch 73/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8373 - val_loss: 0.3377 - val_accuracy: 0.8644\n",
            "Epoch 74/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8396 - val_loss: 0.3370 - val_accuracy: 0.8729\n",
            "Epoch 75/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8396 - val_loss: 0.3354 - val_accuracy: 0.8729\n",
            "Epoch 76/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8373 - val_loss: 0.3361 - val_accuracy: 0.8729\n",
            "Epoch 77/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8384 - val_loss: 0.3339 - val_accuracy: 0.8729\n",
            "Epoch 78/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8384 - val_loss: 0.3344 - val_accuracy: 0.8729\n",
            "Epoch 79/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8325 - val_loss: 0.3350 - val_accuracy: 0.8729\n",
            "Epoch 80/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8349 - val_loss: 0.3340 - val_accuracy: 0.8729\n",
            "Epoch 81/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8373 - val_loss: 0.3342 - val_accuracy: 0.8729\n",
            "Epoch 82/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8373 - val_loss: 0.3327 - val_accuracy: 0.8729\n",
            "Epoch 83/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8384 - val_loss: 0.3329 - val_accuracy: 0.8729\n",
            "Epoch 84/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8373 - val_loss: 0.3308 - val_accuracy: 0.8729\n",
            "Epoch 85/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8384 - val_loss: 0.3312 - val_accuracy: 0.8729\n",
            "Epoch 86/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8361 - val_loss: 0.3314 - val_accuracy: 0.8729\n",
            "Epoch 87/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8325 - val_loss: 0.3336 - val_accuracy: 0.8729\n",
            "Epoch 88/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8396 - val_loss: 0.3300 - val_accuracy: 0.8729\n",
            "Epoch 89/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8361 - val_loss: 0.3303 - val_accuracy: 0.8729\n",
            "Epoch 90/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8361 - val_loss: 0.3301 - val_accuracy: 0.8729\n",
            "Epoch 91/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8373 - val_loss: 0.3296 - val_accuracy: 0.8729\n",
            "Epoch 92/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8373 - val_loss: 0.3294 - val_accuracy: 0.8729\n",
            "Epoch 93/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8349 - val_loss: 0.3289 - val_accuracy: 0.8729\n",
            "Epoch 94/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3906 - accuracy: 0.8361 - val_loss: 0.3268 - val_accuracy: 0.8729\n",
            "Epoch 95/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.8384 - val_loss: 0.3291 - val_accuracy: 0.8729\n",
            "Epoch 96/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.8373 - val_loss: 0.3279 - val_accuracy: 0.8729\n",
            "Epoch 97/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8373 - val_loss: 0.3277 - val_accuracy: 0.8729\n",
            "Epoch 98/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8384 - val_loss: 0.3284 - val_accuracy: 0.8729\n",
            "Epoch 99/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8420 - val_loss: 0.3280 - val_accuracy: 0.8814\n",
            "Epoch 100/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.8373 - val_loss: 0.3285 - val_accuracy: 0.8814\n",
            "Epoch 101/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8384 - val_loss: 0.3267 - val_accuracy: 0.8814\n",
            "Epoch 102/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8349 - val_loss: 0.3276 - val_accuracy: 0.8814\n",
            "Epoch 103/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3876 - accuracy: 0.8373 - val_loss: 0.3270 - val_accuracy: 0.8814\n",
            "Epoch 104/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3872 - accuracy: 0.8396 - val_loss: 0.3256 - val_accuracy: 0.8729\n",
            "Epoch 105/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8396 - val_loss: 0.3257 - val_accuracy: 0.8814\n",
            "Epoch 106/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8373 - val_loss: 0.3248 - val_accuracy: 0.8729\n",
            "Epoch 107/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3859 - accuracy: 0.8373 - val_loss: 0.3265 - val_accuracy: 0.8814\n",
            "Epoch 108/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.8373 - val_loss: 0.3247 - val_accuracy: 0.8729\n",
            "Epoch 109/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3854 - accuracy: 0.8373 - val_loss: 0.3250 - val_accuracy: 0.8729\n",
            "Epoch 110/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3851 - accuracy: 0.8373 - val_loss: 0.3266 - val_accuracy: 0.8814\n",
            "Epoch 111/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.8373 - val_loss: 0.3243 - val_accuracy: 0.8729\n",
            "Epoch 112/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8384 - val_loss: 0.3240 - val_accuracy: 0.8729\n",
            "Epoch 113/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3840 - accuracy: 0.8408 - val_loss: 0.3251 - val_accuracy: 0.8729\n",
            "Epoch 114/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.8396 - val_loss: 0.3236 - val_accuracy: 0.8729\n",
            "Epoch 115/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8384 - val_loss: 0.3255 - val_accuracy: 0.8729\n",
            "Epoch 116/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8408 - val_loss: 0.3258 - val_accuracy: 0.8644\n",
            "Epoch 117/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.8384 - val_loss: 0.3248 - val_accuracy: 0.8644\n",
            "Epoch 118/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.8408 - val_loss: 0.3246 - val_accuracy: 0.8644\n",
            "Epoch 119/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3830 - accuracy: 0.8396 - val_loss: 0.3235 - val_accuracy: 0.8729\n",
            "Epoch 120/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.8396 - val_loss: 0.3228 - val_accuracy: 0.8729\n",
            "Epoch 121/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3825 - accuracy: 0.8396 - val_loss: 0.3233 - val_accuracy: 0.8644\n",
            "Epoch 122/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.8396 - val_loss: 0.3235 - val_accuracy: 0.8644\n",
            "Epoch 123/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8396 - val_loss: 0.3236 - val_accuracy: 0.8644\n",
            "Epoch 124/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3811 - accuracy: 0.8384 - val_loss: 0.3233 - val_accuracy: 0.8729\n",
            "Epoch 125/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.8384 - val_loss: 0.3229 - val_accuracy: 0.8729\n",
            "Epoch 126/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8384 - val_loss: 0.3229 - val_accuracy: 0.8644\n",
            "Epoch 127/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8432 - val_loss: 0.3219 - val_accuracy: 0.8729\n",
            "Epoch 128/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8361 - val_loss: 0.3228 - val_accuracy: 0.8644\n",
            "Epoch 129/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.8396 - val_loss: 0.3236 - val_accuracy: 0.8644\n",
            "Epoch 130/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.8384 - val_loss: 0.3249 - val_accuracy: 0.8644\n",
            "Epoch 131/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8396 - val_loss: 0.3223 - val_accuracy: 0.8644\n",
            "Epoch 132/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8432 - val_loss: 0.3219 - val_accuracy: 0.8644\n",
            "Epoch 133/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.8408 - val_loss: 0.3222 - val_accuracy: 0.8559\n",
            "Epoch 134/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8396 - val_loss: 0.3213 - val_accuracy: 0.8644\n",
            "Epoch 135/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3785 - accuracy: 0.8384 - val_loss: 0.3224 - val_accuracy: 0.8644\n",
            "Epoch 136/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8384 - val_loss: 0.3213 - val_accuracy: 0.8644\n",
            "Epoch 137/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.8396 - val_loss: 0.3222 - val_accuracy: 0.8559\n",
            "Epoch 138/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8408 - val_loss: 0.3216 - val_accuracy: 0.8644\n",
            "Epoch 139/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8396 - val_loss: 0.3207 - val_accuracy: 0.8559\n",
            "Epoch 140/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8420 - val_loss: 0.3208 - val_accuracy: 0.8559\n",
            "Epoch 141/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8420 - val_loss: 0.3224 - val_accuracy: 0.8644\n",
            "Epoch 142/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8420 - val_loss: 0.3218 - val_accuracy: 0.8559\n",
            "Epoch 143/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8408 - val_loss: 0.3203 - val_accuracy: 0.8559\n",
            "Epoch 144/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.8396 - val_loss: 0.3197 - val_accuracy: 0.8644\n",
            "Epoch 145/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8420 - val_loss: 0.3199 - val_accuracy: 0.8644\n",
            "Epoch 146/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8408 - val_loss: 0.3203 - val_accuracy: 0.8644\n",
            "Epoch 147/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3756 - accuracy: 0.8408 - val_loss: 0.3210 - val_accuracy: 0.8644\n",
            "Epoch 148/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8408 - val_loss: 0.3209 - val_accuracy: 0.8644\n",
            "Epoch 149/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8408 - val_loss: 0.3237 - val_accuracy: 0.8559\n",
            "Epoch 150/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8420 - val_loss: 0.3212 - val_accuracy: 0.8559\n",
            "Epoch 151/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3745 - accuracy: 0.8384 - val_loss: 0.3206 - val_accuracy: 0.8644\n",
            "Epoch 152/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8408 - val_loss: 0.3217 - val_accuracy: 0.8559\n",
            "Epoch 153/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.8420 - val_loss: 0.3208 - val_accuracy: 0.8559\n",
            "Epoch 154/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8384 - val_loss: 0.3202 - val_accuracy: 0.8644\n",
            "Epoch 155/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8420 - val_loss: 0.3204 - val_accuracy: 0.8559\n",
            "Epoch 156/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8420 - val_loss: 0.3217 - val_accuracy: 0.8644\n",
            "Epoch 157/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8408 - val_loss: 0.3220 - val_accuracy: 0.8559\n",
            "Epoch 158/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8408 - val_loss: 0.3195 - val_accuracy: 0.8559\n",
            "Epoch 159/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8432 - val_loss: 0.3223 - val_accuracy: 0.8559\n",
            "Epoch 160/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3730 - accuracy: 0.8420 - val_loss: 0.3215 - val_accuracy: 0.8644\n",
            "Epoch 161/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8420 - val_loss: 0.3216 - val_accuracy: 0.8559\n",
            "Epoch 162/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8443 - val_loss: 0.3210 - val_accuracy: 0.8559\n",
            "Epoch 163/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8420 - val_loss: 0.3214 - val_accuracy: 0.8559\n",
            "Epoch 164/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.8408 - val_loss: 0.3203 - val_accuracy: 0.8559\n",
            "Epoch 165/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8420 - val_loss: 0.3201 - val_accuracy: 0.8644\n",
            "Epoch 166/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8420 - val_loss: 0.3197 - val_accuracy: 0.8559\n",
            "Epoch 167/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8408 - val_loss: 0.3221 - val_accuracy: 0.8559\n",
            "Epoch 168/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3710 - accuracy: 0.8384 - val_loss: 0.3197 - val_accuracy: 0.8729\n",
            "Epoch 169/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3703 - accuracy: 0.8396 - val_loss: 0.3191 - val_accuracy: 0.8729\n",
            "Epoch 170/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3705 - accuracy: 0.8443 - val_loss: 0.3211 - val_accuracy: 0.8559\n",
            "Epoch 171/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3699 - accuracy: 0.8408 - val_loss: 0.3221 - val_accuracy: 0.8644\n",
            "Epoch 172/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3695 - accuracy: 0.8408 - val_loss: 0.3208 - val_accuracy: 0.8729\n",
            "Epoch 173/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8420 - val_loss: 0.3210 - val_accuracy: 0.8559\n",
            "Epoch 174/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 0.8420 - val_loss: 0.3210 - val_accuracy: 0.8644\n",
            "Epoch 175/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3689 - accuracy: 0.8408 - val_loss: 0.3227 - val_accuracy: 0.8644\n",
            "Epoch 176/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8396 - val_loss: 0.3211 - val_accuracy: 0.8644\n",
            "Epoch 177/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8384 - val_loss: 0.3212 - val_accuracy: 0.8644\n",
            "Epoch 178/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3683 - accuracy: 0.8432 - val_loss: 0.3218 - val_accuracy: 0.8644\n",
            "Epoch 179/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8420 - val_loss: 0.3202 - val_accuracy: 0.8644\n",
            "Epoch 180/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8408 - val_loss: 0.3224 - val_accuracy: 0.8644\n",
            "Epoch 181/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8408 - val_loss: 0.3226 - val_accuracy: 0.8644\n",
            "Epoch 182/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8396 - val_loss: 0.3221 - val_accuracy: 0.8644\n",
            "Epoch 183/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8408 - val_loss: 0.3206 - val_accuracy: 0.8644\n",
            "Epoch 184/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.8408 - val_loss: 0.3205 - val_accuracy: 0.8644\n",
            "Epoch 185/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3677 - accuracy: 0.8408 - val_loss: 0.3198 - val_accuracy: 0.8729\n",
            "Epoch 186/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8396 - val_loss: 0.3245 - val_accuracy: 0.8559\n",
            "Epoch 187/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3669 - accuracy: 0.8408 - val_loss: 0.3218 - val_accuracy: 0.8644\n",
            "Epoch 188/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8408 - val_loss: 0.3215 - val_accuracy: 0.8729\n",
            "Epoch 189/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8420 - val_loss: 0.3234 - val_accuracy: 0.8559\n",
            "Epoch 190/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8408 - val_loss: 0.3204 - val_accuracy: 0.8729\n",
            "Epoch 191/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.8408 - val_loss: 0.3216 - val_accuracy: 0.8559\n",
            "Epoch 192/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3655 - accuracy: 0.8408 - val_loss: 0.3206 - val_accuracy: 0.8644\n",
            "Epoch 193/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8420 - val_loss: 0.3232 - val_accuracy: 0.8559\n",
            "Epoch 194/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3653 - accuracy: 0.8420 - val_loss: 0.3221 - val_accuracy: 0.8559\n",
            "Epoch 195/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3649 - accuracy: 0.8396 - val_loss: 0.3208 - val_accuracy: 0.8559\n",
            "Epoch 196/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8384 - val_loss: 0.3230 - val_accuracy: 0.8644\n",
            "Epoch 197/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8420 - val_loss: 0.3208 - val_accuracy: 0.8729\n",
            "Epoch 198/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8396 - val_loss: 0.3208 - val_accuracy: 0.8644\n",
            "Epoch 199/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3645 - accuracy: 0.8408 - val_loss: 0.3220 - val_accuracy: 0.8644\n",
            "Epoch 200/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3645 - accuracy: 0.8420 - val_loss: 0.3201 - val_accuracy: 0.8729\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 1s 11ms/step - loss: 0.7005 - accuracy: 0.4658 - val_loss: 0.6768 - val_accuracy: 0.5932\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6608 - accuracy: 0.6521 - val_loss: 0.6449 - val_accuracy: 0.7542\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6332 - accuracy: 0.7700 - val_loss: 0.6207 - val_accuracy: 0.7881\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6108 - accuracy: 0.7748 - val_loss: 0.5989 - val_accuracy: 0.8051\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5914 - accuracy: 0.7818 - val_loss: 0.5786 - val_accuracy: 0.8051\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5734 - accuracy: 0.7877 - val_loss: 0.5591 - val_accuracy: 0.8136\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5567 - accuracy: 0.7960 - val_loss: 0.5400 - val_accuracy: 0.8220\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5412 - accuracy: 0.7936 - val_loss: 0.5224 - val_accuracy: 0.8305\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5274 - accuracy: 0.7960 - val_loss: 0.5068 - val_accuracy: 0.8305\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5150 - accuracy: 0.8042 - val_loss: 0.4929 - val_accuracy: 0.8305\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5044 - accuracy: 0.8078 - val_loss: 0.4803 - val_accuracy: 0.8220\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4954 - accuracy: 0.8125 - val_loss: 0.4694 - val_accuracy: 0.8305\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4877 - accuracy: 0.8113 - val_loss: 0.4602 - val_accuracy: 0.8305\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4811 - accuracy: 0.8137 - val_loss: 0.4528 - val_accuracy: 0.8305\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.8160 - val_loss: 0.4462 - val_accuracy: 0.8305\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.8149 - val_loss: 0.4402 - val_accuracy: 0.8305\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.8149 - val_loss: 0.4356 - val_accuracy: 0.8305\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4630 - accuracy: 0.8160 - val_loss: 0.4307 - val_accuracy: 0.8305\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.8137 - val_loss: 0.4266 - val_accuracy: 0.8305\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.8149 - val_loss: 0.4227 - val_accuracy: 0.8305\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.8149 - val_loss: 0.4192 - val_accuracy: 0.8390\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.8149 - val_loss: 0.4172 - val_accuracy: 0.8390\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.8172 - val_loss: 0.4128 - val_accuracy: 0.8390\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.8172 - val_loss: 0.4109 - val_accuracy: 0.8390\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.8172 - val_loss: 0.4080 - val_accuracy: 0.8390\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.8172 - val_loss: 0.4047 - val_accuracy: 0.8390\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.8172 - val_loss: 0.4026 - val_accuracy: 0.8390\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.8160 - val_loss: 0.4002 - val_accuracy: 0.8305\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.8172 - val_loss: 0.3978 - val_accuracy: 0.8390\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4372 - accuracy: 0.8160 - val_loss: 0.3959 - val_accuracy: 0.8390\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.8184 - val_loss: 0.3935 - val_accuracy: 0.8390\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4342 - accuracy: 0.8196 - val_loss: 0.3923 - val_accuracy: 0.8305\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.8208 - val_loss: 0.3904 - val_accuracy: 0.8305\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.8196 - val_loss: 0.3887 - val_accuracy: 0.8220\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.8231 - val_loss: 0.3862 - val_accuracy: 0.8305\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.8196 - val_loss: 0.3843 - val_accuracy: 0.8305\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.8231 - val_loss: 0.3835 - val_accuracy: 0.8305\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.8255 - val_loss: 0.3826 - val_accuracy: 0.8475\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.8278 - val_loss: 0.3814 - val_accuracy: 0.8475\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8243 - val_loss: 0.3792 - val_accuracy: 0.8475\n",
            "Epoch 41/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8255 - val_loss: 0.3785 - val_accuracy: 0.8390\n",
            "Epoch 42/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.8231 - val_loss: 0.3760 - val_accuracy: 0.8305\n",
            "Epoch 43/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.8267 - val_loss: 0.3766 - val_accuracy: 0.8390\n",
            "Epoch 44/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.8290 - val_loss: 0.3760 - val_accuracy: 0.8305\n",
            "Epoch 45/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4184 - accuracy: 0.8231 - val_loss: 0.3746 - val_accuracy: 0.8390\n",
            "Epoch 46/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.8255 - val_loss: 0.3734 - val_accuracy: 0.8305\n",
            "Epoch 47/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4163 - accuracy: 0.8267 - val_loss: 0.3729 - val_accuracy: 0.8305\n",
            "Epoch 48/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8255 - val_loss: 0.3717 - val_accuracy: 0.8390\n",
            "Epoch 49/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8267 - val_loss: 0.3713 - val_accuracy: 0.8220\n",
            "Epoch 50/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8243 - val_loss: 0.3698 - val_accuracy: 0.8305\n",
            "Epoch 51/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8267 - val_loss: 0.3697 - val_accuracy: 0.8220\n",
            "Epoch 52/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8267 - val_loss: 0.3692 - val_accuracy: 0.8220\n",
            "Epoch 53/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8231 - val_loss: 0.3675 - val_accuracy: 0.8305\n",
            "Epoch 54/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4098 - accuracy: 0.8243 - val_loss: 0.3667 - val_accuracy: 0.8305\n",
            "Epoch 55/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8255 - val_loss: 0.3663 - val_accuracy: 0.8305\n",
            "Epoch 56/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8255 - val_loss: 0.3654 - val_accuracy: 0.8220\n",
            "Epoch 57/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8243 - val_loss: 0.3643 - val_accuracy: 0.8220\n",
            "Epoch 58/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8243 - val_loss: 0.3647 - val_accuracy: 0.8305\n",
            "Epoch 59/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8267 - val_loss: 0.3643 - val_accuracy: 0.8305\n",
            "Epoch 60/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8267 - val_loss: 0.3625 - val_accuracy: 0.8390\n",
            "Epoch 61/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8267 - val_loss: 0.3612 - val_accuracy: 0.8475\n",
            "Epoch 62/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4037 - accuracy: 0.8302 - val_loss: 0.3613 - val_accuracy: 0.8475\n",
            "Epoch 63/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8290 - val_loss: 0.3602 - val_accuracy: 0.8390\n",
            "Epoch 64/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8255 - val_loss: 0.3589 - val_accuracy: 0.8390\n",
            "Epoch 65/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4024 - accuracy: 0.8278 - val_loss: 0.3599 - val_accuracy: 0.8475\n",
            "Epoch 66/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8314 - val_loss: 0.3585 - val_accuracy: 0.8475\n",
            "Epoch 67/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8267 - val_loss: 0.3572 - val_accuracy: 0.8559\n",
            "Epoch 68/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8290 - val_loss: 0.3566 - val_accuracy: 0.8475\n",
            "Epoch 69/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8302 - val_loss: 0.3561 - val_accuracy: 0.8559\n",
            "Epoch 70/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8325 - val_loss: 0.3556 - val_accuracy: 0.8390\n",
            "Epoch 71/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8302 - val_loss: 0.3553 - val_accuracy: 0.8475\n",
            "Epoch 72/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8290 - val_loss: 0.3546 - val_accuracy: 0.8559\n",
            "Epoch 73/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8302 - val_loss: 0.3542 - val_accuracy: 0.8475\n",
            "Epoch 74/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8325 - val_loss: 0.3527 - val_accuracy: 0.8559\n",
            "Epoch 75/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8337 - val_loss: 0.3524 - val_accuracy: 0.8390\n",
            "Epoch 76/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8337 - val_loss: 0.3521 - val_accuracy: 0.8390\n",
            "Epoch 77/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.8361 - val_loss: 0.3525 - val_accuracy: 0.8390\n",
            "Epoch 78/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3956 - accuracy: 0.8361 - val_loss: 0.3521 - val_accuracy: 0.8390\n",
            "Epoch 79/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8314 - val_loss: 0.3510 - val_accuracy: 0.8390\n",
            "Epoch 80/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8337 - val_loss: 0.3504 - val_accuracy: 0.8390\n",
            "Epoch 81/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8337 - val_loss: 0.3506 - val_accuracy: 0.8475\n",
            "Epoch 82/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8349 - val_loss: 0.3503 - val_accuracy: 0.8390\n",
            "Epoch 83/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3939 - accuracy: 0.8337 - val_loss: 0.3508 - val_accuracy: 0.8475\n",
            "Epoch 84/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8349 - val_loss: 0.3492 - val_accuracy: 0.8475\n",
            "Epoch 85/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8349 - val_loss: 0.3488 - val_accuracy: 0.8390\n",
            "Epoch 86/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8337 - val_loss: 0.3467 - val_accuracy: 0.8390\n",
            "Epoch 87/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3929 - accuracy: 0.8349 - val_loss: 0.3488 - val_accuracy: 0.8475\n",
            "Epoch 88/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8337 - val_loss: 0.3481 - val_accuracy: 0.8390\n",
            "Epoch 89/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8361 - val_loss: 0.3489 - val_accuracy: 0.8390\n",
            "Epoch 90/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3918 - accuracy: 0.8349 - val_loss: 0.3465 - val_accuracy: 0.8475\n",
            "Epoch 91/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3913 - accuracy: 0.8349 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 92/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3909 - accuracy: 0.8361 - val_loss: 0.3465 - val_accuracy: 0.8559\n",
            "Epoch 93/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3910 - accuracy: 0.8361 - val_loss: 0.3473 - val_accuracy: 0.8390\n",
            "Epoch 94/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3904 - accuracy: 0.8361 - val_loss: 0.3461 - val_accuracy: 0.8390\n",
            "Epoch 95/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8337 - val_loss: 0.3456 - val_accuracy: 0.8559\n",
            "Epoch 96/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8373 - val_loss: 0.3442 - val_accuracy: 0.8644\n",
            "Epoch 97/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3896 - accuracy: 0.8384 - val_loss: 0.3466 - val_accuracy: 0.8475\n",
            "Epoch 98/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3893 - accuracy: 0.8396 - val_loss: 0.3455 - val_accuracy: 0.8559\n",
            "Epoch 99/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3886 - accuracy: 0.8384 - val_loss: 0.3465 - val_accuracy: 0.8305\n",
            "Epoch 100/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3883 - accuracy: 0.8361 - val_loss: 0.3459 - val_accuracy: 0.8390\n",
            "Epoch 101/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8361 - val_loss: 0.3446 - val_accuracy: 0.8559\n",
            "Epoch 102/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.8361 - val_loss: 0.3450 - val_accuracy: 0.8644\n",
            "Epoch 103/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.8361 - val_loss: 0.3454 - val_accuracy: 0.8390\n",
            "Epoch 104/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3874 - accuracy: 0.8373 - val_loss: 0.3447 - val_accuracy: 0.8475\n",
            "Epoch 105/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3872 - accuracy: 0.8349 - val_loss: 0.3454 - val_accuracy: 0.8644\n",
            "Epoch 106/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.8361 - val_loss: 0.3443 - val_accuracy: 0.8475\n",
            "Epoch 107/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3870 - accuracy: 0.8325 - val_loss: 0.3440 - val_accuracy: 0.8559\n",
            "Epoch 108/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8373 - val_loss: 0.3451 - val_accuracy: 0.8475\n",
            "Epoch 109/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8337 - val_loss: 0.3433 - val_accuracy: 0.8559\n",
            "Epoch 110/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3857 - accuracy: 0.8373 - val_loss: 0.3439 - val_accuracy: 0.8475\n",
            "Epoch 111/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3865 - accuracy: 0.8349 - val_loss: 0.3437 - val_accuracy: 0.8559\n",
            "Epoch 112/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8361 - val_loss: 0.3448 - val_accuracy: 0.8559\n",
            "Epoch 113/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3853 - accuracy: 0.8349 - val_loss: 0.3450 - val_accuracy: 0.8559\n",
            "Epoch 114/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.8384 - val_loss: 0.3457 - val_accuracy: 0.8475\n",
            "Epoch 115/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3862 - accuracy: 0.8337 - val_loss: 0.3433 - val_accuracy: 0.8475\n",
            "Epoch 116/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3842 - accuracy: 0.8361 - val_loss: 0.3434 - val_accuracy: 0.8559\n",
            "Epoch 117/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3849 - accuracy: 0.8373 - val_loss: 0.3443 - val_accuracy: 0.8559\n",
            "Epoch 118/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3840 - accuracy: 0.8373 - val_loss: 0.3440 - val_accuracy: 0.8475\n",
            "Epoch 119/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3843 - accuracy: 0.8349 - val_loss: 0.3449 - val_accuracy: 0.8475\n",
            "Epoch 120/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3835 - accuracy: 0.8373 - val_loss: 0.3439 - val_accuracy: 0.8475\n",
            "Epoch 121/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3833 - accuracy: 0.8361 - val_loss: 0.3418 - val_accuracy: 0.8475\n",
            "Epoch 122/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3835 - accuracy: 0.8361 - val_loss: 0.3430 - val_accuracy: 0.8475\n",
            "Epoch 123/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3834 - accuracy: 0.8349 - val_loss: 0.3418 - val_accuracy: 0.8559\n",
            "Epoch 124/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3835 - accuracy: 0.8361 - val_loss: 0.3436 - val_accuracy: 0.8559\n",
            "Epoch 125/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.8349 - val_loss: 0.3444 - val_accuracy: 0.8559\n",
            "Epoch 126/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3828 - accuracy: 0.8361 - val_loss: 0.3434 - val_accuracy: 0.8559\n",
            "Epoch 127/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3823 - accuracy: 0.8361 - val_loss: 0.3435 - val_accuracy: 0.8559\n",
            "Epoch 128/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3819 - accuracy: 0.8361 - val_loss: 0.3437 - val_accuracy: 0.8559\n",
            "Epoch 129/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3821 - accuracy: 0.8384 - val_loss: 0.3435 - val_accuracy: 0.8559\n",
            "Epoch 130/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3816 - accuracy: 0.8373 - val_loss: 0.3455 - val_accuracy: 0.8559\n",
            "Epoch 131/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3818 - accuracy: 0.8373 - val_loss: 0.3458 - val_accuracy: 0.8559\n",
            "Epoch 132/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3816 - accuracy: 0.8361 - val_loss: 0.3438 - val_accuracy: 0.8559\n",
            "Epoch 133/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3814 - accuracy: 0.8373 - val_loss: 0.3438 - val_accuracy: 0.8559\n",
            "Epoch 134/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8396 - val_loss: 0.3438 - val_accuracy: 0.8559\n",
            "Epoch 135/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3813 - accuracy: 0.8361 - val_loss: 0.3454 - val_accuracy: 0.8559\n",
            "Epoch 136/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3811 - accuracy: 0.8349 - val_loss: 0.3462 - val_accuracy: 0.8475\n",
            "Epoch 137/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3811 - accuracy: 0.8396 - val_loss: 0.3452 - val_accuracy: 0.8559\n",
            "Epoch 138/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3803 - accuracy: 0.8361 - val_loss: 0.3464 - val_accuracy: 0.8475\n",
            "Epoch 139/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3802 - accuracy: 0.8361 - val_loss: 0.3437 - val_accuracy: 0.8644\n",
            "Epoch 140/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3800 - accuracy: 0.8361 - val_loss: 0.3451 - val_accuracy: 0.8475\n",
            "Epoch 141/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3798 - accuracy: 0.8396 - val_loss: 0.3455 - val_accuracy: 0.8559\n",
            "Epoch 142/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3801 - accuracy: 0.8420 - val_loss: 0.3449 - val_accuracy: 0.8559\n",
            "Epoch 143/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3794 - accuracy: 0.8373 - val_loss: 0.3433 - val_accuracy: 0.8729\n",
            "Epoch 144/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3797 - accuracy: 0.8373 - val_loss: 0.3437 - val_accuracy: 0.8559\n",
            "Epoch 145/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3800 - accuracy: 0.8361 - val_loss: 0.3447 - val_accuracy: 0.8644\n",
            "Epoch 146/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.8408 - val_loss: 0.3426 - val_accuracy: 0.8559\n",
            "Epoch 147/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8384 - val_loss: 0.3439 - val_accuracy: 0.8559\n",
            "Epoch 148/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.8384 - val_loss: 0.3439 - val_accuracy: 0.8559\n",
            "Epoch 149/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8408 - val_loss: 0.3430 - val_accuracy: 0.8475\n",
            "Epoch 150/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8396 - val_loss: 0.3444 - val_accuracy: 0.8475\n",
            "Epoch 151/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8396 - val_loss: 0.3433 - val_accuracy: 0.8559\n",
            "Epoch 152/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.8384 - val_loss: 0.3458 - val_accuracy: 0.8559\n",
            "Epoch 153/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8384 - val_loss: 0.3446 - val_accuracy: 0.8475\n",
            "Epoch 154/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8408 - val_loss: 0.3440 - val_accuracy: 0.8559\n",
            "Epoch 155/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8373 - val_loss: 0.3444 - val_accuracy: 0.8559\n",
            "Epoch 156/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8396 - val_loss: 0.3454 - val_accuracy: 0.8559\n",
            "Epoch 157/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8396 - val_loss: 0.3428 - val_accuracy: 0.8559\n",
            "Epoch 158/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8396 - val_loss: 0.3450 - val_accuracy: 0.8559\n",
            "Epoch 159/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8432 - val_loss: 0.3427 - val_accuracy: 0.8559\n",
            "Epoch 160/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8408 - val_loss: 0.3423 - val_accuracy: 0.8559\n",
            "Epoch 161/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8408 - val_loss: 0.3450 - val_accuracy: 0.8559\n",
            "Epoch 162/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.8420 - val_loss: 0.3454 - val_accuracy: 0.8559\n",
            "Epoch 163/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8420 - val_loss: 0.3454 - val_accuracy: 0.8475\n",
            "Epoch 164/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8384 - val_loss: 0.3454 - val_accuracy: 0.8559\n",
            "Epoch 165/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3763 - accuracy: 0.8420 - val_loss: 0.3459 - val_accuracy: 0.8559\n",
            "Epoch 166/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8408 - val_loss: 0.3456 - val_accuracy: 0.8559\n",
            "Epoch 167/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8384 - val_loss: 0.3466 - val_accuracy: 0.8559\n",
            "Epoch 168/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8420 - val_loss: 0.3465 - val_accuracy: 0.8559\n",
            "Epoch 169/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8408 - val_loss: 0.3459 - val_accuracy: 0.8559\n",
            "Epoch 170/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8373 - val_loss: 0.3465 - val_accuracy: 0.8559\n",
            "Epoch 171/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8384 - val_loss: 0.3473 - val_accuracy: 0.8559\n",
            "Epoch 172/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8373 - val_loss: 0.3477 - val_accuracy: 0.8559\n",
            "Epoch 173/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8373 - val_loss: 0.3487 - val_accuracy: 0.8559\n",
            "Epoch 174/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8384 - val_loss: 0.3462 - val_accuracy: 0.8559\n",
            "Epoch 175/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3758 - accuracy: 0.8396 - val_loss: 0.3460 - val_accuracy: 0.8559\n",
            "Epoch 176/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8373 - val_loss: 0.3460 - val_accuracy: 0.8559\n",
            "Epoch 177/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8384 - val_loss: 0.3469 - val_accuracy: 0.8559\n",
            "Epoch 178/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8373 - val_loss: 0.3463 - val_accuracy: 0.8559\n",
            "Epoch 179/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8396 - val_loss: 0.3465 - val_accuracy: 0.8559\n",
            "Epoch 180/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8373 - val_loss: 0.3484 - val_accuracy: 0.8559\n",
            "Epoch 181/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8396 - val_loss: 0.3476 - val_accuracy: 0.8559\n",
            "Epoch 182/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8384 - val_loss: 0.3470 - val_accuracy: 0.8559\n",
            "Epoch 183/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.8384 - val_loss: 0.3492 - val_accuracy: 0.8559\n",
            "Epoch 184/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8373 - val_loss: 0.3490 - val_accuracy: 0.8559\n",
            "Epoch 185/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8373 - val_loss: 0.3463 - val_accuracy: 0.8559\n",
            "Epoch 186/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8420 - val_loss: 0.3475 - val_accuracy: 0.8559\n",
            "Epoch 187/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8384 - val_loss: 0.3476 - val_accuracy: 0.8559\n",
            "Epoch 188/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.8373 - val_loss: 0.3490 - val_accuracy: 0.8559\n",
            "Epoch 189/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8384 - val_loss: 0.3480 - val_accuracy: 0.8559\n",
            "Epoch 190/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8384 - val_loss: 0.3473 - val_accuracy: 0.8559\n",
            "Epoch 191/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8373 - val_loss: 0.3492 - val_accuracy: 0.8559\n",
            "Epoch 192/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8384 - val_loss: 0.3479 - val_accuracy: 0.8559\n",
            "Epoch 193/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.8373 - val_loss: 0.3481 - val_accuracy: 0.8559\n",
            "Epoch 194/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8384 - val_loss: 0.3489 - val_accuracy: 0.8559\n",
            "Epoch 195/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3722 - accuracy: 0.8373 - val_loss: 0.3478 - val_accuracy: 0.8559\n",
            "Epoch 196/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8384 - val_loss: 0.3506 - val_accuracy: 0.8559\n",
            "Epoch 197/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8384 - val_loss: 0.3476 - val_accuracy: 0.8559\n",
            "Epoch 198/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8373 - val_loss: 0.3515 - val_accuracy: 0.8559\n",
            "Epoch 199/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8384 - val_loss: 0.3516 - val_accuracy: 0.8559\n",
            "Epoch 200/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8373 - val_loss: 0.3499 - val_accuracy: 0.8559\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 1s 11ms/step - loss: 0.6923 - accuracy: 0.5354 - val_loss: 0.6751 - val_accuracy: 0.6102\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.6661 - accuracy: 0.6097 - val_loss: 0.6525 - val_accuracy: 0.6102\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6450 - accuracy: 0.6285 - val_loss: 0.6320 - val_accuracy: 0.6186\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6270 - accuracy: 0.6403 - val_loss: 0.6136 - val_accuracy: 0.6441\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.6106 - accuracy: 0.6616 - val_loss: 0.5952 - val_accuracy: 0.6780\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5943 - accuracy: 0.7134 - val_loss: 0.5757 - val_accuracy: 0.7119\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5781 - accuracy: 0.7453 - val_loss: 0.5571 - val_accuracy: 0.7881\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5630 - accuracy: 0.7748 - val_loss: 0.5381 - val_accuracy: 0.7966\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5482 - accuracy: 0.7889 - val_loss: 0.5200 - val_accuracy: 0.8051\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7960 - val_loss: 0.5037 - val_accuracy: 0.8136\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5219 - accuracy: 0.7948 - val_loss: 0.4869 - val_accuracy: 0.8305\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5102 - accuracy: 0.7972 - val_loss: 0.4728 - val_accuracy: 0.8390\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.8019 - val_loss: 0.4612 - val_accuracy: 0.8475\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.8054 - val_loss: 0.4510 - val_accuracy: 0.8305\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.8054 - val_loss: 0.4414 - val_accuracy: 0.8390\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.8113 - val_loss: 0.4344 - val_accuracy: 0.8390\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.8101 - val_loss: 0.4275 - val_accuracy: 0.8220\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.8149 - val_loss: 0.4219 - val_accuracy: 0.8390\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.8101 - val_loss: 0.4166 - val_accuracy: 0.8220\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.8149 - val_loss: 0.4118 - val_accuracy: 0.8305\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.8137 - val_loss: 0.4079 - val_accuracy: 0.8305\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.8137 - val_loss: 0.4045 - val_accuracy: 0.8305\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.8125 - val_loss: 0.4012 - val_accuracy: 0.8305\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.8160 - val_loss: 0.3984 - val_accuracy: 0.8475\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.8196 - val_loss: 0.3965 - val_accuracy: 0.8136\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.8172 - val_loss: 0.3941 - val_accuracy: 0.8475\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.8184 - val_loss: 0.3918 - val_accuracy: 0.8305\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8219 - val_loss: 0.3894 - val_accuracy: 0.8475\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4386 - accuracy: 0.8231 - val_loss: 0.3877 - val_accuracy: 0.8305\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.8219 - val_loss: 0.3850 - val_accuracy: 0.8390\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.8231 - val_loss: 0.3830 - val_accuracy: 0.8390\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4344 - accuracy: 0.8208 - val_loss: 0.3822 - val_accuracy: 0.8390\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.8231 - val_loss: 0.3800 - val_accuracy: 0.8475\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.8231 - val_loss: 0.3781 - val_accuracy: 0.8475\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.8255 - val_loss: 0.3769 - val_accuracy: 0.8305\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.8231 - val_loss: 0.3757 - val_accuracy: 0.8475\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.8196 - val_loss: 0.3735 - val_accuracy: 0.8305\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.8219 - val_loss: 0.3721 - val_accuracy: 0.8305\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.8243 - val_loss: 0.3708 - val_accuracy: 0.8305\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8231 - val_loss: 0.3696 - val_accuracy: 0.8305\n",
            "Epoch 41/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.8196 - val_loss: 0.3688 - val_accuracy: 0.8390\n",
            "Epoch 42/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8208 - val_loss: 0.3666 - val_accuracy: 0.8390\n",
            "Epoch 43/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8267 - val_loss: 0.3656 - val_accuracy: 0.8305\n",
            "Epoch 44/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.8255 - val_loss: 0.3639 - val_accuracy: 0.8220\n",
            "Epoch 45/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8196 - val_loss: 0.3626 - val_accuracy: 0.8390\n",
            "Epoch 46/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4188 - accuracy: 0.8219 - val_loss: 0.3605 - val_accuracy: 0.8390\n",
            "Epoch 47/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8231 - val_loss: 0.3591 - val_accuracy: 0.8390\n",
            "Epoch 48/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8219 - val_loss: 0.3580 - val_accuracy: 0.8390\n",
            "Epoch 49/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8243 - val_loss: 0.3572 - val_accuracy: 0.8390\n",
            "Epoch 50/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8208 - val_loss: 0.3557 - val_accuracy: 0.8390\n",
            "Epoch 51/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8219 - val_loss: 0.3543 - val_accuracy: 0.8390\n",
            "Epoch 52/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8196 - val_loss: 0.3535 - val_accuracy: 0.8390\n",
            "Epoch 53/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8243 - val_loss: 0.3523 - val_accuracy: 0.8390\n",
            "Epoch 54/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8208 - val_loss: 0.3507 - val_accuracy: 0.8390\n",
            "Epoch 55/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8208 - val_loss: 0.3506 - val_accuracy: 0.8390\n",
            "Epoch 56/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8243 - val_loss: 0.3491 - val_accuracy: 0.8390\n",
            "Epoch 57/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8208 - val_loss: 0.3486 - val_accuracy: 0.8475\n",
            "Epoch 58/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.8208 - val_loss: 0.3479 - val_accuracy: 0.8475\n",
            "Epoch 59/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.8255 - val_loss: 0.3466 - val_accuracy: 0.8475\n",
            "Epoch 60/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8255 - val_loss: 0.3461 - val_accuracy: 0.8390\n",
            "Epoch 61/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.8290 - val_loss: 0.3464 - val_accuracy: 0.8475\n",
            "Epoch 62/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8243 - val_loss: 0.3452 - val_accuracy: 0.8475\n",
            "Epoch 63/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.8278 - val_loss: 0.3435 - val_accuracy: 0.8475\n",
            "Epoch 64/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8278 - val_loss: 0.3425 - val_accuracy: 0.8475\n",
            "Epoch 65/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8255 - val_loss: 0.3420 - val_accuracy: 0.8475\n",
            "Epoch 66/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8243 - val_loss: 0.3407 - val_accuracy: 0.8390\n",
            "Epoch 67/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8278 - val_loss: 0.3402 - val_accuracy: 0.8390\n",
            "Epoch 68/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8290 - val_loss: 0.3390 - val_accuracy: 0.8305\n",
            "Epoch 69/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8267 - val_loss: 0.3388 - val_accuracy: 0.8305\n",
            "Epoch 70/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8302 - val_loss: 0.3383 - val_accuracy: 0.8475\n",
            "Epoch 71/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8243 - val_loss: 0.3389 - val_accuracy: 0.8559\n",
            "Epoch 72/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8325 - val_loss: 0.3369 - val_accuracy: 0.8390\n",
            "Epoch 73/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8314 - val_loss: 0.3373 - val_accuracy: 0.8390\n",
            "Epoch 74/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8314 - val_loss: 0.3361 - val_accuracy: 0.8559\n",
            "Epoch 75/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8267 - val_loss: 0.3371 - val_accuracy: 0.8559\n",
            "Epoch 76/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8255 - val_loss: 0.3362 - val_accuracy: 0.8559\n",
            "Epoch 77/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8290 - val_loss: 0.3358 - val_accuracy: 0.8559\n",
            "Epoch 78/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8290 - val_loss: 0.3358 - val_accuracy: 0.8644\n",
            "Epoch 79/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8337 - val_loss: 0.3362 - val_accuracy: 0.8644\n",
            "Epoch 80/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8314 - val_loss: 0.3358 - val_accuracy: 0.8559\n",
            "Epoch 81/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8302 - val_loss: 0.3358 - val_accuracy: 0.8475\n",
            "Epoch 82/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8325 - val_loss: 0.3355 - val_accuracy: 0.8475\n",
            "Epoch 83/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8314 - val_loss: 0.3345 - val_accuracy: 0.8729\n",
            "Epoch 84/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8325 - val_loss: 0.3345 - val_accuracy: 0.8644\n",
            "Epoch 85/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8325 - val_loss: 0.3341 - val_accuracy: 0.8644\n",
            "Epoch 86/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8314 - val_loss: 0.3344 - val_accuracy: 0.8644\n",
            "Epoch 87/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8337 - val_loss: 0.3328 - val_accuracy: 0.8644\n",
            "Epoch 88/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8373 - val_loss: 0.3331 - val_accuracy: 0.8729\n",
            "Epoch 89/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8325 - val_loss: 0.3324 - val_accuracy: 0.8644\n",
            "Epoch 90/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8337 - val_loss: 0.3335 - val_accuracy: 0.8644\n",
            "Epoch 91/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8349 - val_loss: 0.3315 - val_accuracy: 0.8644\n",
            "Epoch 92/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8337 - val_loss: 0.3317 - val_accuracy: 0.8644\n",
            "Epoch 93/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8314 - val_loss: 0.3319 - val_accuracy: 0.8644\n",
            "Epoch 94/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8302 - val_loss: 0.3304 - val_accuracy: 0.8559\n",
            "Epoch 95/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8373 - val_loss: 0.3301 - val_accuracy: 0.8559\n",
            "Epoch 96/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.8337 - val_loss: 0.3312 - val_accuracy: 0.8559\n",
            "Epoch 97/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8384 - val_loss: 0.3302 - val_accuracy: 0.8559\n",
            "Epoch 98/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.8361 - val_loss: 0.3302 - val_accuracy: 0.8559\n",
            "Epoch 99/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3900 - accuracy: 0.8373 - val_loss: 0.3306 - val_accuracy: 0.8559\n",
            "Epoch 100/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8384 - val_loss: 0.3321 - val_accuracy: 0.8559\n",
            "Epoch 101/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8384 - val_loss: 0.3308 - val_accuracy: 0.8475\n",
            "Epoch 102/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8396 - val_loss: 0.3300 - val_accuracy: 0.8475\n",
            "Epoch 103/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8420 - val_loss: 0.3304 - val_accuracy: 0.8475\n",
            "Epoch 104/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8396 - val_loss: 0.3294 - val_accuracy: 0.8475\n",
            "Epoch 105/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8420 - val_loss: 0.3294 - val_accuracy: 0.8475\n",
            "Epoch 106/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8384 - val_loss: 0.3295 - val_accuracy: 0.8475\n",
            "Epoch 107/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8408 - val_loss: 0.3300 - val_accuracy: 0.8475\n",
            "Epoch 108/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8432 - val_loss: 0.3294 - val_accuracy: 0.8475\n",
            "Epoch 109/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8420 - val_loss: 0.3296 - val_accuracy: 0.8475\n",
            "Epoch 110/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8420 - val_loss: 0.3285 - val_accuracy: 0.8475\n",
            "Epoch 111/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.8420 - val_loss: 0.3279 - val_accuracy: 0.8559\n",
            "Epoch 112/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8443 - val_loss: 0.3279 - val_accuracy: 0.8475\n",
            "Epoch 113/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8408 - val_loss: 0.3283 - val_accuracy: 0.8475\n",
            "Epoch 114/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8420 - val_loss: 0.3267 - val_accuracy: 0.8475\n",
            "Epoch 115/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.8337 - val_loss: 0.3287 - val_accuracy: 0.8559\n",
            "Epoch 116/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3837 - accuracy: 0.8420 - val_loss: 0.3271 - val_accuracy: 0.8475\n",
            "Epoch 117/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8432 - val_loss: 0.3288 - val_accuracy: 0.8475\n",
            "Epoch 118/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3838 - accuracy: 0.8443 - val_loss: 0.3277 - val_accuracy: 0.8475\n",
            "Epoch 119/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.8432 - val_loss: 0.3268 - val_accuracy: 0.8475\n",
            "Epoch 120/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.8408 - val_loss: 0.3273 - val_accuracy: 0.8475\n",
            "Epoch 121/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.8479 - val_loss: 0.3288 - val_accuracy: 0.8475\n",
            "Epoch 122/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3825 - accuracy: 0.8443 - val_loss: 0.3276 - val_accuracy: 0.8475\n",
            "Epoch 123/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8396 - val_loss: 0.3282 - val_accuracy: 0.8475\n",
            "Epoch 124/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8420 - val_loss: 0.3270 - val_accuracy: 0.8475\n",
            "Epoch 125/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3820 - accuracy: 0.8408 - val_loss: 0.3264 - val_accuracy: 0.8475\n",
            "Epoch 126/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8467 - val_loss: 0.3275 - val_accuracy: 0.8475\n",
            "Epoch 127/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3816 - accuracy: 0.8408 - val_loss: 0.3267 - val_accuracy: 0.8475\n",
            "Epoch 128/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8443 - val_loss: 0.3278 - val_accuracy: 0.8475\n",
            "Epoch 129/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.8432 - val_loss: 0.3271 - val_accuracy: 0.8475\n",
            "Epoch 130/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8443 - val_loss: 0.3277 - val_accuracy: 0.8475\n",
            "Epoch 131/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8443 - val_loss: 0.3276 - val_accuracy: 0.8475\n",
            "Epoch 132/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8432 - val_loss: 0.3272 - val_accuracy: 0.8475\n",
            "Epoch 133/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8491 - val_loss: 0.3260 - val_accuracy: 0.8475\n",
            "Epoch 134/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3799 - accuracy: 0.8432 - val_loss: 0.3264 - val_accuracy: 0.8475\n",
            "Epoch 135/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.8443 - val_loss: 0.3285 - val_accuracy: 0.8475\n",
            "Epoch 136/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.8432 - val_loss: 0.3269 - val_accuracy: 0.8475\n",
            "Epoch 137/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3789 - accuracy: 0.8467 - val_loss: 0.3271 - val_accuracy: 0.8475\n",
            "Epoch 138/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3785 - accuracy: 0.8455 - val_loss: 0.3269 - val_accuracy: 0.8475\n",
            "Epoch 139/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8479 - val_loss: 0.3267 - val_accuracy: 0.8475\n",
            "Epoch 140/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3789 - accuracy: 0.8432 - val_loss: 0.3274 - val_accuracy: 0.8475\n",
            "Epoch 141/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8455 - val_loss: 0.3262 - val_accuracy: 0.8475\n",
            "Epoch 142/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.8443 - val_loss: 0.3272 - val_accuracy: 0.8475\n",
            "Epoch 143/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.8467 - val_loss: 0.3275 - val_accuracy: 0.8475\n",
            "Epoch 144/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8479 - val_loss: 0.3265 - val_accuracy: 0.8475\n",
            "Epoch 145/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8420 - val_loss: 0.3273 - val_accuracy: 0.8475\n",
            "Epoch 146/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8432 - val_loss: 0.3276 - val_accuracy: 0.8475\n",
            "Epoch 147/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3768 - accuracy: 0.8502 - val_loss: 0.3272 - val_accuracy: 0.8475\n",
            "Epoch 148/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.8420 - val_loss: 0.3280 - val_accuracy: 0.8475\n",
            "Epoch 149/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8467 - val_loss: 0.3277 - val_accuracy: 0.8475\n",
            "Epoch 150/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8455 - val_loss: 0.3264 - val_accuracy: 0.8475\n",
            "Epoch 151/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8467 - val_loss: 0.3284 - val_accuracy: 0.8475\n",
            "Epoch 152/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8502 - val_loss: 0.3276 - val_accuracy: 0.8475\n",
            "Epoch 153/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3761 - accuracy: 0.8467 - val_loss: 0.3283 - val_accuracy: 0.8475\n",
            "Epoch 154/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8467 - val_loss: 0.3275 - val_accuracy: 0.8475\n",
            "Epoch 155/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8467 - val_loss: 0.3263 - val_accuracy: 0.8475\n",
            "Epoch 156/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8479 - val_loss: 0.3287 - val_accuracy: 0.8475\n",
            "Epoch 157/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3756 - accuracy: 0.8479 - val_loss: 0.3274 - val_accuracy: 0.8475\n",
            "Epoch 158/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3761 - accuracy: 0.8479 - val_loss: 0.3279 - val_accuracy: 0.8475\n",
            "Epoch 159/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8491 - val_loss: 0.3260 - val_accuracy: 0.8475\n",
            "Epoch 160/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8479 - val_loss: 0.3271 - val_accuracy: 0.8475\n",
            "Epoch 161/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8491 - val_loss: 0.3276 - val_accuracy: 0.8475\n",
            "Epoch 162/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8491 - val_loss: 0.3293 - val_accuracy: 0.8475\n",
            "Epoch 163/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3745 - accuracy: 0.8467 - val_loss: 0.3273 - val_accuracy: 0.8475\n",
            "Epoch 164/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8491 - val_loss: 0.3262 - val_accuracy: 0.8475\n",
            "Epoch 165/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8479 - val_loss: 0.3269 - val_accuracy: 0.8475\n",
            "Epoch 166/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8491 - val_loss: 0.3295 - val_accuracy: 0.8475\n",
            "Epoch 167/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3745 - accuracy: 0.8479 - val_loss: 0.3253 - val_accuracy: 0.8475\n",
            "Epoch 168/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3745 - accuracy: 0.8514 - val_loss: 0.3279 - val_accuracy: 0.8475\n",
            "Epoch 169/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8514 - val_loss: 0.3267 - val_accuracy: 0.8475\n",
            "Epoch 170/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3731 - accuracy: 0.8467 - val_loss: 0.3267 - val_accuracy: 0.8475\n",
            "Epoch 171/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8467 - val_loss: 0.3277 - val_accuracy: 0.8475\n",
            "Epoch 172/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8479 - val_loss: 0.3265 - val_accuracy: 0.8475\n",
            "Epoch 173/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8467 - val_loss: 0.3278 - val_accuracy: 0.8475\n",
            "Epoch 174/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8467 - val_loss: 0.3240 - val_accuracy: 0.8475\n",
            "Epoch 175/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8455 - val_loss: 0.3264 - val_accuracy: 0.8475\n",
            "Epoch 176/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3722 - accuracy: 0.8479 - val_loss: 0.3243 - val_accuracy: 0.8475\n",
            "Epoch 177/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8479 - val_loss: 0.3261 - val_accuracy: 0.8475\n",
            "Epoch 178/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8455 - val_loss: 0.3226 - val_accuracy: 0.8559\n",
            "Epoch 179/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.8432 - val_loss: 0.3256 - val_accuracy: 0.8475\n",
            "Epoch 180/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8479 - val_loss: 0.3246 - val_accuracy: 0.8475\n",
            "Epoch 181/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8467 - val_loss: 0.3251 - val_accuracy: 0.8475\n",
            "Epoch 182/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8479 - val_loss: 0.3260 - val_accuracy: 0.8475\n",
            "Epoch 183/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8502 - val_loss: 0.3249 - val_accuracy: 0.8475\n",
            "Epoch 184/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8408 - val_loss: 0.3227 - val_accuracy: 0.8475\n",
            "Epoch 185/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8514 - val_loss: 0.3282 - val_accuracy: 0.8475\n",
            "Epoch 186/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3708 - accuracy: 0.8467 - val_loss: 0.3243 - val_accuracy: 0.8559\n",
            "Epoch 187/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8491 - val_loss: 0.3255 - val_accuracy: 0.8559\n",
            "Epoch 188/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8455 - val_loss: 0.3268 - val_accuracy: 0.8559\n",
            "Epoch 189/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8491 - val_loss: 0.3269 - val_accuracy: 0.8559\n",
            "Epoch 190/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3704 - accuracy: 0.8479 - val_loss: 0.3256 - val_accuracy: 0.8559\n",
            "Epoch 191/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8502 - val_loss: 0.3231 - val_accuracy: 0.8559\n",
            "Epoch 192/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8443 - val_loss: 0.3264 - val_accuracy: 0.8559\n",
            "Epoch 193/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8443 - val_loss: 0.3241 - val_accuracy: 0.8559\n",
            "Epoch 194/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8479 - val_loss: 0.3246 - val_accuracy: 0.8475\n",
            "Epoch 195/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8491 - val_loss: 0.3245 - val_accuracy: 0.8559\n",
            "Epoch 196/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3700 - accuracy: 0.8443 - val_loss: 0.3249 - val_accuracy: 0.8559\n",
            "Epoch 197/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3688 - accuracy: 0.8479 - val_loss: 0.3254 - val_accuracy: 0.8559\n",
            "Epoch 198/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8455 - val_loss: 0.3255 - val_accuracy: 0.8559\n",
            "Epoch 199/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8491 - val_loss: 0.3235 - val_accuracy: 0.8559\n",
            "Epoch 200/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3684 - accuracy: 0.8443 - val_loss: 0.3243 - val_accuracy: 0.8559\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 1s 12ms/step - loss: 0.7398 - accuracy: 0.3915 - val_loss: 0.7097 - val_accuracy: 0.4237\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5083 - val_loss: 0.6677 - val_accuracy: 0.6186\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6594 - accuracy: 0.6592 - val_loss: 0.6392 - val_accuracy: 0.7712\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6348 - accuracy: 0.7535 - val_loss: 0.6146 - val_accuracy: 0.8220\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6141 - accuracy: 0.7618 - val_loss: 0.5936 - val_accuracy: 0.8136\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5959 - accuracy: 0.7736 - val_loss: 0.5732 - val_accuracy: 0.7966\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5787 - accuracy: 0.7771 - val_loss: 0.5526 - val_accuracy: 0.8220\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5628 - accuracy: 0.7877 - val_loss: 0.5331 - val_accuracy: 0.8220\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5480 - accuracy: 0.7960 - val_loss: 0.5142 - val_accuracy: 0.8305\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5342 - accuracy: 0.7972 - val_loss: 0.4977 - val_accuracy: 0.8390\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5217 - accuracy: 0.8031 - val_loss: 0.4814 - val_accuracy: 0.8475\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5099 - accuracy: 0.8031 - val_loss: 0.4655 - val_accuracy: 0.8559\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4990 - accuracy: 0.8054 - val_loss: 0.4524 - val_accuracy: 0.8559\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4898 - accuracy: 0.8066 - val_loss: 0.4401 - val_accuracy: 0.8644\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4818 - accuracy: 0.8066 - val_loss: 0.4291 - val_accuracy: 0.8729\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4750 - accuracy: 0.8054 - val_loss: 0.4214 - val_accuracy: 0.8729\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.8090 - val_loss: 0.4131 - val_accuracy: 0.8729\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4644 - accuracy: 0.8113 - val_loss: 0.4068 - val_accuracy: 0.8814\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4602 - accuracy: 0.8160 - val_loss: 0.4003 - val_accuracy: 0.8729\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4565 - accuracy: 0.8172 - val_loss: 0.3961 - val_accuracy: 0.8644\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.8184 - val_loss: 0.3909 - val_accuracy: 0.8644\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.8160 - val_loss: 0.3866 - val_accuracy: 0.8644\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.8172 - val_loss: 0.3838 - val_accuracy: 0.8644\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.8184 - val_loss: 0.3804 - val_accuracy: 0.8644\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.8184 - val_loss: 0.3791 - val_accuracy: 0.8644\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.8184 - val_loss: 0.3747 - val_accuracy: 0.8644\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.8172 - val_loss: 0.3738 - val_accuracy: 0.8644\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.8184 - val_loss: 0.3705 - val_accuracy: 0.8644\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.8196 - val_loss: 0.3697 - val_accuracy: 0.8729\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.8196 - val_loss: 0.3671 - val_accuracy: 0.8644\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.8184 - val_loss: 0.3660 - val_accuracy: 0.8644\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.8184 - val_loss: 0.3635 - val_accuracy: 0.8644\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.8184 - val_loss: 0.3626 - val_accuracy: 0.8644\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.8125 - val_loss: 0.3613 - val_accuracy: 0.8644\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.8184 - val_loss: 0.3597 - val_accuracy: 0.8729\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8160 - val_loss: 0.3584 - val_accuracy: 0.8814\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8137 - val_loss: 0.3568 - val_accuracy: 0.8644\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.8160 - val_loss: 0.3568 - val_accuracy: 0.8814\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.8208 - val_loss: 0.3536 - val_accuracy: 0.8729\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.8160 - val_loss: 0.3538 - val_accuracy: 0.8644\n",
            "Epoch 41/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8149 - val_loss: 0.3525 - val_accuracy: 0.8644\n",
            "Epoch 42/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8149 - val_loss: 0.3518 - val_accuracy: 0.8729\n",
            "Epoch 43/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8160 - val_loss: 0.3511 - val_accuracy: 0.8729\n",
            "Epoch 44/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8160 - val_loss: 0.3494 - val_accuracy: 0.8729\n",
            "Epoch 45/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8172 - val_loss: 0.3495 - val_accuracy: 0.8729\n",
            "Epoch 46/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8184 - val_loss: 0.3472 - val_accuracy: 0.8644\n",
            "Epoch 47/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8208 - val_loss: 0.3454 - val_accuracy: 0.8644\n",
            "Epoch 48/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8243 - val_loss: 0.3468 - val_accuracy: 0.8729\n",
            "Epoch 49/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8231 - val_loss: 0.3450 - val_accuracy: 0.8729\n",
            "Epoch 50/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8208 - val_loss: 0.3427 - val_accuracy: 0.8559\n",
            "Epoch 51/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8219 - val_loss: 0.3437 - val_accuracy: 0.8475\n",
            "Epoch 52/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.8243 - val_loss: 0.3418 - val_accuracy: 0.8559\n",
            "Epoch 53/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.8219 - val_loss: 0.3410 - val_accuracy: 0.8729\n",
            "Epoch 54/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.8208 - val_loss: 0.3399 - val_accuracy: 0.8475\n",
            "Epoch 55/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8231 - val_loss: 0.3391 - val_accuracy: 0.8644\n",
            "Epoch 56/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8208 - val_loss: 0.3380 - val_accuracy: 0.8559\n",
            "Epoch 57/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.8255 - val_loss: 0.3364 - val_accuracy: 0.8559\n",
            "Epoch 58/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8231 - val_loss: 0.3364 - val_accuracy: 0.8729\n",
            "Epoch 59/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4042 - accuracy: 0.8243 - val_loss: 0.3343 - val_accuracy: 0.8729\n",
            "Epoch 60/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8243 - val_loss: 0.3330 - val_accuracy: 0.8559\n",
            "Epoch 61/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8219 - val_loss: 0.3326 - val_accuracy: 0.8814\n",
            "Epoch 62/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8208 - val_loss: 0.3316 - val_accuracy: 0.8814\n",
            "Epoch 63/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8267 - val_loss: 0.3325 - val_accuracy: 0.8729\n",
            "Epoch 64/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8208 - val_loss: 0.3300 - val_accuracy: 0.8729\n",
            "Epoch 65/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8231 - val_loss: 0.3287 - val_accuracy: 0.8644\n",
            "Epoch 66/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8219 - val_loss: 0.3282 - val_accuracy: 0.8559\n",
            "Epoch 67/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8219 - val_loss: 0.3281 - val_accuracy: 0.8729\n",
            "Epoch 68/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3992 - accuracy: 0.8196 - val_loss: 0.3266 - val_accuracy: 0.8644\n",
            "Epoch 69/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8219 - val_loss: 0.3251 - val_accuracy: 0.8644\n",
            "Epoch 70/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8184 - val_loss: 0.3247 - val_accuracy: 0.8390\n",
            "Epoch 71/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8196 - val_loss: 0.3238 - val_accuracy: 0.8644\n",
            "Epoch 72/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8243 - val_loss: 0.3241 - val_accuracy: 0.8644\n",
            "Epoch 73/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8208 - val_loss: 0.3224 - val_accuracy: 0.8390\n",
            "Epoch 74/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8219 - val_loss: 0.3223 - val_accuracy: 0.8475\n",
            "Epoch 75/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8255 - val_loss: 0.3220 - val_accuracy: 0.8559\n",
            "Epoch 76/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8208 - val_loss: 0.3215 - val_accuracy: 0.8729\n",
            "Epoch 77/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8267 - val_loss: 0.3211 - val_accuracy: 0.8644\n",
            "Epoch 78/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8219 - val_loss: 0.3191 - val_accuracy: 0.8729\n",
            "Epoch 79/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8278 - val_loss: 0.3193 - val_accuracy: 0.8559\n",
            "Epoch 80/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8243 - val_loss: 0.3199 - val_accuracy: 0.8729\n",
            "Epoch 81/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8255 - val_loss: 0.3184 - val_accuracy: 0.8559\n",
            "Epoch 82/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8255 - val_loss: 0.3180 - val_accuracy: 0.8644\n",
            "Epoch 83/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8255 - val_loss: 0.3174 - val_accuracy: 0.8644\n",
            "Epoch 84/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8255 - val_loss: 0.3168 - val_accuracy: 0.8814\n",
            "Epoch 85/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8243 - val_loss: 0.3157 - val_accuracy: 0.8814\n",
            "Epoch 86/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8243 - val_loss: 0.3154 - val_accuracy: 0.8729\n",
            "Epoch 87/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8243 - val_loss: 0.3127 - val_accuracy: 0.8898\n",
            "Epoch 88/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8255 - val_loss: 0.3136 - val_accuracy: 0.8729\n",
            "Epoch 89/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8255 - val_loss: 0.3133 - val_accuracy: 0.8898\n",
            "Epoch 90/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8290 - val_loss: 0.3131 - val_accuracy: 0.8729\n",
            "Epoch 91/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8255 - val_loss: 0.3129 - val_accuracy: 0.8729\n",
            "Epoch 92/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8314 - val_loss: 0.3129 - val_accuracy: 0.8814\n",
            "Epoch 93/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8267 - val_loss: 0.3108 - val_accuracy: 0.8729\n",
            "Epoch 94/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8267 - val_loss: 0.3111 - val_accuracy: 0.8898\n",
            "Epoch 95/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8278 - val_loss: 0.3118 - val_accuracy: 0.8729\n",
            "Epoch 96/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.8267 - val_loss: 0.3107 - val_accuracy: 0.8814\n",
            "Epoch 97/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8255 - val_loss: 0.3099 - val_accuracy: 0.8729\n",
            "Epoch 98/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.8267 - val_loss: 0.3113 - val_accuracy: 0.8814\n",
            "Epoch 99/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.8278 - val_loss: 0.3100 - val_accuracy: 0.8729\n",
            "Epoch 100/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8255 - val_loss: 0.3098 - val_accuracy: 0.8644\n",
            "Epoch 101/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8219 - val_loss: 0.3113 - val_accuracy: 0.8644\n",
            "Epoch 102/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8267 - val_loss: 0.3091 - val_accuracy: 0.8729\n",
            "Epoch 103/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8314 - val_loss: 0.3080 - val_accuracy: 0.8644\n",
            "Epoch 104/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.8267 - val_loss: 0.3092 - val_accuracy: 0.8644\n",
            "Epoch 105/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8255 - val_loss: 0.3071 - val_accuracy: 0.8729\n",
            "Epoch 106/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8255 - val_loss: 0.3063 - val_accuracy: 0.8644\n",
            "Epoch 107/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8267 - val_loss: 0.3078 - val_accuracy: 0.8644\n",
            "Epoch 108/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8267 - val_loss: 0.3060 - val_accuracy: 0.8729\n",
            "Epoch 109/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3877 - accuracy: 0.8278 - val_loss: 0.3056 - val_accuracy: 0.8729\n",
            "Epoch 110/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3872 - accuracy: 0.8278 - val_loss: 0.3056 - val_accuracy: 0.8559\n",
            "Epoch 111/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3871 - accuracy: 0.8255 - val_loss: 0.3061 - val_accuracy: 0.8729\n",
            "Epoch 112/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.8302 - val_loss: 0.3044 - val_accuracy: 0.8729\n",
            "Epoch 113/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.8278 - val_loss: 0.3051 - val_accuracy: 0.8644\n",
            "Epoch 114/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.8267 - val_loss: 0.3058 - val_accuracy: 0.8814\n",
            "Epoch 115/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3867 - accuracy: 0.8325 - val_loss: 0.3033 - val_accuracy: 0.8644\n",
            "Epoch 116/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8337 - val_loss: 0.3025 - val_accuracy: 0.8729\n",
            "Epoch 117/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8243 - val_loss: 0.3043 - val_accuracy: 0.8814\n",
            "Epoch 118/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8325 - val_loss: 0.3040 - val_accuracy: 0.8814\n",
            "Epoch 119/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3861 - accuracy: 0.8278 - val_loss: 0.3031 - val_accuracy: 0.8814\n",
            "Epoch 120/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8302 - val_loss: 0.3023 - val_accuracy: 0.8814\n",
            "Epoch 121/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8267 - val_loss: 0.3038 - val_accuracy: 0.8644\n",
            "Epoch 122/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8302 - val_loss: 0.3027 - val_accuracy: 0.8644\n",
            "Epoch 123/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.8267 - val_loss: 0.3027 - val_accuracy: 0.8644\n",
            "Epoch 124/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.8314 - val_loss: 0.3037 - val_accuracy: 0.8983\n",
            "Epoch 125/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.8278 - val_loss: 0.3018 - val_accuracy: 0.8898\n",
            "Epoch 126/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.8267 - val_loss: 0.3022 - val_accuracy: 0.8644\n",
            "Epoch 127/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8290 - val_loss: 0.3015 - val_accuracy: 0.8814\n",
            "Epoch 128/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.8290 - val_loss: 0.3018 - val_accuracy: 0.8814\n",
            "Epoch 129/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.8278 - val_loss: 0.3012 - val_accuracy: 0.8814\n",
            "Epoch 130/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8302 - val_loss: 0.3006 - val_accuracy: 0.8898\n",
            "Epoch 131/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.8267 - val_loss: 0.3014 - val_accuracy: 0.8644\n",
            "Epoch 132/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3838 - accuracy: 0.8255 - val_loss: 0.3017 - val_accuracy: 0.8559\n",
            "Epoch 133/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.8278 - val_loss: 0.3008 - val_accuracy: 0.8729\n",
            "Epoch 134/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.8255 - val_loss: 0.3015 - val_accuracy: 0.8729\n",
            "Epoch 135/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3832 - accuracy: 0.8278 - val_loss: 0.3006 - val_accuracy: 0.8814\n",
            "Epoch 136/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.8314 - val_loss: 0.2991 - val_accuracy: 0.8898\n",
            "Epoch 137/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3831 - accuracy: 0.8314 - val_loss: 0.2982 - val_accuracy: 0.8898\n",
            "Epoch 138/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.8267 - val_loss: 0.3004 - val_accuracy: 0.8644\n",
            "Epoch 139/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8278 - val_loss: 0.2982 - val_accuracy: 0.8644\n",
            "Epoch 140/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8302 - val_loss: 0.2988 - val_accuracy: 0.8898\n",
            "Epoch 141/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8255 - val_loss: 0.2980 - val_accuracy: 0.8814\n",
            "Epoch 142/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.8278 - val_loss: 0.2990 - val_accuracy: 0.8898\n",
            "Epoch 143/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8267 - val_loss: 0.2977 - val_accuracy: 0.8644\n",
            "Epoch 144/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.8243 - val_loss: 0.2977 - val_accuracy: 0.8729\n",
            "Epoch 145/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.8290 - val_loss: 0.2978 - val_accuracy: 0.8983\n",
            "Epoch 146/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8255 - val_loss: 0.2979 - val_accuracy: 0.8814\n",
            "Epoch 147/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.8267 - val_loss: 0.2981 - val_accuracy: 0.8729\n",
            "Epoch 148/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3816 - accuracy: 0.8290 - val_loss: 0.2966 - val_accuracy: 0.8898\n",
            "Epoch 149/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8290 - val_loss: 0.2982 - val_accuracy: 0.8983\n",
            "Epoch 150/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3811 - accuracy: 0.8290 - val_loss: 0.2963 - val_accuracy: 0.8729\n",
            "Epoch 151/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.8278 - val_loss: 0.2967 - val_accuracy: 0.8644\n",
            "Epoch 152/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8278 - val_loss: 0.2964 - val_accuracy: 0.8898\n",
            "Epoch 153/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8267 - val_loss: 0.2968 - val_accuracy: 0.8729\n",
            "Epoch 154/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.8267 - val_loss: 0.2963 - val_accuracy: 0.8644\n",
            "Epoch 155/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8231 - val_loss: 0.2963 - val_accuracy: 0.8983\n",
            "Epoch 156/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8243 - val_loss: 0.2972 - val_accuracy: 0.8898\n",
            "Epoch 157/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3799 - accuracy: 0.8278 - val_loss: 0.2956 - val_accuracy: 0.8814\n",
            "Epoch 158/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.8243 - val_loss: 0.2957 - val_accuracy: 0.8898\n",
            "Epoch 159/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8243 - val_loss: 0.2958 - val_accuracy: 0.8898\n",
            "Epoch 160/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3796 - accuracy: 0.8278 - val_loss: 0.2962 - val_accuracy: 0.8983\n",
            "Epoch 161/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8243 - val_loss: 0.2948 - val_accuracy: 0.8729\n",
            "Epoch 162/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8267 - val_loss: 0.2951 - val_accuracy: 0.8814\n",
            "Epoch 163/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8267 - val_loss: 0.2948 - val_accuracy: 0.8983\n",
            "Epoch 164/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.8290 - val_loss: 0.2957 - val_accuracy: 0.8814\n",
            "Epoch 165/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.8267 - val_loss: 0.2955 - val_accuracy: 0.8898\n",
            "Epoch 166/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8267 - val_loss: 0.2948 - val_accuracy: 0.8898\n",
            "Epoch 167/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.8278 - val_loss: 0.2944 - val_accuracy: 0.8983\n",
            "Epoch 168/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8278 - val_loss: 0.2950 - val_accuracy: 0.8644\n",
            "Epoch 169/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.8267 - val_loss: 0.2942 - val_accuracy: 0.8814\n",
            "Epoch 170/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8278 - val_loss: 0.2963 - val_accuracy: 0.8814\n",
            "Epoch 171/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8278 - val_loss: 0.2955 - val_accuracy: 0.8898\n",
            "Epoch 172/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3777 - accuracy: 0.8290 - val_loss: 0.2949 - val_accuracy: 0.8814\n",
            "Epoch 173/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3777 - accuracy: 0.8267 - val_loss: 0.2955 - val_accuracy: 0.8898\n",
            "Epoch 174/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.8278 - val_loss: 0.2938 - val_accuracy: 0.8729\n",
            "Epoch 175/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8278 - val_loss: 0.2951 - val_accuracy: 0.8983\n",
            "Epoch 176/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.8290 - val_loss: 0.2946 - val_accuracy: 0.8898\n",
            "Epoch 177/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8243 - val_loss: 0.2948 - val_accuracy: 0.8898\n",
            "Epoch 178/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8278 - val_loss: 0.2940 - val_accuracy: 0.8729\n",
            "Epoch 179/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.8231 - val_loss: 0.2946 - val_accuracy: 0.8898\n",
            "Epoch 180/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8290 - val_loss: 0.2943 - val_accuracy: 0.8898\n",
            "Epoch 181/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3764 - accuracy: 0.8314 - val_loss: 0.2942 - val_accuracy: 0.8983\n",
            "Epoch 182/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8290 - val_loss: 0.2945 - val_accuracy: 0.8814\n",
            "Epoch 183/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8290 - val_loss: 0.2943 - val_accuracy: 0.8814\n",
            "Epoch 184/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8290 - val_loss: 0.2948 - val_accuracy: 0.8814\n",
            "Epoch 185/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8278 - val_loss: 0.2945 - val_accuracy: 0.8729\n",
            "Epoch 186/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8290 - val_loss: 0.2947 - val_accuracy: 0.8898\n",
            "Epoch 187/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8278 - val_loss: 0.2940 - val_accuracy: 0.8729\n",
            "Epoch 188/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.8302 - val_loss: 0.2932 - val_accuracy: 0.8898\n",
            "Epoch 189/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8290 - val_loss: 0.2934 - val_accuracy: 0.8814\n",
            "Epoch 190/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8278 - val_loss: 0.2944 - val_accuracy: 0.8644\n",
            "Epoch 191/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8267 - val_loss: 0.2945 - val_accuracy: 0.8814\n",
            "Epoch 192/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8278 - val_loss: 0.2943 - val_accuracy: 0.8983\n",
            "Epoch 193/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8302 - val_loss: 0.2939 - val_accuracy: 0.8983\n",
            "Epoch 194/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8267 - val_loss: 0.2934 - val_accuracy: 0.8898\n",
            "Epoch 195/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8314 - val_loss: 0.2932 - val_accuracy: 0.8898\n",
            "Epoch 196/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8302 - val_loss: 0.2927 - val_accuracy: 0.8983\n",
            "Epoch 197/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.8290 - val_loss: 0.2938 - val_accuracy: 0.8983\n",
            "Epoch 198/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8302 - val_loss: 0.2925 - val_accuracy: 0.9068\n",
            "Epoch 199/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.8267 - val_loss: 0.2934 - val_accuracy: 0.8983\n",
            "Epoch 200/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8267 - val_loss: 0.2932 - val_accuracy: 0.8814\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 1s 11ms/step - loss: 0.6803 - accuracy: 0.6085 - val_loss: 0.6557 - val_accuracy: 0.7373\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6487 - accuracy: 0.6934 - val_loss: 0.6299 - val_accuracy: 0.6780\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6268 - accuracy: 0.6887 - val_loss: 0.6095 - val_accuracy: 0.6780\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6086 - accuracy: 0.6993 - val_loss: 0.5901 - val_accuracy: 0.7203\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5903 - accuracy: 0.7288 - val_loss: 0.5685 - val_accuracy: 0.7542\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5715 - accuracy: 0.7606 - val_loss: 0.5447 - val_accuracy: 0.8051\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5522 - accuracy: 0.7807 - val_loss: 0.5217 - val_accuracy: 0.8136\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5337 - accuracy: 0.7936 - val_loss: 0.4997 - val_accuracy: 0.8220\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5174 - accuracy: 0.7995 - val_loss: 0.4806 - val_accuracy: 0.8220\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5035 - accuracy: 0.8054 - val_loss: 0.4645 - val_accuracy: 0.8136\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4921 - accuracy: 0.8054 - val_loss: 0.4515 - val_accuracy: 0.8051\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.8019 - val_loss: 0.4403 - val_accuracy: 0.8136\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4752 - accuracy: 0.8042 - val_loss: 0.4304 - val_accuracy: 0.8220\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.8078 - val_loss: 0.4242 - val_accuracy: 0.8220\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.8090 - val_loss: 0.4168 - val_accuracy: 0.8220\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.8101 - val_loss: 0.4123 - val_accuracy: 0.8220\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.8066 - val_loss: 0.4075 - val_accuracy: 0.8305\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.8078 - val_loss: 0.4036 - val_accuracy: 0.8305\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.8054 - val_loss: 0.4010 - val_accuracy: 0.8475\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.8078 - val_loss: 0.3978 - val_accuracy: 0.8475\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.8113 - val_loss: 0.3948 - val_accuracy: 0.8559\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.8125 - val_loss: 0.3916 - val_accuracy: 0.8475\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.8125 - val_loss: 0.3893 - val_accuracy: 0.8475\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.8113 - val_loss: 0.3881 - val_accuracy: 0.8559\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.8149 - val_loss: 0.3858 - val_accuracy: 0.8390\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.8160 - val_loss: 0.3838 - val_accuracy: 0.8390\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.8149 - val_loss: 0.3846 - val_accuracy: 0.8559\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.8137 - val_loss: 0.3805 - val_accuracy: 0.8305\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.8160 - val_loss: 0.3805 - val_accuracy: 0.8305\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.8149 - val_loss: 0.3795 - val_accuracy: 0.8390\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.8160 - val_loss: 0.3791 - val_accuracy: 0.8390\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.8172 - val_loss: 0.3774 - val_accuracy: 0.8390\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.8172 - val_loss: 0.3774 - val_accuracy: 0.8390\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.8196 - val_loss: 0.3749 - val_accuracy: 0.8475\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8172 - val_loss: 0.3771 - val_accuracy: 0.8390\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4263 - accuracy: 0.8184 - val_loss: 0.3746 - val_accuracy: 0.8390\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8196 - val_loss: 0.3741 - val_accuracy: 0.8390\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.8219 - val_loss: 0.3734 - val_accuracy: 0.8390\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8172 - val_loss: 0.3747 - val_accuracy: 0.8390\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8184 - val_loss: 0.3726 - val_accuracy: 0.8390\n",
            "Epoch 41/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.8231 - val_loss: 0.3727 - val_accuracy: 0.8390\n",
            "Epoch 42/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.8243 - val_loss: 0.3709 - val_accuracy: 0.8390\n",
            "Epoch 43/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.8231 - val_loss: 0.3707 - val_accuracy: 0.8475\n",
            "Epoch 44/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4201 - accuracy: 0.8184 - val_loss: 0.3710 - val_accuracy: 0.8475\n",
            "Epoch 45/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.8231 - val_loss: 0.3699 - val_accuracy: 0.8475\n",
            "Epoch 46/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8231 - val_loss: 0.3690 - val_accuracy: 0.8475\n",
            "Epoch 47/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8231 - val_loss: 0.3699 - val_accuracy: 0.8390\n",
            "Epoch 48/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.8219 - val_loss: 0.3697 - val_accuracy: 0.8390\n",
            "Epoch 49/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8290 - val_loss: 0.3699 - val_accuracy: 0.8390\n",
            "Epoch 50/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8255 - val_loss: 0.3689 - val_accuracy: 0.8475\n",
            "Epoch 51/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8208 - val_loss: 0.3689 - val_accuracy: 0.8475\n",
            "Epoch 52/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8231 - val_loss: 0.3690 - val_accuracy: 0.8475\n",
            "Epoch 53/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8278 - val_loss: 0.3689 - val_accuracy: 0.8390\n",
            "Epoch 54/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8278 - val_loss: 0.3681 - val_accuracy: 0.8475\n",
            "Epoch 55/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8267 - val_loss: 0.3675 - val_accuracy: 0.8475\n",
            "Epoch 56/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8267 - val_loss: 0.3682 - val_accuracy: 0.8390\n",
            "Epoch 57/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8219 - val_loss: 0.3669 - val_accuracy: 0.8475\n",
            "Epoch 58/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8231 - val_loss: 0.3673 - val_accuracy: 0.8475\n",
            "Epoch 59/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8278 - val_loss: 0.3658 - val_accuracy: 0.8559\n",
            "Epoch 60/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8278 - val_loss: 0.3656 - val_accuracy: 0.8475\n",
            "Epoch 61/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.8314 - val_loss: 0.3680 - val_accuracy: 0.8390\n",
            "Epoch 62/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.8314 - val_loss: 0.3649 - val_accuracy: 0.8559\n",
            "Epoch 63/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8278 - val_loss: 0.3653 - val_accuracy: 0.8475\n",
            "Epoch 64/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8302 - val_loss: 0.3645 - val_accuracy: 0.8559\n",
            "Epoch 65/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8267 - val_loss: 0.3644 - val_accuracy: 0.8475\n",
            "Epoch 66/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8267 - val_loss: 0.3656 - val_accuracy: 0.8390\n",
            "Epoch 67/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8290 - val_loss: 0.3638 - val_accuracy: 0.8559\n",
            "Epoch 68/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8278 - val_loss: 0.3654 - val_accuracy: 0.8475\n",
            "Epoch 69/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4042 - accuracy: 0.8267 - val_loss: 0.3649 - val_accuracy: 0.8559\n",
            "Epoch 70/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8278 - val_loss: 0.3661 - val_accuracy: 0.8390\n",
            "Epoch 71/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8267 - val_loss: 0.3651 - val_accuracy: 0.8475\n",
            "Epoch 72/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8278 - val_loss: 0.3653 - val_accuracy: 0.8390\n",
            "Epoch 73/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8302 - val_loss: 0.3648 - val_accuracy: 0.8475\n",
            "Epoch 74/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8314 - val_loss: 0.3643 - val_accuracy: 0.8559\n",
            "Epoch 75/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4014 - accuracy: 0.8302 - val_loss: 0.3653 - val_accuracy: 0.8475\n",
            "Epoch 76/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8278 - val_loss: 0.3642 - val_accuracy: 0.8475\n",
            "Epoch 77/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8325 - val_loss: 0.3652 - val_accuracy: 0.8475\n",
            "Epoch 78/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8337 - val_loss: 0.3646 - val_accuracy: 0.8559\n",
            "Epoch 79/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8302 - val_loss: 0.3653 - val_accuracy: 0.8559\n",
            "Epoch 80/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8314 - val_loss: 0.3639 - val_accuracy: 0.8475\n",
            "Epoch 81/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8337 - val_loss: 0.3640 - val_accuracy: 0.8390\n",
            "Epoch 82/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8314 - val_loss: 0.3656 - val_accuracy: 0.8390\n",
            "Epoch 83/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8314 - val_loss: 0.3645 - val_accuracy: 0.8475\n",
            "Epoch 84/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8325 - val_loss: 0.3638 - val_accuracy: 0.8475\n",
            "Epoch 85/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8349 - val_loss: 0.3654 - val_accuracy: 0.8305\n",
            "Epoch 86/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8349 - val_loss: 0.3647 - val_accuracy: 0.8390\n",
            "Epoch 87/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8325 - val_loss: 0.3652 - val_accuracy: 0.8390\n",
            "Epoch 88/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8373 - val_loss: 0.3646 - val_accuracy: 0.8390\n",
            "Epoch 89/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8349 - val_loss: 0.3640 - val_accuracy: 0.8475\n",
            "Epoch 90/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3949 - accuracy: 0.8349 - val_loss: 0.3625 - val_accuracy: 0.8475\n",
            "Epoch 91/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8349 - val_loss: 0.3644 - val_accuracy: 0.8390\n",
            "Epoch 92/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8337 - val_loss: 0.3648 - val_accuracy: 0.8390\n",
            "Epoch 93/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8396 - val_loss: 0.3635 - val_accuracy: 0.8390\n",
            "Epoch 94/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8384 - val_loss: 0.3648 - val_accuracy: 0.8305\n",
            "Epoch 95/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3929 - accuracy: 0.8361 - val_loss: 0.3644 - val_accuracy: 0.8305\n",
            "Epoch 96/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8349 - val_loss: 0.3649 - val_accuracy: 0.8305\n",
            "Epoch 97/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8396 - val_loss: 0.3652 - val_accuracy: 0.8220\n",
            "Epoch 98/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3921 - accuracy: 0.8361 - val_loss: 0.3645 - val_accuracy: 0.8220\n",
            "Epoch 99/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8337 - val_loss: 0.3644 - val_accuracy: 0.8136\n",
            "Epoch 100/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8361 - val_loss: 0.3633 - val_accuracy: 0.8305\n",
            "Epoch 101/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8373 - val_loss: 0.3642 - val_accuracy: 0.8220\n",
            "Epoch 102/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8361 - val_loss: 0.3622 - val_accuracy: 0.8220\n",
            "Epoch 103/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8325 - val_loss: 0.3642 - val_accuracy: 0.8220\n",
            "Epoch 104/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8349 - val_loss: 0.3639 - val_accuracy: 0.8136\n",
            "Epoch 105/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8325 - val_loss: 0.3619 - val_accuracy: 0.8220\n",
            "Epoch 106/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8349 - val_loss: 0.3642 - val_accuracy: 0.8220\n",
            "Epoch 107/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8373 - val_loss: 0.3639 - val_accuracy: 0.8220\n",
            "Epoch 108/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.8349 - val_loss: 0.3651 - val_accuracy: 0.8220\n",
            "Epoch 109/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.8361 - val_loss: 0.3648 - val_accuracy: 0.8136\n",
            "Epoch 110/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3872 - accuracy: 0.8361 - val_loss: 0.3637 - val_accuracy: 0.8220\n",
            "Epoch 111/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8349 - val_loss: 0.3645 - val_accuracy: 0.8220\n",
            "Epoch 112/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8384 - val_loss: 0.3635 - val_accuracy: 0.8220\n",
            "Epoch 113/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8408 - val_loss: 0.3634 - val_accuracy: 0.8390\n",
            "Epoch 114/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8396 - val_loss: 0.3621 - val_accuracy: 0.8220\n",
            "Epoch 115/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8384 - val_loss: 0.3634 - val_accuracy: 0.8220\n",
            "Epoch 116/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8396 - val_loss: 0.3629 - val_accuracy: 0.8220\n",
            "Epoch 117/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.8396 - val_loss: 0.3625 - val_accuracy: 0.8136\n",
            "Epoch 118/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8373 - val_loss: 0.3607 - val_accuracy: 0.8220\n",
            "Epoch 119/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8384 - val_loss: 0.3609 - val_accuracy: 0.8220\n",
            "Epoch 120/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8396 - val_loss: 0.3621 - val_accuracy: 0.8220\n",
            "Epoch 121/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.8396 - val_loss: 0.3595 - val_accuracy: 0.8220\n",
            "Epoch 122/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.8384 - val_loss: 0.3610 - val_accuracy: 0.8220\n",
            "Epoch 123/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.8396 - val_loss: 0.3607 - val_accuracy: 0.8220\n",
            "Epoch 124/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.8408 - val_loss: 0.3606 - val_accuracy: 0.8220\n",
            "Epoch 125/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.8349 - val_loss: 0.3620 - val_accuracy: 0.8220\n",
            "Epoch 126/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8396 - val_loss: 0.3605 - val_accuracy: 0.8220\n",
            "Epoch 127/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.8408 - val_loss: 0.3622 - val_accuracy: 0.8220\n",
            "Epoch 128/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8408 - val_loss: 0.3619 - val_accuracy: 0.8305\n",
            "Epoch 129/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.8432 - val_loss: 0.3611 - val_accuracy: 0.8305\n",
            "Epoch 130/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3825 - accuracy: 0.8408 - val_loss: 0.3619 - val_accuracy: 0.8305\n",
            "Epoch 131/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3808 - accuracy: 0.8420 - val_loss: 0.3612 - val_accuracy: 0.8220\n",
            "Epoch 132/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3805 - accuracy: 0.8420 - val_loss: 0.3604 - val_accuracy: 0.8305\n",
            "Epoch 133/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8408 - val_loss: 0.3624 - val_accuracy: 0.8220\n",
            "Epoch 134/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8443 - val_loss: 0.3616 - val_accuracy: 0.8305\n",
            "Epoch 135/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3803 - accuracy: 0.8455 - val_loss: 0.3598 - val_accuracy: 0.8220\n",
            "Epoch 136/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8408 - val_loss: 0.3616 - val_accuracy: 0.8305\n",
            "Epoch 137/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8443 - val_loss: 0.3610 - val_accuracy: 0.8220\n",
            "Epoch 138/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8420 - val_loss: 0.3604 - val_accuracy: 0.8390\n",
            "Epoch 139/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.8396 - val_loss: 0.3617 - val_accuracy: 0.8305\n",
            "Epoch 140/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8432 - val_loss: 0.3610 - val_accuracy: 0.8220\n",
            "Epoch 141/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.8408 - val_loss: 0.3598 - val_accuracy: 0.8390\n",
            "Epoch 142/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.8420 - val_loss: 0.3605 - val_accuracy: 0.8220\n",
            "Epoch 143/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3782 - accuracy: 0.8420 - val_loss: 0.3610 - val_accuracy: 0.8305\n",
            "Epoch 144/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8432 - val_loss: 0.3605 - val_accuracy: 0.8390\n",
            "Epoch 145/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8443 - val_loss: 0.3601 - val_accuracy: 0.8305\n",
            "Epoch 146/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.8432 - val_loss: 0.3638 - val_accuracy: 0.8220\n",
            "Epoch 147/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.8455 - val_loss: 0.3604 - val_accuracy: 0.8220\n",
            "Epoch 148/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8432 - val_loss: 0.3629 - val_accuracy: 0.8390\n",
            "Epoch 149/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8479 - val_loss: 0.3618 - val_accuracy: 0.8220\n",
            "Epoch 150/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8455 - val_loss: 0.3607 - val_accuracy: 0.8220\n",
            "Epoch 151/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.8384 - val_loss: 0.3632 - val_accuracy: 0.8220\n",
            "Epoch 152/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8420 - val_loss: 0.3623 - val_accuracy: 0.8220\n",
            "Epoch 153/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8455 - val_loss: 0.3641 - val_accuracy: 0.8220\n",
            "Epoch 154/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8467 - val_loss: 0.3623 - val_accuracy: 0.8220\n",
            "Epoch 155/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.8443 - val_loss: 0.3652 - val_accuracy: 0.8220\n",
            "Epoch 156/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8432 - val_loss: 0.3637 - val_accuracy: 0.8136\n",
            "Epoch 157/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8443 - val_loss: 0.3623 - val_accuracy: 0.8220\n",
            "Epoch 158/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8443 - val_loss: 0.3608 - val_accuracy: 0.8305\n",
            "Epoch 159/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8479 - val_loss: 0.3656 - val_accuracy: 0.8305\n",
            "Epoch 160/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.8455 - val_loss: 0.3627 - val_accuracy: 0.8305\n",
            "Epoch 161/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8432 - val_loss: 0.3635 - val_accuracy: 0.8305\n",
            "Epoch 162/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8443 - val_loss: 0.3621 - val_accuracy: 0.8305\n",
            "Epoch 163/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8455 - val_loss: 0.3639 - val_accuracy: 0.8220\n",
            "Epoch 164/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3733 - accuracy: 0.8443 - val_loss: 0.3638 - val_accuracy: 0.8220\n",
            "Epoch 165/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8455 - val_loss: 0.3628 - val_accuracy: 0.8220\n",
            "Epoch 166/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8455 - val_loss: 0.3637 - val_accuracy: 0.8220\n",
            "Epoch 167/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.8479 - val_loss: 0.3647 - val_accuracy: 0.8220\n",
            "Epoch 168/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8408 - val_loss: 0.3628 - val_accuracy: 0.8305\n",
            "Epoch 169/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3722 - accuracy: 0.8479 - val_loss: 0.3648 - val_accuracy: 0.8220\n",
            "Epoch 170/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3719 - accuracy: 0.8443 - val_loss: 0.3642 - val_accuracy: 0.8220\n",
            "Epoch 171/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3717 - accuracy: 0.8467 - val_loss: 0.3634 - val_accuracy: 0.8305\n",
            "Epoch 172/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8432 - val_loss: 0.3650 - val_accuracy: 0.8220\n",
            "Epoch 173/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3715 - accuracy: 0.8479 - val_loss: 0.3631 - val_accuracy: 0.8220\n",
            "Epoch 174/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8432 - val_loss: 0.3646 - val_accuracy: 0.8305\n",
            "Epoch 175/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8443 - val_loss: 0.3644 - val_accuracy: 0.8220\n",
            "Epoch 176/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3711 - accuracy: 0.8467 - val_loss: 0.3644 - val_accuracy: 0.8220\n",
            "Epoch 177/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8502 - val_loss: 0.3636 - val_accuracy: 0.8220\n",
            "Epoch 178/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8455 - val_loss: 0.3642 - val_accuracy: 0.8220\n",
            "Epoch 179/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8455 - val_loss: 0.3640 - val_accuracy: 0.8220\n",
            "Epoch 180/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3704 - accuracy: 0.8479 - val_loss: 0.3652 - val_accuracy: 0.8220\n",
            "Epoch 181/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3698 - accuracy: 0.8491 - val_loss: 0.3635 - val_accuracy: 0.8220\n",
            "Epoch 182/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3702 - accuracy: 0.8443 - val_loss: 0.3635 - val_accuracy: 0.8220\n",
            "Epoch 183/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3691 - accuracy: 0.8455 - val_loss: 0.3639 - val_accuracy: 0.8220\n",
            "Epoch 184/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3700 - accuracy: 0.8443 - val_loss: 0.3644 - val_accuracy: 0.8220\n",
            "Epoch 185/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3698 - accuracy: 0.8455 - val_loss: 0.3647 - val_accuracy: 0.8136\n",
            "Epoch 186/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8491 - val_loss: 0.3635 - val_accuracy: 0.8305\n",
            "Epoch 187/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 0.8432 - val_loss: 0.3650 - val_accuracy: 0.8220\n",
            "Epoch 188/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.8479 - val_loss: 0.3650 - val_accuracy: 0.8220\n",
            "Epoch 189/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3689 - accuracy: 0.8479 - val_loss: 0.3639 - val_accuracy: 0.8305\n",
            "Epoch 190/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3686 - accuracy: 0.8455 - val_loss: 0.3653 - val_accuracy: 0.8220\n",
            "Epoch 191/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3686 - accuracy: 0.8491 - val_loss: 0.3649 - val_accuracy: 0.8220\n",
            "Epoch 192/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3684 - accuracy: 0.8432 - val_loss: 0.3646 - val_accuracy: 0.8220\n",
            "Epoch 193/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8467 - val_loss: 0.3656 - val_accuracy: 0.8220\n",
            "Epoch 194/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8455 - val_loss: 0.3666 - val_accuracy: 0.8220\n",
            "Epoch 195/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8467 - val_loss: 0.3658 - val_accuracy: 0.8136\n",
            "Epoch 196/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3675 - accuracy: 0.8479 - val_loss: 0.3640 - val_accuracy: 0.8220\n",
            "Epoch 197/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3675 - accuracy: 0.8491 - val_loss: 0.3672 - val_accuracy: 0.8220\n",
            "Epoch 198/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3672 - accuracy: 0.8479 - val_loss: 0.3655 - val_accuracy: 0.8136\n",
            "Epoch 199/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8479 - val_loss: 0.3642 - val_accuracy: 0.8220\n",
            "Epoch 200/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3675 - accuracy: 0.8455 - val_loss: 0.3649 - val_accuracy: 0.8220\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 1s 10ms/step - loss: 0.6796 - accuracy: 0.6097 - val_loss: 0.6647 - val_accuracy: 0.6102\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6565 - accuracy: 0.6097 - val_loss: 0.6409 - val_accuracy: 0.6102\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6345 - accuracy: 0.6108 - val_loss: 0.6149 - val_accuracy: 0.6102\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6116 - accuracy: 0.6297 - val_loss: 0.5877 - val_accuracy: 0.6525\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5877 - accuracy: 0.6663 - val_loss: 0.5609 - val_accuracy: 0.7034\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5659 - accuracy: 0.7087 - val_loss: 0.5360 - val_accuracy: 0.7627\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5466 - accuracy: 0.7512 - val_loss: 0.5148 - val_accuracy: 0.7797\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5307 - accuracy: 0.7748 - val_loss: 0.4964 - val_accuracy: 0.8136\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5173 - accuracy: 0.7866 - val_loss: 0.4809 - val_accuracy: 0.8220\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5066 - accuracy: 0.7866 - val_loss: 0.4675 - val_accuracy: 0.8220\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7925 - val_loss: 0.4579 - val_accuracy: 0.8220\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7913 - val_loss: 0.4487 - val_accuracy: 0.8305\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7948 - val_loss: 0.4411 - val_accuracy: 0.8305\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4781 - accuracy: 0.7948 - val_loss: 0.4341 - val_accuracy: 0.8305\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4734 - accuracy: 0.7936 - val_loss: 0.4278 - val_accuracy: 0.8305\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.8019 - val_loss: 0.4222 - val_accuracy: 0.8305\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.8054 - val_loss: 0.4182 - val_accuracy: 0.8305\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.8090 - val_loss: 0.4134 - val_accuracy: 0.8390\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.8125 - val_loss: 0.4106 - val_accuracy: 0.8390\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.8137 - val_loss: 0.4067 - val_accuracy: 0.8305\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.8137 - val_loss: 0.4039 - val_accuracy: 0.8305\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.8137 - val_loss: 0.4005 - val_accuracy: 0.8305\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.8149 - val_loss: 0.3977 - val_accuracy: 0.8305\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.8172 - val_loss: 0.3947 - val_accuracy: 0.8305\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.8125 - val_loss: 0.3925 - val_accuracy: 0.8305\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.8172 - val_loss: 0.3901 - val_accuracy: 0.8390\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.8172 - val_loss: 0.3883 - val_accuracy: 0.8390\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.8160 - val_loss: 0.3862 - val_accuracy: 0.8390\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.8172 - val_loss: 0.3839 - val_accuracy: 0.8390\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.8172 - val_loss: 0.3816 - val_accuracy: 0.8475\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4336 - accuracy: 0.8149 - val_loss: 0.3806 - val_accuracy: 0.8390\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.8184 - val_loss: 0.3781 - val_accuracy: 0.8390\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.8184 - val_loss: 0.3766 - val_accuracy: 0.8390\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.8196 - val_loss: 0.3750 - val_accuracy: 0.8305\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.8184 - val_loss: 0.3729 - val_accuracy: 0.8559\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.8160 - val_loss: 0.3728 - val_accuracy: 0.8390\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.8208 - val_loss: 0.3701 - val_accuracy: 0.8559\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.8196 - val_loss: 0.3684 - val_accuracy: 0.8559\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.8208 - val_loss: 0.3672 - val_accuracy: 0.8559\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.8219 - val_loss: 0.3661 - val_accuracy: 0.8559\n",
            "Epoch 41/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.8231 - val_loss: 0.3655 - val_accuracy: 0.8475\n",
            "Epoch 42/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.8243 - val_loss: 0.3637 - val_accuracy: 0.8559\n",
            "Epoch 43/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8255 - val_loss: 0.3630 - val_accuracy: 0.8559\n",
            "Epoch 44/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.8243 - val_loss: 0.3613 - val_accuracy: 0.8729\n",
            "Epoch 45/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.8267 - val_loss: 0.3603 - val_accuracy: 0.8644\n",
            "Epoch 46/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8278 - val_loss: 0.3598 - val_accuracy: 0.8644\n",
            "Epoch 47/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.4149 - accuracy: 0.8278 - val_loss: 0.3579 - val_accuracy: 0.8644\n",
            "Epoch 48/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8290 - val_loss: 0.3570 - val_accuracy: 0.8644\n",
            "Epoch 49/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8302 - val_loss: 0.3571 - val_accuracy: 0.8559\n",
            "Epoch 50/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.4123 - accuracy: 0.8314 - val_loss: 0.3549 - val_accuracy: 0.8559\n",
            "Epoch 51/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8337 - val_loss: 0.3536 - val_accuracy: 0.8644\n",
            "Epoch 52/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8314 - val_loss: 0.3530 - val_accuracy: 0.8729\n",
            "Epoch 53/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8337 - val_loss: 0.3525 - val_accuracy: 0.8644\n",
            "Epoch 54/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.8337 - val_loss: 0.3516 - val_accuracy: 0.8644\n",
            "Epoch 55/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4086 - accuracy: 0.8337 - val_loss: 0.3510 - val_accuracy: 0.8644\n",
            "Epoch 56/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8290 - val_loss: 0.3500 - val_accuracy: 0.8559\n",
            "Epoch 57/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8337 - val_loss: 0.3500 - val_accuracy: 0.8644\n",
            "Epoch 58/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8325 - val_loss: 0.3484 - val_accuracy: 0.8559\n",
            "Epoch 59/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8302 - val_loss: 0.3477 - val_accuracy: 0.8559\n",
            "Epoch 60/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8349 - val_loss: 0.3474 - val_accuracy: 0.8729\n",
            "Epoch 61/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8396 - val_loss: 0.3464 - val_accuracy: 0.8559\n",
            "Epoch 62/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8325 - val_loss: 0.3463 - val_accuracy: 0.8559\n",
            "Epoch 63/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.8337 - val_loss: 0.3447 - val_accuracy: 0.8644\n",
            "Epoch 64/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8349 - val_loss: 0.3443 - val_accuracy: 0.8729\n",
            "Epoch 65/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8337 - val_loss: 0.3441 - val_accuracy: 0.8644\n",
            "Epoch 66/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8314 - val_loss: 0.3427 - val_accuracy: 0.8729\n",
            "Epoch 67/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8337 - val_loss: 0.3421 - val_accuracy: 0.8729\n",
            "Epoch 68/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8349 - val_loss: 0.3415 - val_accuracy: 0.8729\n",
            "Epoch 69/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8325 - val_loss: 0.3414 - val_accuracy: 0.8644\n",
            "Epoch 70/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8349 - val_loss: 0.3396 - val_accuracy: 0.8729\n",
            "Epoch 71/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8337 - val_loss: 0.3393 - val_accuracy: 0.8729\n",
            "Epoch 72/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3983 - accuracy: 0.8361 - val_loss: 0.3390 - val_accuracy: 0.8729\n",
            "Epoch 73/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8337 - val_loss: 0.3376 - val_accuracy: 0.8729\n",
            "Epoch 74/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8325 - val_loss: 0.3381 - val_accuracy: 0.8729\n",
            "Epoch 75/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8325 - val_loss: 0.3374 - val_accuracy: 0.8814\n",
            "Epoch 76/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8314 - val_loss: 0.3364 - val_accuracy: 0.8814\n",
            "Epoch 77/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8325 - val_loss: 0.3353 - val_accuracy: 0.8814\n",
            "Epoch 78/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8314 - val_loss: 0.3366 - val_accuracy: 0.8729\n",
            "Epoch 79/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8314 - val_loss: 0.3352 - val_accuracy: 0.8729\n",
            "Epoch 80/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8290 - val_loss: 0.3349 - val_accuracy: 0.8814\n",
            "Epoch 81/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8314 - val_loss: 0.3356 - val_accuracy: 0.8814\n",
            "Epoch 82/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8290 - val_loss: 0.3349 - val_accuracy: 0.8729\n",
            "Epoch 83/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8325 - val_loss: 0.3342 - val_accuracy: 0.8729\n",
            "Epoch 84/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8349 - val_loss: 0.3339 - val_accuracy: 0.8814\n",
            "Epoch 85/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8325 - val_loss: 0.3334 - val_accuracy: 0.8814\n",
            "Epoch 86/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8325 - val_loss: 0.3330 - val_accuracy: 0.8814\n",
            "Epoch 87/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3905 - accuracy: 0.8325 - val_loss: 0.3326 - val_accuracy: 0.8729\n",
            "Epoch 88/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8349 - val_loss: 0.3329 - val_accuracy: 0.8814\n",
            "Epoch 89/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8337 - val_loss: 0.3327 - val_accuracy: 0.8814\n",
            "Epoch 90/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8325 - val_loss: 0.3324 - val_accuracy: 0.8814\n",
            "Epoch 91/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8290 - val_loss: 0.3325 - val_accuracy: 0.8814\n",
            "Epoch 92/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8325 - val_loss: 0.3326 - val_accuracy: 0.8814\n",
            "Epoch 93/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8337 - val_loss: 0.3342 - val_accuracy: 0.8814\n",
            "Epoch 94/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8314 - val_loss: 0.3348 - val_accuracy: 0.8814\n",
            "Epoch 95/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8337 - val_loss: 0.3334 - val_accuracy: 0.8814\n",
            "Epoch 96/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8325 - val_loss: 0.3325 - val_accuracy: 0.8729\n",
            "Epoch 97/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8314 - val_loss: 0.3325 - val_accuracy: 0.8729\n",
            "Epoch 98/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8337 - val_loss: 0.3333 - val_accuracy: 0.8729\n",
            "Epoch 99/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8325 - val_loss: 0.3340 - val_accuracy: 0.8814\n",
            "Epoch 100/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.8337 - val_loss: 0.3321 - val_accuracy: 0.8729\n",
            "Epoch 101/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.8314 - val_loss: 0.3318 - val_accuracy: 0.8729\n",
            "Epoch 102/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8314 - val_loss: 0.3318 - val_accuracy: 0.8729\n",
            "Epoch 103/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8278 - val_loss: 0.3312 - val_accuracy: 0.8729\n",
            "Epoch 104/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.8290 - val_loss: 0.3311 - val_accuracy: 0.8729\n",
            "Epoch 105/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3840 - accuracy: 0.8325 - val_loss: 0.3333 - val_accuracy: 0.8729\n",
            "Epoch 106/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8302 - val_loss: 0.3316 - val_accuracy: 0.8729\n",
            "Epoch 107/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.8314 - val_loss: 0.3320 - val_accuracy: 0.8729\n",
            "Epoch 108/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3824 - accuracy: 0.8337 - val_loss: 0.3312 - val_accuracy: 0.8729\n",
            "Epoch 109/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8337 - val_loss: 0.3325 - val_accuracy: 0.8729\n",
            "Epoch 110/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.8290 - val_loss: 0.3315 - val_accuracy: 0.8729\n",
            "Epoch 111/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3817 - accuracy: 0.8325 - val_loss: 0.3304 - val_accuracy: 0.8729\n",
            "Epoch 112/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.8302 - val_loss: 0.3305 - val_accuracy: 0.8729\n",
            "Epoch 113/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3811 - accuracy: 0.8349 - val_loss: 0.3316 - val_accuracy: 0.8729\n",
            "Epoch 114/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8337 - val_loss: 0.3314 - val_accuracy: 0.8729\n",
            "Epoch 115/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8349 - val_loss: 0.3321 - val_accuracy: 0.8729\n",
            "Epoch 116/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.8325 - val_loss: 0.3320 - val_accuracy: 0.8729\n",
            "Epoch 117/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3799 - accuracy: 0.8349 - val_loss: 0.3306 - val_accuracy: 0.8729\n",
            "Epoch 118/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8349 - val_loss: 0.3311 - val_accuracy: 0.8729\n",
            "Epoch 119/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8349 - val_loss: 0.3296 - val_accuracy: 0.8644\n",
            "Epoch 120/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8349 - val_loss: 0.3305 - val_accuracy: 0.8729\n",
            "Epoch 121/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8278 - val_loss: 0.3278 - val_accuracy: 0.8729\n",
            "Epoch 122/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8325 - val_loss: 0.3297 - val_accuracy: 0.8729\n",
            "Epoch 123/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.8278 - val_loss: 0.3290 - val_accuracy: 0.8729\n",
            "Epoch 124/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.8396 - val_loss: 0.3299 - val_accuracy: 0.8729\n",
            "Epoch 125/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.8314 - val_loss: 0.3280 - val_accuracy: 0.8729\n",
            "Epoch 126/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.8325 - val_loss: 0.3282 - val_accuracy: 0.8729\n",
            "Epoch 127/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3765 - accuracy: 0.8337 - val_loss: 0.3289 - val_accuracy: 0.8729\n",
            "Epoch 128/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8325 - val_loss: 0.3286 - val_accuracy: 0.8729\n",
            "Epoch 129/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8349 - val_loss: 0.3292 - val_accuracy: 0.8644\n",
            "Epoch 130/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8314 - val_loss: 0.3275 - val_accuracy: 0.8729\n",
            "Epoch 131/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8373 - val_loss: 0.3282 - val_accuracy: 0.8644\n",
            "Epoch 132/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8314 - val_loss: 0.3281 - val_accuracy: 0.8729\n",
            "Epoch 133/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3742 - accuracy: 0.8384 - val_loss: 0.3280 - val_accuracy: 0.8729\n",
            "Epoch 134/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8337 - val_loss: 0.3272 - val_accuracy: 0.8729\n",
            "Epoch 135/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8337 - val_loss: 0.3276 - val_accuracy: 0.8729\n",
            "Epoch 136/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8325 - val_loss: 0.3297 - val_accuracy: 0.8729\n",
            "Epoch 137/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8337 - val_loss: 0.3274 - val_accuracy: 0.8729\n",
            "Epoch 138/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3717 - accuracy: 0.8314 - val_loss: 0.3268 - val_accuracy: 0.8729\n",
            "Epoch 139/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3720 - accuracy: 0.8373 - val_loss: 0.3273 - val_accuracy: 0.8644\n",
            "Epoch 140/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8349 - val_loss: 0.3285 - val_accuracy: 0.8729\n",
            "Epoch 141/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3712 - accuracy: 0.8384 - val_loss: 0.3277 - val_accuracy: 0.8729\n",
            "Epoch 142/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8349 - val_loss: 0.3275 - val_accuracy: 0.8729\n",
            "Epoch 143/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8349 - val_loss: 0.3274 - val_accuracy: 0.8729\n",
            "Epoch 144/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3705 - accuracy: 0.8373 - val_loss: 0.3278 - val_accuracy: 0.8729\n",
            "Epoch 145/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3707 - accuracy: 0.8361 - val_loss: 0.3269 - val_accuracy: 0.8729\n",
            "Epoch 146/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3698 - accuracy: 0.8349 - val_loss: 0.3287 - val_accuracy: 0.8729\n",
            "Epoch 147/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3696 - accuracy: 0.8302 - val_loss: 0.3278 - val_accuracy: 0.8729\n",
            "Epoch 148/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8373 - val_loss: 0.3275 - val_accuracy: 0.8729\n",
            "Epoch 149/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8349 - val_loss: 0.3255 - val_accuracy: 0.8814\n",
            "Epoch 150/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3687 - accuracy: 0.8361 - val_loss: 0.3273 - val_accuracy: 0.8729\n",
            "Epoch 151/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3683 - accuracy: 0.8361 - val_loss: 0.3277 - val_accuracy: 0.8729\n",
            "Epoch 152/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3681 - accuracy: 0.8373 - val_loss: 0.3267 - val_accuracy: 0.8729\n",
            "Epoch 153/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3678 - accuracy: 0.8349 - val_loss: 0.3275 - val_accuracy: 0.8729\n",
            "Epoch 154/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3675 - accuracy: 0.8325 - val_loss: 0.3273 - val_accuracy: 0.8814\n",
            "Epoch 155/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8349 - val_loss: 0.3282 - val_accuracy: 0.8729\n",
            "Epoch 156/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3669 - accuracy: 0.8361 - val_loss: 0.3275 - val_accuracy: 0.8729\n",
            "Epoch 157/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3668 - accuracy: 0.8384 - val_loss: 0.3277 - val_accuracy: 0.8729\n",
            "Epoch 158/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3668 - accuracy: 0.8337 - val_loss: 0.3278 - val_accuracy: 0.8814\n",
            "Epoch 159/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3659 - accuracy: 0.8349 - val_loss: 0.3271 - val_accuracy: 0.8729\n",
            "Epoch 160/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3660 - accuracy: 0.8361 - val_loss: 0.3269 - val_accuracy: 0.8729\n",
            "Epoch 161/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3658 - accuracy: 0.8361 - val_loss: 0.3294 - val_accuracy: 0.8729\n",
            "Epoch 162/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3654 - accuracy: 0.8349 - val_loss: 0.3250 - val_accuracy: 0.8814\n",
            "Epoch 163/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8349 - val_loss: 0.3263 - val_accuracy: 0.8814\n",
            "Epoch 164/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3650 - accuracy: 0.8361 - val_loss: 0.3282 - val_accuracy: 0.8729\n",
            "Epoch 165/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3644 - accuracy: 0.8361 - val_loss: 0.3268 - val_accuracy: 0.8644\n",
            "Epoch 166/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8361 - val_loss: 0.3263 - val_accuracy: 0.8814\n",
            "Epoch 167/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.8373 - val_loss: 0.3276 - val_accuracy: 0.8814\n",
            "Epoch 168/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3640 - accuracy: 0.8349 - val_loss: 0.3292 - val_accuracy: 0.8729\n",
            "Epoch 169/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8349 - val_loss: 0.3287 - val_accuracy: 0.8814\n",
            "Epoch 170/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3638 - accuracy: 0.8361 - val_loss: 0.3278 - val_accuracy: 0.8729\n",
            "Epoch 171/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3632 - accuracy: 0.8373 - val_loss: 0.3298 - val_accuracy: 0.8814\n",
            "Epoch 172/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3627 - accuracy: 0.8373 - val_loss: 0.3284 - val_accuracy: 0.8729\n",
            "Epoch 173/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3631 - accuracy: 0.8349 - val_loss: 0.3293 - val_accuracy: 0.8729\n",
            "Epoch 174/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3626 - accuracy: 0.8361 - val_loss: 0.3290 - val_accuracy: 0.8814\n",
            "Epoch 175/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3625 - accuracy: 0.8373 - val_loss: 0.3282 - val_accuracy: 0.8814\n",
            "Epoch 176/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3627 - accuracy: 0.8373 - val_loss: 0.3308 - val_accuracy: 0.8814\n",
            "Epoch 177/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3617 - accuracy: 0.8373 - val_loss: 0.3286 - val_accuracy: 0.8814\n",
            "Epoch 178/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3616 - accuracy: 0.8361 - val_loss: 0.3302 - val_accuracy: 0.8814\n",
            "Epoch 179/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3611 - accuracy: 0.8361 - val_loss: 0.3293 - val_accuracy: 0.8814\n",
            "Epoch 180/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3607 - accuracy: 0.8349 - val_loss: 0.3299 - val_accuracy: 0.8814\n",
            "Epoch 181/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3610 - accuracy: 0.8373 - val_loss: 0.3299 - val_accuracy: 0.8814\n",
            "Epoch 182/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3608 - accuracy: 0.8337 - val_loss: 0.3288 - val_accuracy: 0.8814\n",
            "Epoch 183/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3606 - accuracy: 0.8337 - val_loss: 0.3304 - val_accuracy: 0.8814\n",
            "Epoch 184/200\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8361 - val_loss: 0.3294 - val_accuracy: 0.8814\n",
            "Epoch 185/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3601 - accuracy: 0.8384 - val_loss: 0.3283 - val_accuracy: 0.8814\n",
            "Epoch 186/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3598 - accuracy: 0.8349 - val_loss: 0.3280 - val_accuracy: 0.8814\n",
            "Epoch 187/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3598 - accuracy: 0.8373 - val_loss: 0.3296 - val_accuracy: 0.8814\n",
            "Epoch 188/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3593 - accuracy: 0.8396 - val_loss: 0.3306 - val_accuracy: 0.8814\n",
            "Epoch 189/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3599 - accuracy: 0.8373 - val_loss: 0.3296 - val_accuracy: 0.8814\n",
            "Epoch 190/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3595 - accuracy: 0.8373 - val_loss: 0.3297 - val_accuracy: 0.8814\n",
            "Epoch 191/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3593 - accuracy: 0.8396 - val_loss: 0.3315 - val_accuracy: 0.8814\n",
            "Epoch 192/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3587 - accuracy: 0.8361 - val_loss: 0.3302 - val_accuracy: 0.8814\n",
            "Epoch 193/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3589 - accuracy: 0.8396 - val_loss: 0.3317 - val_accuracy: 0.8814\n",
            "Epoch 194/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3585 - accuracy: 0.8337 - val_loss: 0.3304 - val_accuracy: 0.8814\n",
            "Epoch 195/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3580 - accuracy: 0.8361 - val_loss: 0.3305 - val_accuracy: 0.8814\n",
            "Epoch 196/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3580 - accuracy: 0.8396 - val_loss: 0.3304 - val_accuracy: 0.8814\n",
            "Epoch 197/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3576 - accuracy: 0.8373 - val_loss: 0.3316 - val_accuracy: 0.8814\n",
            "Epoch 198/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3574 - accuracy: 0.8396 - val_loss: 0.3320 - val_accuracy: 0.8814\n",
            "Epoch 199/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3572 - accuracy: 0.8396 - val_loss: 0.3319 - val_accuracy: 0.8814\n",
            "Epoch 200/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3572 - accuracy: 0.8396 - val_loss: 0.3338 - val_accuracy: 0.8814\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 2s 32ms/step - loss: 0.6830 - accuracy: 0.5790 - val_loss: 0.6682 - val_accuracy: 0.5932\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6594 - accuracy: 0.6250 - val_loss: 0.6475 - val_accuracy: 0.6102\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.6344 - val_loss: 0.6286 - val_accuracy: 0.6271\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6204 - accuracy: 0.6580 - val_loss: 0.6088 - val_accuracy: 0.6525\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6018 - accuracy: 0.6934 - val_loss: 0.5892 - val_accuracy: 0.7034\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5842 - accuracy: 0.7182 - val_loss: 0.5676 - val_accuracy: 0.7034\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5666 - accuracy: 0.7441 - val_loss: 0.5458 - val_accuracy: 0.7373\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5501 - accuracy: 0.7736 - val_loss: 0.5265 - val_accuracy: 0.7797\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5356 - accuracy: 0.7854 - val_loss: 0.5081 - val_accuracy: 0.8051\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5225 - accuracy: 0.7948 - val_loss: 0.4901 - val_accuracy: 0.8390\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.8019 - val_loss: 0.4753 - val_accuracy: 0.8390\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5010 - accuracy: 0.8078 - val_loss: 0.4625 - val_accuracy: 0.8475\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4928 - accuracy: 0.8137 - val_loss: 0.4522 - val_accuracy: 0.8559\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.8113 - val_loss: 0.4430 - val_accuracy: 0.8475\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.8078 - val_loss: 0.4352 - val_accuracy: 0.8475\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.8078 - val_loss: 0.4281 - val_accuracy: 0.8475\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.8101 - val_loss: 0.4220 - val_accuracy: 0.8475\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4666 - accuracy: 0.8113 - val_loss: 0.4166 - val_accuracy: 0.8475\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4632 - accuracy: 0.8125 - val_loss: 0.4110 - val_accuracy: 0.8475\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.8113 - val_loss: 0.4070 - val_accuracy: 0.8475\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.8137 - val_loss: 0.4030 - val_accuracy: 0.8475\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.8113 - val_loss: 0.3987 - val_accuracy: 0.8390\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.8137 - val_loss: 0.3949 - val_accuracy: 0.8390\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.8137 - val_loss: 0.3915 - val_accuracy: 0.8475\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.8184 - val_loss: 0.3891 - val_accuracy: 0.8559\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.8196 - val_loss: 0.3849 - val_accuracy: 0.8559\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4430 - accuracy: 0.8196 - val_loss: 0.3827 - val_accuracy: 0.8559\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4414 - accuracy: 0.8196 - val_loss: 0.3796 - val_accuracy: 0.8644\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.8172 - val_loss: 0.3767 - val_accuracy: 0.8559\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.8208 - val_loss: 0.3741 - val_accuracy: 0.8559\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4360 - accuracy: 0.8243 - val_loss: 0.3722 - val_accuracy: 0.8644\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.8184 - val_loss: 0.3694 - val_accuracy: 0.8644\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.8208 - val_loss: 0.3670 - val_accuracy: 0.8644\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.8231 - val_loss: 0.3651 - val_accuracy: 0.8729\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.8196 - val_loss: 0.3630 - val_accuracy: 0.8644\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4272 - accuracy: 0.8219 - val_loss: 0.3608 - val_accuracy: 0.8644\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8219 - val_loss: 0.3583 - val_accuracy: 0.8729\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8208 - val_loss: 0.3573 - val_accuracy: 0.8814\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8219 - val_loss: 0.3542 - val_accuracy: 0.8814\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8208 - val_loss: 0.3526 - val_accuracy: 0.8814\n",
            "Epoch 41/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.8231 - val_loss: 0.3508 - val_accuracy: 0.8898\n",
            "Epoch 42/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.8208 - val_loss: 0.3505 - val_accuracy: 0.8898\n",
            "Epoch 43/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8243 - val_loss: 0.3485 - val_accuracy: 0.8983\n",
            "Epoch 44/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8243 - val_loss: 0.3468 - val_accuracy: 0.8983\n",
            "Epoch 45/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8231 - val_loss: 0.3439 - val_accuracy: 0.8898\n",
            "Epoch 46/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8290 - val_loss: 0.3425 - val_accuracy: 0.8983\n",
            "Epoch 47/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8302 - val_loss: 0.3412 - val_accuracy: 0.8983\n",
            "Epoch 48/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8290 - val_loss: 0.3393 - val_accuracy: 0.8983\n",
            "Epoch 49/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8278 - val_loss: 0.3380 - val_accuracy: 0.8983\n",
            "Epoch 50/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8302 - val_loss: 0.3381 - val_accuracy: 0.8898\n",
            "Epoch 51/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8290 - val_loss: 0.3373 - val_accuracy: 0.8898\n",
            "Epoch 52/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8314 - val_loss: 0.3341 - val_accuracy: 0.8983\n",
            "Epoch 53/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8278 - val_loss: 0.3321 - val_accuracy: 0.8983\n",
            "Epoch 54/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.8290 - val_loss: 0.3324 - val_accuracy: 0.8898\n",
            "Epoch 55/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8314 - val_loss: 0.3313 - val_accuracy: 0.8898\n",
            "Epoch 56/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8302 - val_loss: 0.3310 - val_accuracy: 0.8898\n",
            "Epoch 57/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8290 - val_loss: 0.3312 - val_accuracy: 0.8814\n",
            "Epoch 58/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4024 - accuracy: 0.8302 - val_loss: 0.3283 - val_accuracy: 0.8898\n",
            "Epoch 59/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8314 - val_loss: 0.3279 - val_accuracy: 0.8814\n",
            "Epoch 60/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8302 - val_loss: 0.3277 - val_accuracy: 0.8814\n",
            "Epoch 61/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4006 - accuracy: 0.8373 - val_loss: 0.3250 - val_accuracy: 0.8898\n",
            "Epoch 62/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8278 - val_loss: 0.3251 - val_accuracy: 0.8814\n",
            "Epoch 63/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8290 - val_loss: 0.3234 - val_accuracy: 0.8814\n",
            "Epoch 64/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8278 - val_loss: 0.3251 - val_accuracy: 0.8814\n",
            "Epoch 65/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8314 - val_loss: 0.3233 - val_accuracy: 0.8814\n",
            "Epoch 66/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8290 - val_loss: 0.3229 - val_accuracy: 0.8898\n",
            "Epoch 67/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8361 - val_loss: 0.3215 - val_accuracy: 0.8898\n",
            "Epoch 68/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8349 - val_loss: 0.3215 - val_accuracy: 0.8814\n",
            "Epoch 69/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8349 - val_loss: 0.3208 - val_accuracy: 0.8898\n",
            "Epoch 70/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8349 - val_loss: 0.3209 - val_accuracy: 0.8814\n",
            "Epoch 71/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8349 - val_loss: 0.3200 - val_accuracy: 0.8814\n",
            "Epoch 72/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8337 - val_loss: 0.3177 - val_accuracy: 0.8814\n",
            "Epoch 73/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8396 - val_loss: 0.3180 - val_accuracy: 0.8898\n",
            "Epoch 74/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8314 - val_loss: 0.3170 - val_accuracy: 0.8814\n",
            "Epoch 75/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8373 - val_loss: 0.3161 - val_accuracy: 0.8814\n",
            "Epoch 76/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8325 - val_loss: 0.3151 - val_accuracy: 0.8814\n",
            "Epoch 77/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8361 - val_loss: 0.3152 - val_accuracy: 0.8814\n",
            "Epoch 78/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8361 - val_loss: 0.3138 - val_accuracy: 0.8814\n",
            "Epoch 79/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8349 - val_loss: 0.3140 - val_accuracy: 0.8729\n",
            "Epoch 80/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3909 - accuracy: 0.8349 - val_loss: 0.3146 - val_accuracy: 0.8898\n",
            "Epoch 81/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3903 - accuracy: 0.8349 - val_loss: 0.3133 - val_accuracy: 0.8814\n",
            "Epoch 82/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3900 - accuracy: 0.8349 - val_loss: 0.3112 - val_accuracy: 0.8814\n",
            "Epoch 83/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8314 - val_loss: 0.3109 - val_accuracy: 0.8729\n",
            "Epoch 84/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3894 - accuracy: 0.8361 - val_loss: 0.3105 - val_accuracy: 0.8729\n",
            "Epoch 85/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3897 - accuracy: 0.8384 - val_loss: 0.3101 - val_accuracy: 0.8814\n",
            "Epoch 86/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8349 - val_loss: 0.3098 - val_accuracy: 0.8729\n",
            "Epoch 87/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3888 - accuracy: 0.8361 - val_loss: 0.3089 - val_accuracy: 0.8729\n",
            "Epoch 88/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8325 - val_loss: 0.3100 - val_accuracy: 0.8729\n",
            "Epoch 89/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8349 - val_loss: 0.3089 - val_accuracy: 0.8644\n",
            "Epoch 90/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3877 - accuracy: 0.8349 - val_loss: 0.3072 - val_accuracy: 0.8729\n",
            "Epoch 91/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3873 - accuracy: 0.8384 - val_loss: 0.3063 - val_accuracy: 0.8814\n",
            "Epoch 92/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8384 - val_loss: 0.3074 - val_accuracy: 0.8644\n",
            "Epoch 93/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3873 - accuracy: 0.8373 - val_loss: 0.3079 - val_accuracy: 0.8814\n",
            "Epoch 94/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3867 - accuracy: 0.8396 - val_loss: 0.3074 - val_accuracy: 0.8729\n",
            "Epoch 95/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3866 - accuracy: 0.8373 - val_loss: 0.3076 - val_accuracy: 0.8814\n",
            "Epoch 96/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3864 - accuracy: 0.8361 - val_loss: 0.3067 - val_accuracy: 0.8729\n",
            "Epoch 97/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3857 - accuracy: 0.8361 - val_loss: 0.3058 - val_accuracy: 0.8898\n",
            "Epoch 98/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3860 - accuracy: 0.8361 - val_loss: 0.3063 - val_accuracy: 0.8729\n",
            "Epoch 99/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3858 - accuracy: 0.8361 - val_loss: 0.3073 - val_accuracy: 0.8898\n",
            "Epoch 100/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3848 - accuracy: 0.8384 - val_loss: 0.3045 - val_accuracy: 0.8814\n",
            "Epoch 101/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3849 - accuracy: 0.8349 - val_loss: 0.3048 - val_accuracy: 0.8814\n",
            "Epoch 102/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3846 - accuracy: 0.8361 - val_loss: 0.3064 - val_accuracy: 0.8644\n",
            "Epoch 103/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3851 - accuracy: 0.8361 - val_loss: 0.3047 - val_accuracy: 0.8729\n",
            "Epoch 104/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.8325 - val_loss: 0.3041 - val_accuracy: 0.8729\n",
            "Epoch 105/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8337 - val_loss: 0.3039 - val_accuracy: 0.8729\n",
            "Epoch 106/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3835 - accuracy: 0.8396 - val_loss: 0.3040 - val_accuracy: 0.8644\n",
            "Epoch 107/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3834 - accuracy: 0.8373 - val_loss: 0.3053 - val_accuracy: 0.8729\n",
            "Epoch 108/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.8384 - val_loss: 0.3034 - val_accuracy: 0.8814\n",
            "Epoch 109/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.8384 - val_loss: 0.3031 - val_accuracy: 0.8729\n",
            "Epoch 110/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.8314 - val_loss: 0.3038 - val_accuracy: 0.8814\n",
            "Epoch 111/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8384 - val_loss: 0.3055 - val_accuracy: 0.8729\n",
            "Epoch 112/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.8314 - val_loss: 0.3053 - val_accuracy: 0.8814\n",
            "Epoch 113/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.8349 - val_loss: 0.3040 - val_accuracy: 0.8814\n",
            "Epoch 114/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.8361 - val_loss: 0.3052 - val_accuracy: 0.8814\n",
            "Epoch 115/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8361 - val_loss: 0.3033 - val_accuracy: 0.8814\n",
            "Epoch 116/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3811 - accuracy: 0.8408 - val_loss: 0.3045 - val_accuracy: 0.8814\n",
            "Epoch 117/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.8396 - val_loss: 0.3026 - val_accuracy: 0.8814\n",
            "Epoch 118/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.8361 - val_loss: 0.3028 - val_accuracy: 0.8814\n",
            "Epoch 119/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.8373 - val_loss: 0.3042 - val_accuracy: 0.8814\n",
            "Epoch 120/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8373 - val_loss: 0.3049 - val_accuracy: 0.8814\n",
            "Epoch 121/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3803 - accuracy: 0.8384 - val_loss: 0.3037 - val_accuracy: 0.8814\n",
            "Epoch 122/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.8361 - val_loss: 0.3040 - val_accuracy: 0.8729\n",
            "Epoch 123/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8384 - val_loss: 0.3044 - val_accuracy: 0.8983\n",
            "Epoch 124/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8361 - val_loss: 0.3043 - val_accuracy: 0.8729\n",
            "Epoch 125/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3796 - accuracy: 0.8349 - val_loss: 0.3032 - val_accuracy: 0.8729\n",
            "Epoch 126/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8314 - val_loss: 0.3035 - val_accuracy: 0.8729\n",
            "Epoch 127/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.8384 - val_loss: 0.3034 - val_accuracy: 0.8729\n",
            "Epoch 128/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8408 - val_loss: 0.3040 - val_accuracy: 0.8729\n",
            "Epoch 129/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8349 - val_loss: 0.3032 - val_accuracy: 0.8729\n",
            "Epoch 130/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.8361 - val_loss: 0.3036 - val_accuracy: 0.8814\n",
            "Epoch 131/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3789 - accuracy: 0.8337 - val_loss: 0.3021 - val_accuracy: 0.8729\n",
            "Epoch 132/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8384 - val_loss: 0.3035 - val_accuracy: 0.8898\n",
            "Epoch 133/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3782 - accuracy: 0.8373 - val_loss: 0.3028 - val_accuracy: 0.8898\n",
            "Epoch 134/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3777 - accuracy: 0.8384 - val_loss: 0.3021 - val_accuracy: 0.8729\n",
            "Epoch 135/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8384 - val_loss: 0.3042 - val_accuracy: 0.8729\n",
            "Epoch 136/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8396 - val_loss: 0.3020 - val_accuracy: 0.8814\n",
            "Epoch 137/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8373 - val_loss: 0.3029 - val_accuracy: 0.8814\n",
            "Epoch 138/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3777 - accuracy: 0.8361 - val_loss: 0.3035 - val_accuracy: 0.8814\n",
            "Epoch 139/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8408 - val_loss: 0.3039 - val_accuracy: 0.8729\n",
            "Epoch 140/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.8325 - val_loss: 0.3041 - val_accuracy: 0.8898\n",
            "Epoch 141/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.8384 - val_loss: 0.3041 - val_accuracy: 0.8729\n",
            "Epoch 142/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.8384 - val_loss: 0.3056 - val_accuracy: 0.8898\n",
            "Epoch 143/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3765 - accuracy: 0.8349 - val_loss: 0.3011 - val_accuracy: 0.8898\n",
            "Epoch 144/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.8384 - val_loss: 0.3041 - val_accuracy: 0.8898\n",
            "Epoch 145/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3763 - accuracy: 0.8408 - val_loss: 0.3008 - val_accuracy: 0.8814\n",
            "Epoch 146/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.8373 - val_loss: 0.3026 - val_accuracy: 0.8814\n",
            "Epoch 147/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8384 - val_loss: 0.3012 - val_accuracy: 0.8729\n",
            "Epoch 148/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.8349 - val_loss: 0.3027 - val_accuracy: 0.8814\n",
            "Epoch 149/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8408 - val_loss: 0.3032 - val_accuracy: 0.8814\n",
            "Epoch 150/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8420 - val_loss: 0.3028 - val_accuracy: 0.8814\n",
            "Epoch 151/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8396 - val_loss: 0.3032 - val_accuracy: 0.8814\n",
            "Epoch 152/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.8361 - val_loss: 0.3034 - val_accuracy: 0.8814\n",
            "Epoch 153/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.8396 - val_loss: 0.3034 - val_accuracy: 0.8814\n",
            "Epoch 154/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8373 - val_loss: 0.3036 - val_accuracy: 0.8729\n",
            "Epoch 155/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8373 - val_loss: 0.3031 - val_accuracy: 0.8729\n",
            "Epoch 156/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8408 - val_loss: 0.3049 - val_accuracy: 0.8729\n",
            "Epoch 157/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.8384 - val_loss: 0.3037 - val_accuracy: 0.8814\n",
            "Epoch 158/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8420 - val_loss: 0.3035 - val_accuracy: 0.8729\n",
            "Epoch 159/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.8408 - val_loss: 0.3016 - val_accuracy: 0.8898\n",
            "Epoch 160/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8384 - val_loss: 0.3039 - val_accuracy: 0.8729\n",
            "Epoch 161/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8420 - val_loss: 0.3045 - val_accuracy: 0.8814\n",
            "Epoch 162/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8420 - val_loss: 0.3061 - val_accuracy: 0.8729\n",
            "Epoch 163/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.8408 - val_loss: 0.3045 - val_accuracy: 0.8729\n",
            "Epoch 164/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8349 - val_loss: 0.3031 - val_accuracy: 0.8814\n",
            "Epoch 165/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8373 - val_loss: 0.3033 - val_accuracy: 0.8729\n",
            "Epoch 166/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8420 - val_loss: 0.3066 - val_accuracy: 0.8729\n",
            "Epoch 167/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.8373 - val_loss: 0.3043 - val_accuracy: 0.8729\n",
            "Epoch 168/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3730 - accuracy: 0.8384 - val_loss: 0.3045 - val_accuracy: 0.8729\n",
            "Epoch 169/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.8349 - val_loss: 0.3048 - val_accuracy: 0.8729\n",
            "Epoch 170/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3730 - accuracy: 0.8384 - val_loss: 0.3059 - val_accuracy: 0.8729\n",
            "Epoch 171/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8361 - val_loss: 0.3080 - val_accuracy: 0.8729\n",
            "Epoch 172/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.8373 - val_loss: 0.3054 - val_accuracy: 0.8729\n",
            "Epoch 173/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8396 - val_loss: 0.3056 - val_accuracy: 0.8729\n",
            "Epoch 174/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.8373 - val_loss: 0.3076 - val_accuracy: 0.8814\n",
            "Epoch 175/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8384 - val_loss: 0.3059 - val_accuracy: 0.8729\n",
            "Epoch 176/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8337 - val_loss: 0.3028 - val_accuracy: 0.8814\n",
            "Epoch 177/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3711 - accuracy: 0.8396 - val_loss: 0.3032 - val_accuracy: 0.8729\n",
            "Epoch 178/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8408 - val_loss: 0.3048 - val_accuracy: 0.8729\n",
            "Epoch 179/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3705 - accuracy: 0.8408 - val_loss: 0.3050 - val_accuracy: 0.8814\n",
            "Epoch 180/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3708 - accuracy: 0.8408 - val_loss: 0.3042 - val_accuracy: 0.8729\n",
            "Epoch 181/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8408 - val_loss: 0.3039 - val_accuracy: 0.8729\n",
            "Epoch 182/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3694 - accuracy: 0.8396 - val_loss: 0.3045 - val_accuracy: 0.8729\n",
            "Epoch 183/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3697 - accuracy: 0.8408 - val_loss: 0.3042 - val_accuracy: 0.8729\n",
            "Epoch 184/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3694 - accuracy: 0.8432 - val_loss: 0.3045 - val_accuracy: 0.8729\n",
            "Epoch 185/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3695 - accuracy: 0.8384 - val_loss: 0.3069 - val_accuracy: 0.8729\n",
            "Epoch 186/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8384 - val_loss: 0.3029 - val_accuracy: 0.8729\n",
            "Epoch 187/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8396 - val_loss: 0.3073 - val_accuracy: 0.8729\n",
            "Epoch 188/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3688 - accuracy: 0.8408 - val_loss: 0.3091 - val_accuracy: 0.8814\n",
            "Epoch 189/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3684 - accuracy: 0.8408 - val_loss: 0.3042 - val_accuracy: 0.8814\n",
            "Epoch 190/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3684 - accuracy: 0.8408 - val_loss: 0.3053 - val_accuracy: 0.8729\n",
            "Epoch 191/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8396 - val_loss: 0.3064 - val_accuracy: 0.8814\n",
            "Epoch 192/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3678 - accuracy: 0.8420 - val_loss: 0.3055 - val_accuracy: 0.8814\n",
            "Epoch 193/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3685 - accuracy: 0.8408 - val_loss: 0.3054 - val_accuracy: 0.8729\n",
            "Epoch 194/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8384 - val_loss: 0.3035 - val_accuracy: 0.8729\n",
            "Epoch 195/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8396 - val_loss: 0.3093 - val_accuracy: 0.8729\n",
            "Epoch 196/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3673 - accuracy: 0.8408 - val_loss: 0.3094 - val_accuracy: 0.8814\n",
            "Epoch 197/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3671 - accuracy: 0.8408 - val_loss: 0.3091 - val_accuracy: 0.8814\n",
            "Epoch 198/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8408 - val_loss: 0.3094 - val_accuracy: 0.8814\n",
            "Epoch 199/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3668 - accuracy: 0.8396 - val_loss: 0.3074 - val_accuracy: 0.8814\n",
            "Epoch 200/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8432 - val_loss: 0.3063 - val_accuracy: 0.8729\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 1s 12ms/step - loss: 0.6934 - accuracy: 0.5106 - val_loss: 0.6771 - val_accuracy: 0.6441\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6593 - accuracy: 0.6722 - val_loss: 0.6453 - val_accuracy: 0.7203\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6317 - accuracy: 0.7040 - val_loss: 0.6170 - val_accuracy: 0.7288\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6069 - accuracy: 0.7323 - val_loss: 0.5910 - val_accuracy: 0.7458\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5840 - accuracy: 0.7500 - val_loss: 0.5653 - val_accuracy: 0.7542\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5631 - accuracy: 0.7583 - val_loss: 0.5420 - val_accuracy: 0.7966\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5451 - accuracy: 0.7748 - val_loss: 0.5197 - val_accuracy: 0.8136\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5298 - accuracy: 0.7854 - val_loss: 0.5005 - val_accuracy: 0.8220\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5173 - accuracy: 0.7877 - val_loss: 0.4842 - val_accuracy: 0.8559\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5069 - accuracy: 0.7995 - val_loss: 0.4695 - val_accuracy: 0.8475\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4981 - accuracy: 0.7960 - val_loss: 0.4568 - val_accuracy: 0.8644\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4908 - accuracy: 0.7995 - val_loss: 0.4463 - val_accuracy: 0.8644\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.8019 - val_loss: 0.4380 - val_accuracy: 0.8559\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.8031 - val_loss: 0.4310 - val_accuracy: 0.8559\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.8066 - val_loss: 0.4237 - val_accuracy: 0.8559\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.8066 - val_loss: 0.4178 - val_accuracy: 0.8559\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.8078 - val_loss: 0.4130 - val_accuracy: 0.8644\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.8125 - val_loss: 0.4086 - val_accuracy: 0.8559\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.8137 - val_loss: 0.4052 - val_accuracy: 0.8644\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.8125 - val_loss: 0.4009 - val_accuracy: 0.8559\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.8113 - val_loss: 0.3977 - val_accuracy: 0.8559\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.8125 - val_loss: 0.3944 - val_accuracy: 0.8559\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4510 - accuracy: 0.8137 - val_loss: 0.3926 - val_accuracy: 0.8644\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.8172 - val_loss: 0.3903 - val_accuracy: 0.8559\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.8172 - val_loss: 0.3884 - val_accuracy: 0.8475\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.8160 - val_loss: 0.3862 - val_accuracy: 0.8475\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.8160 - val_loss: 0.3851 - val_accuracy: 0.8390\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.8184 - val_loss: 0.3838 - val_accuracy: 0.8390\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.8196 - val_loss: 0.3824 - val_accuracy: 0.8305\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.8184 - val_loss: 0.3800 - val_accuracy: 0.8475\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.8172 - val_loss: 0.3780 - val_accuracy: 0.8475\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.8184 - val_loss: 0.3766 - val_accuracy: 0.8390\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.8196 - val_loss: 0.3752 - val_accuracy: 0.8475\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.8172 - val_loss: 0.3744 - val_accuracy: 0.8390\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.8172 - val_loss: 0.3732 - val_accuracy: 0.8475\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.8172 - val_loss: 0.3721 - val_accuracy: 0.8559\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.8160 - val_loss: 0.3719 - val_accuracy: 0.8475\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.8196 - val_loss: 0.3710 - val_accuracy: 0.8729\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.8196 - val_loss: 0.3679 - val_accuracy: 0.8644\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.8184 - val_loss: 0.3684 - val_accuracy: 0.8559\n",
            "Epoch 41/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.8184 - val_loss: 0.3668 - val_accuracy: 0.8644\n",
            "Epoch 42/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8219 - val_loss: 0.3671 - val_accuracy: 0.8559\n",
            "Epoch 43/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.8196 - val_loss: 0.3657 - val_accuracy: 0.8644\n",
            "Epoch 44/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8208 - val_loss: 0.3656 - val_accuracy: 0.8559\n",
            "Epoch 45/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.8196 - val_loss: 0.3651 - val_accuracy: 0.8644\n",
            "Epoch 46/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.8219 - val_loss: 0.3631 - val_accuracy: 0.8559\n",
            "Epoch 47/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4163 - accuracy: 0.8208 - val_loss: 0.3628 - val_accuracy: 0.8644\n",
            "Epoch 48/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8196 - val_loss: 0.3615 - val_accuracy: 0.8644\n",
            "Epoch 49/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8231 - val_loss: 0.3604 - val_accuracy: 0.8729\n",
            "Epoch 50/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8208 - val_loss: 0.3598 - val_accuracy: 0.8644\n",
            "Epoch 51/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8196 - val_loss: 0.3590 - val_accuracy: 0.8475\n",
            "Epoch 52/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8231 - val_loss: 0.3590 - val_accuracy: 0.8475\n",
            "Epoch 53/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8208 - val_loss: 0.3574 - val_accuracy: 0.8559\n",
            "Epoch 54/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4099 - accuracy: 0.8219 - val_loss: 0.3568 - val_accuracy: 0.8559\n",
            "Epoch 55/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.8219 - val_loss: 0.3574 - val_accuracy: 0.8644\n",
            "Epoch 56/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.8219 - val_loss: 0.3568 - val_accuracy: 0.8559\n",
            "Epoch 57/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8196 - val_loss: 0.3553 - val_accuracy: 0.8644\n",
            "Epoch 58/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4062 - accuracy: 0.8208 - val_loss: 0.3555 - val_accuracy: 0.8475\n",
            "Epoch 59/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.8243 - val_loss: 0.3548 - val_accuracy: 0.8475\n",
            "Epoch 60/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4045 - accuracy: 0.8231 - val_loss: 0.3546 - val_accuracy: 0.8475\n",
            "Epoch 61/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.8231 - val_loss: 0.3533 - val_accuracy: 0.8644\n",
            "Epoch 62/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.8243 - val_loss: 0.3526 - val_accuracy: 0.8475\n",
            "Epoch 63/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8231 - val_loss: 0.3518 - val_accuracy: 0.8390\n",
            "Epoch 64/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.8208 - val_loss: 0.3520 - val_accuracy: 0.8475\n",
            "Epoch 65/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8243 - val_loss: 0.3510 - val_accuracy: 0.8475\n",
            "Epoch 66/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8255 - val_loss: 0.3515 - val_accuracy: 0.8559\n",
            "Epoch 67/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8267 - val_loss: 0.3502 - val_accuracy: 0.8475\n",
            "Epoch 68/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8278 - val_loss: 0.3500 - val_accuracy: 0.8729\n",
            "Epoch 69/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8267 - val_loss: 0.3489 - val_accuracy: 0.8559\n",
            "Epoch 70/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8255 - val_loss: 0.3501 - val_accuracy: 0.8644\n",
            "Epoch 71/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8278 - val_loss: 0.3485 - val_accuracy: 0.8644\n",
            "Epoch 72/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8267 - val_loss: 0.3489 - val_accuracy: 0.8559\n",
            "Epoch 73/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8278 - val_loss: 0.3478 - val_accuracy: 0.8475\n",
            "Epoch 74/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8243 - val_loss: 0.3462 - val_accuracy: 0.8475\n",
            "Epoch 75/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8278 - val_loss: 0.3490 - val_accuracy: 0.8644\n",
            "Epoch 76/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8267 - val_loss: 0.3467 - val_accuracy: 0.8559\n",
            "Epoch 77/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8278 - val_loss: 0.3475 - val_accuracy: 0.8559\n",
            "Epoch 78/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8278 - val_loss: 0.3466 - val_accuracy: 0.8559\n",
            "Epoch 79/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8278 - val_loss: 0.3450 - val_accuracy: 0.8559\n",
            "Epoch 80/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8278 - val_loss: 0.3442 - val_accuracy: 0.8559\n",
            "Epoch 81/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3914 - accuracy: 0.8314 - val_loss: 0.3451 - val_accuracy: 0.8559\n",
            "Epoch 82/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8278 - val_loss: 0.3440 - val_accuracy: 0.8559\n",
            "Epoch 83/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3901 - accuracy: 0.8325 - val_loss: 0.3433 - val_accuracy: 0.8475\n",
            "Epoch 84/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3898 - accuracy: 0.8314 - val_loss: 0.3430 - val_accuracy: 0.8559\n",
            "Epoch 85/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3892 - accuracy: 0.8314 - val_loss: 0.3417 - val_accuracy: 0.8475\n",
            "Epoch 86/200\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 0.3900 - accuracy: 0.8302 - val_loss: 0.3425 - val_accuracy: 0.8475\n",
            "Epoch 87/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3882 - accuracy: 0.8396 - val_loss: 0.3424 - val_accuracy: 0.8644\n",
            "Epoch 88/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3882 - accuracy: 0.8349 - val_loss: 0.3401 - val_accuracy: 0.8559\n",
            "Epoch 89/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3873 - accuracy: 0.8361 - val_loss: 0.3403 - val_accuracy: 0.8559\n",
            "Epoch 90/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3870 - accuracy: 0.8373 - val_loss: 0.3403 - val_accuracy: 0.8475\n",
            "Epoch 91/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3867 - accuracy: 0.8349 - val_loss: 0.3403 - val_accuracy: 0.8475\n",
            "Epoch 92/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8408 - val_loss: 0.3409 - val_accuracy: 0.8559\n",
            "Epoch 93/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8373 - val_loss: 0.3385 - val_accuracy: 0.8475\n",
            "Epoch 94/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3852 - accuracy: 0.8396 - val_loss: 0.3383 - val_accuracy: 0.8475\n",
            "Epoch 95/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3850 - accuracy: 0.8361 - val_loss: 0.3392 - val_accuracy: 0.8644\n",
            "Epoch 96/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8349 - val_loss: 0.3374 - val_accuracy: 0.8475\n",
            "Epoch 97/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8337 - val_loss: 0.3409 - val_accuracy: 0.8475\n",
            "Epoch 98/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8337 - val_loss: 0.3359 - val_accuracy: 0.8729\n",
            "Epoch 99/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3833 - accuracy: 0.8361 - val_loss: 0.3366 - val_accuracy: 0.8559\n",
            "Epoch 100/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8373 - val_loss: 0.3354 - val_accuracy: 0.8559\n",
            "Epoch 101/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.8384 - val_loss: 0.3352 - val_accuracy: 0.8559\n",
            "Epoch 102/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8384 - val_loss: 0.3349 - val_accuracy: 0.8475\n",
            "Epoch 103/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.8373 - val_loss: 0.3360 - val_accuracy: 0.8729\n",
            "Epoch 104/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.8384 - val_loss: 0.3331 - val_accuracy: 0.8559\n",
            "Epoch 105/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3812 - accuracy: 0.8384 - val_loss: 0.3351 - val_accuracy: 0.8644\n",
            "Epoch 106/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8420 - val_loss: 0.3354 - val_accuracy: 0.8559\n",
            "Epoch 107/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3808 - accuracy: 0.8396 - val_loss: 0.3332 - val_accuracy: 0.8644\n",
            "Epoch 108/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8408 - val_loss: 0.3352 - val_accuracy: 0.8559\n",
            "Epoch 109/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8420 - val_loss: 0.3322 - val_accuracy: 0.8644\n",
            "Epoch 110/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8420 - val_loss: 0.3326 - val_accuracy: 0.8644\n",
            "Epoch 111/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.8408 - val_loss: 0.3342 - val_accuracy: 0.8644\n",
            "Epoch 112/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8408 - val_loss: 0.3330 - val_accuracy: 0.8644\n",
            "Epoch 113/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8396 - val_loss: 0.3321 - val_accuracy: 0.8475\n",
            "Epoch 114/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.8408 - val_loss: 0.3322 - val_accuracy: 0.8814\n",
            "Epoch 115/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8408 - val_loss: 0.3321 - val_accuracy: 0.8475\n",
            "Epoch 116/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.8408 - val_loss: 0.3334 - val_accuracy: 0.8814\n",
            "Epoch 117/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.8396 - val_loss: 0.3327 - val_accuracy: 0.8475\n",
            "Epoch 118/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8373 - val_loss: 0.3320 - val_accuracy: 0.8814\n",
            "Epoch 119/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.8408 - val_loss: 0.3318 - val_accuracy: 0.8559\n",
            "Epoch 120/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8396 - val_loss: 0.3339 - val_accuracy: 0.8814\n",
            "Epoch 121/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8384 - val_loss: 0.3315 - val_accuracy: 0.8729\n",
            "Epoch 122/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.8408 - val_loss: 0.3342 - val_accuracy: 0.8729\n",
            "Epoch 123/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8443 - val_loss: 0.3305 - val_accuracy: 0.8644\n",
            "Epoch 124/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8420 - val_loss: 0.3310 - val_accuracy: 0.8729\n",
            "Epoch 125/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8432 - val_loss: 0.3302 - val_accuracy: 0.8729\n",
            "Epoch 126/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8443 - val_loss: 0.3314 - val_accuracy: 0.8729\n",
            "Epoch 127/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3756 - accuracy: 0.8408 - val_loss: 0.3293 - val_accuracy: 0.8559\n",
            "Epoch 128/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8420 - val_loss: 0.3282 - val_accuracy: 0.8644\n",
            "Epoch 129/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8432 - val_loss: 0.3289 - val_accuracy: 0.8814\n",
            "Epoch 130/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8396 - val_loss: 0.3316 - val_accuracy: 0.8814\n",
            "Epoch 131/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8420 - val_loss: 0.3308 - val_accuracy: 0.8729\n",
            "Epoch 132/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8325 - val_loss: 0.3299 - val_accuracy: 0.8729\n",
            "Epoch 133/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8432 - val_loss: 0.3288 - val_accuracy: 0.8729\n",
            "Epoch 134/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8420 - val_loss: 0.3295 - val_accuracy: 0.8729\n",
            "Epoch 135/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.8443 - val_loss: 0.3298 - val_accuracy: 0.8814\n",
            "Epoch 136/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8420 - val_loss: 0.3294 - val_accuracy: 0.8814\n",
            "Epoch 137/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.8443 - val_loss: 0.3285 - val_accuracy: 0.8729\n",
            "Epoch 138/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.8420 - val_loss: 0.3298 - val_accuracy: 0.8729\n",
            "Epoch 139/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8408 - val_loss: 0.3300 - val_accuracy: 0.8814\n",
            "Epoch 140/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.8420 - val_loss: 0.3282 - val_accuracy: 0.8729\n",
            "Epoch 141/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8432 - val_loss: 0.3316 - val_accuracy: 0.8729\n",
            "Epoch 142/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.8396 - val_loss: 0.3294 - val_accuracy: 0.8898\n",
            "Epoch 143/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3717 - accuracy: 0.8408 - val_loss: 0.3286 - val_accuracy: 0.8814\n",
            "Epoch 144/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8420 - val_loss: 0.3297 - val_accuracy: 0.8729\n",
            "Epoch 145/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3710 - accuracy: 0.8408 - val_loss: 0.3319 - val_accuracy: 0.8814\n",
            "Epoch 146/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3709 - accuracy: 0.8432 - val_loss: 0.3285 - val_accuracy: 0.8729\n",
            "Epoch 147/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3708 - accuracy: 0.8432 - val_loss: 0.3286 - val_accuracy: 0.8729\n",
            "Epoch 148/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3709 - accuracy: 0.8384 - val_loss: 0.3297 - val_accuracy: 0.8814\n",
            "Epoch 149/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8420 - val_loss: 0.3302 - val_accuracy: 0.8729\n",
            "Epoch 150/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3704 - accuracy: 0.8408 - val_loss: 0.3302 - val_accuracy: 0.8644\n",
            "Epoch 151/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3704 - accuracy: 0.8420 - val_loss: 0.3302 - val_accuracy: 0.8729\n",
            "Epoch 152/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3704 - accuracy: 0.8420 - val_loss: 0.3300 - val_accuracy: 0.8814\n",
            "Epoch 153/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3702 - accuracy: 0.8396 - val_loss: 0.3270 - val_accuracy: 0.8644\n",
            "Epoch 154/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3705 - accuracy: 0.8443 - val_loss: 0.3298 - val_accuracy: 0.8729\n",
            "Epoch 155/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8432 - val_loss: 0.3288 - val_accuracy: 0.8559\n",
            "Epoch 156/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3695 - accuracy: 0.8373 - val_loss: 0.3301 - val_accuracy: 0.8729\n",
            "Epoch 157/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3686 - accuracy: 0.8408 - val_loss: 0.3286 - val_accuracy: 0.8814\n",
            "Epoch 158/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8384 - val_loss: 0.3279 - val_accuracy: 0.8729\n",
            "Epoch 159/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8384 - val_loss: 0.3298 - val_accuracy: 0.8814\n",
            "Epoch 160/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3686 - accuracy: 0.8420 - val_loss: 0.3280 - val_accuracy: 0.8898\n",
            "Epoch 161/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8384 - val_loss: 0.3303 - val_accuracy: 0.8729\n",
            "Epoch 162/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8384 - val_loss: 0.3289 - val_accuracy: 0.8814\n",
            "Epoch 163/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3685 - accuracy: 0.8420 - val_loss: 0.3296 - val_accuracy: 0.8814\n",
            "Epoch 164/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3675 - accuracy: 0.8420 - val_loss: 0.3306 - val_accuracy: 0.8814\n",
            "Epoch 165/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8420 - val_loss: 0.3326 - val_accuracy: 0.8729\n",
            "Epoch 166/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8455 - val_loss: 0.3303 - val_accuracy: 0.8814\n",
            "Epoch 167/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8455 - val_loss: 0.3316 - val_accuracy: 0.8729\n",
            "Epoch 168/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8443 - val_loss: 0.3309 - val_accuracy: 0.8898\n",
            "Epoch 169/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3672 - accuracy: 0.8420 - val_loss: 0.3308 - val_accuracy: 0.8814\n",
            "Epoch 170/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.8408 - val_loss: 0.3350 - val_accuracy: 0.8814\n",
            "Epoch 171/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3674 - accuracy: 0.8396 - val_loss: 0.3334 - val_accuracy: 0.8898\n",
            "Epoch 172/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3669 - accuracy: 0.8443 - val_loss: 0.3333 - val_accuracy: 0.8814\n",
            "Epoch 173/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3661 - accuracy: 0.8408 - val_loss: 0.3344 - val_accuracy: 0.8814\n",
            "Epoch 174/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8443 - val_loss: 0.3299 - val_accuracy: 0.8814\n",
            "Epoch 175/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8455 - val_loss: 0.3339 - val_accuracy: 0.8729\n",
            "Epoch 176/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8443 - val_loss: 0.3318 - val_accuracy: 0.8814\n",
            "Epoch 177/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3660 - accuracy: 0.8455 - val_loss: 0.3329 - val_accuracy: 0.8729\n",
            "Epoch 178/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.8443 - val_loss: 0.3326 - val_accuracy: 0.8898\n",
            "Epoch 179/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8443 - val_loss: 0.3314 - val_accuracy: 0.8814\n",
            "Epoch 180/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8455 - val_loss: 0.3327 - val_accuracy: 0.8898\n",
            "Epoch 181/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8420 - val_loss: 0.3325 - val_accuracy: 0.8814\n",
            "Epoch 182/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8455 - val_loss: 0.3317 - val_accuracy: 0.8814\n",
            "Epoch 183/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3653 - accuracy: 0.8420 - val_loss: 0.3348 - val_accuracy: 0.8814\n",
            "Epoch 184/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3646 - accuracy: 0.8479 - val_loss: 0.3336 - val_accuracy: 0.8814\n",
            "Epoch 185/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3643 - accuracy: 0.8432 - val_loss: 0.3349 - val_accuracy: 0.8814\n",
            "Epoch 186/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.8396 - val_loss: 0.3347 - val_accuracy: 0.8814\n",
            "Epoch 187/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3640 - accuracy: 0.8455 - val_loss: 0.3312 - val_accuracy: 0.8898\n",
            "Epoch 188/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3641 - accuracy: 0.8455 - val_loss: 0.3326 - val_accuracy: 0.8814\n",
            "Epoch 189/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3641 - accuracy: 0.8491 - val_loss: 0.3327 - val_accuracy: 0.8898\n",
            "Epoch 190/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3637 - accuracy: 0.8455 - val_loss: 0.3318 - val_accuracy: 0.8898\n",
            "Epoch 191/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3637 - accuracy: 0.8432 - val_loss: 0.3322 - val_accuracy: 0.8814\n",
            "Epoch 192/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3626 - accuracy: 0.8479 - val_loss: 0.3315 - val_accuracy: 0.8898\n",
            "Epoch 193/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3634 - accuracy: 0.8467 - val_loss: 0.3334 - val_accuracy: 0.8898\n",
            "Epoch 194/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3638 - accuracy: 0.8420 - val_loss: 0.3368 - val_accuracy: 0.8814\n",
            "Epoch 195/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3627 - accuracy: 0.8443 - val_loss: 0.3369 - val_accuracy: 0.8898\n",
            "Epoch 196/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3618 - accuracy: 0.8491 - val_loss: 0.3305 - val_accuracy: 0.8729\n",
            "Epoch 197/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3620 - accuracy: 0.8479 - val_loss: 0.3325 - val_accuracy: 0.8729\n",
            "Epoch 198/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3618 - accuracy: 0.8455 - val_loss: 0.3319 - val_accuracy: 0.8898\n",
            "Epoch 199/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3627 - accuracy: 0.8443 - val_loss: 0.3351 - val_accuracy: 0.8898\n",
            "Epoch 200/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.8443 - val_loss: 0.3356 - val_accuracy: 0.8814\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 1s 12ms/step - loss: 0.7306 - accuracy: 0.3833 - val_loss: 0.7077 - val_accuracy: 0.3898\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6953 - accuracy: 0.4057 - val_loss: 0.6761 - val_accuracy: 0.4576\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6673 - accuracy: 0.5967 - val_loss: 0.6497 - val_accuracy: 0.7373\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6432 - accuracy: 0.7441 - val_loss: 0.6262 - val_accuracy: 0.7966\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6226 - accuracy: 0.7818 - val_loss: 0.6052 - val_accuracy: 0.8390\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6035 - accuracy: 0.7866 - val_loss: 0.5858 - val_accuracy: 0.8220\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5859 - accuracy: 0.7948 - val_loss: 0.5664 - val_accuracy: 0.8305\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5691 - accuracy: 0.7948 - val_loss: 0.5482 - val_accuracy: 0.8390\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5535 - accuracy: 0.7960 - val_loss: 0.5308 - val_accuracy: 0.8305\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5384 - accuracy: 0.8078 - val_loss: 0.5124 - val_accuracy: 0.8305\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5235 - accuracy: 0.8101 - val_loss: 0.4956 - val_accuracy: 0.8305\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5101 - accuracy: 0.8090 - val_loss: 0.4803 - val_accuracy: 0.8305\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4985 - accuracy: 0.8101 - val_loss: 0.4669 - val_accuracy: 0.8390\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4887 - accuracy: 0.8125 - val_loss: 0.4566 - val_accuracy: 0.8475\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4810 - accuracy: 0.8137 - val_loss: 0.4470 - val_accuracy: 0.8475\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.8160 - val_loss: 0.4388 - val_accuracy: 0.8559\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.8172 - val_loss: 0.4317 - val_accuracy: 0.8559\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.8219 - val_loss: 0.4256 - val_accuracy: 0.8559\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.8208 - val_loss: 0.4208 - val_accuracy: 0.8559\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.8219 - val_loss: 0.4159 - val_accuracy: 0.8559\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.8196 - val_loss: 0.4119 - val_accuracy: 0.8475\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.8208 - val_loss: 0.4090 - val_accuracy: 0.8475\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.8219 - val_loss: 0.4049 - val_accuracy: 0.8475\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.8231 - val_loss: 0.4017 - val_accuracy: 0.8475\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.8196 - val_loss: 0.3989 - val_accuracy: 0.8475\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.8208 - val_loss: 0.3964 - val_accuracy: 0.8475\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.8219 - val_loss: 0.3945 - val_accuracy: 0.8475\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.8208 - val_loss: 0.3917 - val_accuracy: 0.8475\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4374 - accuracy: 0.8219 - val_loss: 0.3893 - val_accuracy: 0.8475\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4361 - accuracy: 0.8208 - val_loss: 0.3869 - val_accuracy: 0.8390\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.8231 - val_loss: 0.3851 - val_accuracy: 0.8390\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.8184 - val_loss: 0.3837 - val_accuracy: 0.8305\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.8184 - val_loss: 0.3825 - val_accuracy: 0.8390\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.8184 - val_loss: 0.3805 - val_accuracy: 0.8390\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.8208 - val_loss: 0.3791 - val_accuracy: 0.8305\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.8219 - val_loss: 0.3780 - val_accuracy: 0.8305\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.8231 - val_loss: 0.3767 - val_accuracy: 0.8305\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.8196 - val_loss: 0.3751 - val_accuracy: 0.8305\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.8196 - val_loss: 0.3740 - val_accuracy: 0.8305\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4260 - accuracy: 0.8208 - val_loss: 0.3738 - val_accuracy: 0.8305\n",
            "Epoch 41/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.8196 - val_loss: 0.3731 - val_accuracy: 0.8305\n",
            "Epoch 42/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.8208 - val_loss: 0.3711 - val_accuracy: 0.8305\n",
            "Epoch 43/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.8160 - val_loss: 0.3714 - val_accuracy: 0.8390\n",
            "Epoch 44/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8184 - val_loss: 0.3701 - val_accuracy: 0.8305\n",
            "Epoch 45/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8184 - val_loss: 0.3699 - val_accuracy: 0.8220\n",
            "Epoch 46/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8184 - val_loss: 0.3686 - val_accuracy: 0.8220\n",
            "Epoch 47/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.8219 - val_loss: 0.3681 - val_accuracy: 0.8305\n",
            "Epoch 48/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8231 - val_loss: 0.3669 - val_accuracy: 0.8220\n",
            "Epoch 49/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8231 - val_loss: 0.3681 - val_accuracy: 0.8220\n",
            "Epoch 50/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.8243 - val_loss: 0.3674 - val_accuracy: 0.8220\n",
            "Epoch 51/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8184 - val_loss: 0.3672 - val_accuracy: 0.8305\n",
            "Epoch 52/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8219 - val_loss: 0.3673 - val_accuracy: 0.8136\n",
            "Epoch 53/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8255 - val_loss: 0.3670 - val_accuracy: 0.8220\n",
            "Epoch 54/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8278 - val_loss: 0.3676 - val_accuracy: 0.8220\n",
            "Epoch 55/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8231 - val_loss: 0.3670 - val_accuracy: 0.8305\n",
            "Epoch 56/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8208 - val_loss: 0.3658 - val_accuracy: 0.8220\n",
            "Epoch 57/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8219 - val_loss: 0.3664 - val_accuracy: 0.8220\n",
            "Epoch 58/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8231 - val_loss: 0.3649 - val_accuracy: 0.8220\n",
            "Epoch 59/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8208 - val_loss: 0.3653 - val_accuracy: 0.8220\n",
            "Epoch 60/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8231 - val_loss: 0.3647 - val_accuracy: 0.8390\n",
            "Epoch 61/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8196 - val_loss: 0.3640 - val_accuracy: 0.8305\n",
            "Epoch 62/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8290 - val_loss: 0.3642 - val_accuracy: 0.8305\n",
            "Epoch 63/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8255 - val_loss: 0.3632 - val_accuracy: 0.8305\n",
            "Epoch 64/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8267 - val_loss: 0.3631 - val_accuracy: 0.8305\n",
            "Epoch 65/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8231 - val_loss: 0.3620 - val_accuracy: 0.8390\n",
            "Epoch 66/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8255 - val_loss: 0.3631 - val_accuracy: 0.8305\n",
            "Epoch 67/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8278 - val_loss: 0.3629 - val_accuracy: 0.8305\n",
            "Epoch 68/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.8278 - val_loss: 0.3611 - val_accuracy: 0.8305\n",
            "Epoch 69/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.8278 - val_loss: 0.3606 - val_accuracy: 0.8390\n",
            "Epoch 70/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8267 - val_loss: 0.3610 - val_accuracy: 0.8390\n",
            "Epoch 71/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8278 - val_loss: 0.3601 - val_accuracy: 0.8390\n",
            "Epoch 72/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8290 - val_loss: 0.3591 - val_accuracy: 0.8305\n",
            "Epoch 73/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8302 - val_loss: 0.3589 - val_accuracy: 0.8220\n",
            "Epoch 74/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8278 - val_loss: 0.3583 - val_accuracy: 0.8390\n",
            "Epoch 75/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8267 - val_loss: 0.3586 - val_accuracy: 0.8390\n",
            "Epoch 76/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4037 - accuracy: 0.8290 - val_loss: 0.3575 - val_accuracy: 0.8475\n",
            "Epoch 77/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8290 - val_loss: 0.3564 - val_accuracy: 0.8390\n",
            "Epoch 78/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8290 - val_loss: 0.3564 - val_accuracy: 0.8390\n",
            "Epoch 79/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8267 - val_loss: 0.3544 - val_accuracy: 0.8390\n",
            "Epoch 80/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8278 - val_loss: 0.3545 - val_accuracy: 0.8390\n",
            "Epoch 81/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8290 - val_loss: 0.3540 - val_accuracy: 0.8390\n",
            "Epoch 82/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8314 - val_loss: 0.3542 - val_accuracy: 0.8390\n",
            "Epoch 83/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8337 - val_loss: 0.3529 - val_accuracy: 0.8390\n",
            "Epoch 84/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8290 - val_loss: 0.3539 - val_accuracy: 0.8390\n",
            "Epoch 85/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8325 - val_loss: 0.3524 - val_accuracy: 0.8475\n",
            "Epoch 86/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8302 - val_loss: 0.3523 - val_accuracy: 0.8390\n",
            "Epoch 87/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8302 - val_loss: 0.3520 - val_accuracy: 0.8390\n",
            "Epoch 88/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8278 - val_loss: 0.3513 - val_accuracy: 0.8559\n",
            "Epoch 89/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8314 - val_loss: 0.3497 - val_accuracy: 0.8390\n",
            "Epoch 90/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8290 - val_loss: 0.3516 - val_accuracy: 0.8390\n",
            "Epoch 91/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8290 - val_loss: 0.3505 - val_accuracy: 0.8559\n",
            "Epoch 92/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8325 - val_loss: 0.3499 - val_accuracy: 0.8390\n",
            "Epoch 93/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8314 - val_loss: 0.3506 - val_accuracy: 0.8390\n",
            "Epoch 94/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8302 - val_loss: 0.3502 - val_accuracy: 0.8390\n",
            "Epoch 95/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8325 - val_loss: 0.3501 - val_accuracy: 0.8475\n",
            "Epoch 96/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8337 - val_loss: 0.3499 - val_accuracy: 0.8390\n",
            "Epoch 97/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8349 - val_loss: 0.3496 - val_accuracy: 0.8305\n",
            "Epoch 98/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8349 - val_loss: 0.3488 - val_accuracy: 0.8559\n",
            "Epoch 99/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8361 - val_loss: 0.3480 - val_accuracy: 0.8475\n",
            "Epoch 100/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8361 - val_loss: 0.3493 - val_accuracy: 0.8390\n",
            "Epoch 101/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8349 - val_loss: 0.3474 - val_accuracy: 0.8559\n",
            "Epoch 102/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8349 - val_loss: 0.3478 - val_accuracy: 0.8559\n",
            "Epoch 103/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8361 - val_loss: 0.3476 - val_accuracy: 0.8559\n",
            "Epoch 104/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8349 - val_loss: 0.3467 - val_accuracy: 0.8390\n",
            "Epoch 105/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8337 - val_loss: 0.3468 - val_accuracy: 0.8475\n",
            "Epoch 106/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8349 - val_loss: 0.3469 - val_accuracy: 0.8475\n",
            "Epoch 107/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8384 - val_loss: 0.3477 - val_accuracy: 0.8390\n",
            "Epoch 108/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8349 - val_loss: 0.3456 - val_accuracy: 0.8475\n",
            "Epoch 109/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8361 - val_loss: 0.3465 - val_accuracy: 0.8475\n",
            "Epoch 110/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8337 - val_loss: 0.3465 - val_accuracy: 0.8305\n",
            "Epoch 111/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8314 - val_loss: 0.3462 - val_accuracy: 0.8305\n",
            "Epoch 112/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8361 - val_loss: 0.3452 - val_accuracy: 0.8390\n",
            "Epoch 113/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3912 - accuracy: 0.8373 - val_loss: 0.3452 - val_accuracy: 0.8390\n",
            "Epoch 114/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8373 - val_loss: 0.3452 - val_accuracy: 0.8390\n",
            "Epoch 115/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8337 - val_loss: 0.3455 - val_accuracy: 0.8390\n",
            "Epoch 116/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8384 - val_loss: 0.3433 - val_accuracy: 0.8475\n",
            "Epoch 117/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8373 - val_loss: 0.3437 - val_accuracy: 0.8390\n",
            "Epoch 118/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8361 - val_loss: 0.3441 - val_accuracy: 0.8475\n",
            "Epoch 119/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8361 - val_loss: 0.3441 - val_accuracy: 0.8305\n",
            "Epoch 120/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8361 - val_loss: 0.3443 - val_accuracy: 0.8390\n",
            "Epoch 121/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8361 - val_loss: 0.3430 - val_accuracy: 0.8475\n",
            "Epoch 122/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8384 - val_loss: 0.3423 - val_accuracy: 0.8644\n",
            "Epoch 123/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8373 - val_loss: 0.3426 - val_accuracy: 0.8559\n",
            "Epoch 124/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.8396 - val_loss: 0.3437 - val_accuracy: 0.8305\n",
            "Epoch 125/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8373 - val_loss: 0.3440 - val_accuracy: 0.8390\n",
            "Epoch 126/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8373 - val_loss: 0.3438 - val_accuracy: 0.8305\n",
            "Epoch 127/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8373 - val_loss: 0.3429 - val_accuracy: 0.8475\n",
            "Epoch 128/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8384 - val_loss: 0.3431 - val_accuracy: 0.8305\n",
            "Epoch 129/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8396 - val_loss: 0.3430 - val_accuracy: 0.8305\n",
            "Epoch 130/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8396 - val_loss: 0.3433 - val_accuracy: 0.8390\n",
            "Epoch 131/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.8420 - val_loss: 0.3439 - val_accuracy: 0.8390\n",
            "Epoch 132/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3873 - accuracy: 0.8408 - val_loss: 0.3434 - val_accuracy: 0.8390\n",
            "Epoch 133/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8408 - val_loss: 0.3441 - val_accuracy: 0.8305\n",
            "Epoch 134/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8432 - val_loss: 0.3428 - val_accuracy: 0.8390\n",
            "Epoch 135/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.8455 - val_loss: 0.3434 - val_accuracy: 0.8390\n",
            "Epoch 136/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.8396 - val_loss: 0.3424 - val_accuracy: 0.8475\n",
            "Epoch 137/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.8443 - val_loss: 0.3424 - val_accuracy: 0.8475\n",
            "Epoch 138/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8420 - val_loss: 0.3427 - val_accuracy: 0.8390\n",
            "Epoch 139/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.8420 - val_loss: 0.3421 - val_accuracy: 0.8475\n",
            "Epoch 140/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8420 - val_loss: 0.3426 - val_accuracy: 0.8390\n",
            "Epoch 141/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8432 - val_loss: 0.3419 - val_accuracy: 0.8305\n",
            "Epoch 142/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.8396 - val_loss: 0.3414 - val_accuracy: 0.8305\n",
            "Epoch 143/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8455 - val_loss: 0.3424 - val_accuracy: 0.8475\n",
            "Epoch 144/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.8408 - val_loss: 0.3418 - val_accuracy: 0.8390\n",
            "Epoch 145/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.8443 - val_loss: 0.3419 - val_accuracy: 0.8475\n",
            "Epoch 146/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8408 - val_loss: 0.3428 - val_accuracy: 0.8390\n",
            "Epoch 147/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3832 - accuracy: 0.8467 - val_loss: 0.3422 - val_accuracy: 0.8559\n",
            "Epoch 148/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.8432 - val_loss: 0.3415 - val_accuracy: 0.8475\n",
            "Epoch 149/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3826 - accuracy: 0.8443 - val_loss: 0.3414 - val_accuracy: 0.8475\n",
            "Epoch 150/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8408 - val_loss: 0.3428 - val_accuracy: 0.8475\n",
            "Epoch 151/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.8432 - val_loss: 0.3421 - val_accuracy: 0.8390\n",
            "Epoch 152/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3819 - accuracy: 0.8420 - val_loss: 0.3432 - val_accuracy: 0.8390\n",
            "Epoch 153/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8443 - val_loss: 0.3429 - val_accuracy: 0.8475\n",
            "Epoch 154/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3817 - accuracy: 0.8408 - val_loss: 0.3428 - val_accuracy: 0.8475\n",
            "Epoch 155/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8432 - val_loss: 0.3428 - val_accuracy: 0.8475\n",
            "Epoch 156/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3816 - accuracy: 0.8384 - val_loss: 0.3428 - val_accuracy: 0.8475\n",
            "Epoch 157/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.8432 - val_loss: 0.3424 - val_accuracy: 0.8390\n",
            "Epoch 158/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8420 - val_loss: 0.3432 - val_accuracy: 0.8390\n",
            "Epoch 159/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8432 - val_loss: 0.3420 - val_accuracy: 0.8390\n",
            "Epoch 160/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8396 - val_loss: 0.3419 - val_accuracy: 0.8475\n",
            "Epoch 161/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8455 - val_loss: 0.3432 - val_accuracy: 0.8390\n",
            "Epoch 162/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3795 - accuracy: 0.8420 - val_loss: 0.3430 - val_accuracy: 0.8475\n",
            "Epoch 163/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8432 - val_loss: 0.3444 - val_accuracy: 0.8305\n",
            "Epoch 164/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8420 - val_loss: 0.3432 - val_accuracy: 0.8475\n",
            "Epoch 165/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3789 - accuracy: 0.8443 - val_loss: 0.3426 - val_accuracy: 0.8475\n",
            "Epoch 166/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.8432 - val_loss: 0.3436 - val_accuracy: 0.8475\n",
            "Epoch 167/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3782 - accuracy: 0.8420 - val_loss: 0.3426 - val_accuracy: 0.8390\n",
            "Epoch 168/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3791 - accuracy: 0.8420 - val_loss: 0.3433 - val_accuracy: 0.8390\n",
            "Epoch 169/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8420 - val_loss: 0.3432 - val_accuracy: 0.8390\n",
            "Epoch 170/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8432 - val_loss: 0.3438 - val_accuracy: 0.8390\n",
            "Epoch 171/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8443 - val_loss: 0.3433 - val_accuracy: 0.8475\n",
            "Epoch 172/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.8443 - val_loss: 0.3441 - val_accuracy: 0.8475\n",
            "Epoch 173/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.8443 - val_loss: 0.3426 - val_accuracy: 0.8475\n",
            "Epoch 174/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8443 - val_loss: 0.3433 - val_accuracy: 0.8305\n",
            "Epoch 175/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8420 - val_loss: 0.3435 - val_accuracy: 0.8390\n",
            "Epoch 176/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8455 - val_loss: 0.3426 - val_accuracy: 0.8475\n",
            "Epoch 177/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3763 - accuracy: 0.8420 - val_loss: 0.3435 - val_accuracy: 0.8475\n",
            "Epoch 178/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3762 - accuracy: 0.8396 - val_loss: 0.3440 - val_accuracy: 0.8475\n",
            "Epoch 179/200\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.3758 - accuracy: 0.8479 - val_loss: 0.3431 - val_accuracy: 0.8475\n",
            "Epoch 180/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8479 - val_loss: 0.3429 - val_accuracy: 0.8475\n",
            "Epoch 181/200\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3749 - accuracy: 0.8467 - val_loss: 0.3433 - val_accuracy: 0.8390\n",
            "Epoch 182/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8455 - val_loss: 0.3441 - val_accuracy: 0.8390\n",
            "Epoch 183/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8408 - val_loss: 0.3435 - val_accuracy: 0.8390\n",
            "Epoch 184/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8467 - val_loss: 0.3429 - val_accuracy: 0.8475\n",
            "Epoch 185/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.8479 - val_loss: 0.3444 - val_accuracy: 0.8390\n",
            "Epoch 186/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3742 - accuracy: 0.8479 - val_loss: 0.3449 - val_accuracy: 0.8305\n",
            "Epoch 187/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.8443 - val_loss: 0.3446 - val_accuracy: 0.8390\n",
            "Epoch 188/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8455 - val_loss: 0.3453 - val_accuracy: 0.8390\n",
            "Epoch 189/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8443 - val_loss: 0.3442 - val_accuracy: 0.8390\n",
            "Epoch 190/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.8455 - val_loss: 0.3457 - val_accuracy: 0.8390\n",
            "Epoch 191/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.8467 - val_loss: 0.3435 - val_accuracy: 0.8390\n",
            "Epoch 192/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8479 - val_loss: 0.3446 - val_accuracy: 0.8475\n",
            "Epoch 193/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8455 - val_loss: 0.3444 - val_accuracy: 0.8475\n",
            "Epoch 194/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3726 - accuracy: 0.8455 - val_loss: 0.3451 - val_accuracy: 0.8475\n",
            "Epoch 195/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8443 - val_loss: 0.3459 - val_accuracy: 0.8390\n",
            "Epoch 196/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8479 - val_loss: 0.3451 - val_accuracy: 0.8475\n",
            "Epoch 197/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.8432 - val_loss: 0.3458 - val_accuracy: 0.8390\n",
            "Epoch 198/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8455 - val_loss: 0.3464 - val_accuracy: 0.8390\n",
            "Epoch 199/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8432 - val_loss: 0.3456 - val_accuracy: 0.8475\n",
            "Epoch 200/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3716 - accuracy: 0.8443 - val_loss: 0.3461 - val_accuracy: 0.8305\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 1s 11ms/step - loss: 0.8146 - accuracy: 0.3833 - val_loss: 0.7804 - val_accuracy: 0.3898\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.7596 - accuracy: 0.3833 - val_loss: 0.7317 - val_accuracy: 0.3898\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.7178 - accuracy: 0.3892 - val_loss: 0.6940 - val_accuracy: 0.4153\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6844 - accuracy: 0.5472 - val_loss: 0.6649 - val_accuracy: 0.6864\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6575 - accuracy: 0.6993 - val_loss: 0.6393 - val_accuracy: 0.7881\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.6347 - accuracy: 0.7724 - val_loss: 0.6159 - val_accuracy: 0.8136\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.6135 - accuracy: 0.7866 - val_loss: 0.5922 - val_accuracy: 0.8051\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5925 - accuracy: 0.7913 - val_loss: 0.5684 - val_accuracy: 0.8136\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5724 - accuracy: 0.7983 - val_loss: 0.5449 - val_accuracy: 0.8220\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5539 - accuracy: 0.8090 - val_loss: 0.5247 - val_accuracy: 0.8390\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5383 - accuracy: 0.8066 - val_loss: 0.5074 - val_accuracy: 0.8305\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5249 - accuracy: 0.8078 - val_loss: 0.4911 - val_accuracy: 0.8475\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.5134 - accuracy: 0.8078 - val_loss: 0.4785 - val_accuracy: 0.8475\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5035 - accuracy: 0.8101 - val_loss: 0.4667 - val_accuracy: 0.8475\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4948 - accuracy: 0.8137 - val_loss: 0.4569 - val_accuracy: 0.8559\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4870 - accuracy: 0.8149 - val_loss: 0.4471 - val_accuracy: 0.8559\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.8160 - val_loss: 0.4390 - val_accuracy: 0.8644\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4736 - accuracy: 0.8149 - val_loss: 0.4321 - val_accuracy: 0.8644\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.8149 - val_loss: 0.4259 - val_accuracy: 0.8644\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.8149 - val_loss: 0.4208 - val_accuracy: 0.8559\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.8184 - val_loss: 0.4155 - val_accuracy: 0.8644\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4559 - accuracy: 0.8208 - val_loss: 0.4118 - val_accuracy: 0.8559\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.8196 - val_loss: 0.4078 - val_accuracy: 0.8559\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.8208 - val_loss: 0.4037 - val_accuracy: 0.8559\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.8231 - val_loss: 0.4015 - val_accuracy: 0.8559\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.8219 - val_loss: 0.3979 - val_accuracy: 0.8559\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.8219 - val_loss: 0.3949 - val_accuracy: 0.8559\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.8255 - val_loss: 0.3937 - val_accuracy: 0.8475\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.8196 - val_loss: 0.3914 - val_accuracy: 0.8559\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.8196 - val_loss: 0.3882 - val_accuracy: 0.8475\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4370 - accuracy: 0.8196 - val_loss: 0.3871 - val_accuracy: 0.8475\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.8208 - val_loss: 0.3846 - val_accuracy: 0.8475\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.8172 - val_loss: 0.3819 - val_accuracy: 0.8305\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.8184 - val_loss: 0.3817 - val_accuracy: 0.8390\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.8231 - val_loss: 0.3805 - val_accuracy: 0.8390\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.8172 - val_loss: 0.3781 - val_accuracy: 0.8305\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.8219 - val_loss: 0.3769 - val_accuracy: 0.8305\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.8243 - val_loss: 0.3764 - val_accuracy: 0.8305\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.8243 - val_loss: 0.3742 - val_accuracy: 0.8305\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.8231 - val_loss: 0.3727 - val_accuracy: 0.8305\n",
            "Epoch 41/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.8255 - val_loss: 0.3707 - val_accuracy: 0.8305\n",
            "Epoch 42/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.8278 - val_loss: 0.3712 - val_accuracy: 0.8305\n",
            "Epoch 43/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8243 - val_loss: 0.3704 - val_accuracy: 0.8390\n",
            "Epoch 44/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8231 - val_loss: 0.3692 - val_accuracy: 0.8390\n",
            "Epoch 45/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.8278 - val_loss: 0.3669 - val_accuracy: 0.8390\n",
            "Epoch 46/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8267 - val_loss: 0.3662 - val_accuracy: 0.8390\n",
            "Epoch 47/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.8267 - val_loss: 0.3667 - val_accuracy: 0.8390\n",
            "Epoch 48/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8255 - val_loss: 0.3650 - val_accuracy: 0.8390\n",
            "Epoch 49/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.8243 - val_loss: 0.3654 - val_accuracy: 0.8390\n",
            "Epoch 50/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8290 - val_loss: 0.3641 - val_accuracy: 0.8390\n",
            "Epoch 51/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8278 - val_loss: 0.3635 - val_accuracy: 0.8390\n",
            "Epoch 52/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.8278 - val_loss: 0.3627 - val_accuracy: 0.8390\n",
            "Epoch 53/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8267 - val_loss: 0.3620 - val_accuracy: 0.8390\n",
            "Epoch 54/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8267 - val_loss: 0.3603 - val_accuracy: 0.8559\n",
            "Epoch 55/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8278 - val_loss: 0.3608 - val_accuracy: 0.8390\n",
            "Epoch 56/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8302 - val_loss: 0.3601 - val_accuracy: 0.8559\n",
            "Epoch 57/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8290 - val_loss: 0.3598 - val_accuracy: 0.8559\n",
            "Epoch 58/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8278 - val_loss: 0.3591 - val_accuracy: 0.8559\n",
            "Epoch 59/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8290 - val_loss: 0.3586 - val_accuracy: 0.8559\n",
            "Epoch 60/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8267 - val_loss: 0.3579 - val_accuracy: 0.8559\n",
            "Epoch 61/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8267 - val_loss: 0.3579 - val_accuracy: 0.8559\n",
            "Epoch 62/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8278 - val_loss: 0.3565 - val_accuracy: 0.8559\n",
            "Epoch 63/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8243 - val_loss: 0.3562 - val_accuracy: 0.8559\n",
            "Epoch 64/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8290 - val_loss: 0.3554 - val_accuracy: 0.8559\n",
            "Epoch 65/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.8314 - val_loss: 0.3548 - val_accuracy: 0.8559\n",
            "Epoch 66/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8290 - val_loss: 0.3546 - val_accuracy: 0.8559\n",
            "Epoch 67/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8290 - val_loss: 0.3543 - val_accuracy: 0.8559\n",
            "Epoch 68/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8267 - val_loss: 0.3551 - val_accuracy: 0.8644\n",
            "Epoch 69/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8267 - val_loss: 0.3535 - val_accuracy: 0.8559\n",
            "Epoch 70/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8302 - val_loss: 0.3532 - val_accuracy: 0.8475\n",
            "Epoch 71/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8267 - val_loss: 0.3536 - val_accuracy: 0.8475\n",
            "Epoch 72/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8278 - val_loss: 0.3526 - val_accuracy: 0.8475\n",
            "Epoch 73/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8278 - val_loss: 0.3521 - val_accuracy: 0.8475\n",
            "Epoch 74/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8278 - val_loss: 0.3528 - val_accuracy: 0.8475\n",
            "Epoch 75/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8290 - val_loss: 0.3522 - val_accuracy: 0.8475\n",
            "Epoch 76/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8314 - val_loss: 0.3510 - val_accuracy: 0.8475\n",
            "Epoch 77/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8255 - val_loss: 0.3511 - val_accuracy: 0.8390\n",
            "Epoch 78/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8278 - val_loss: 0.3528 - val_accuracy: 0.8390\n",
            "Epoch 79/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8314 - val_loss: 0.3511 - val_accuracy: 0.8390\n",
            "Epoch 80/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8278 - val_loss: 0.3511 - val_accuracy: 0.8390\n",
            "Epoch 81/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8302 - val_loss: 0.3508 - val_accuracy: 0.8390\n",
            "Epoch 82/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8325 - val_loss: 0.3508 - val_accuracy: 0.8390\n",
            "Epoch 83/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8278 - val_loss: 0.3505 - val_accuracy: 0.8390\n",
            "Epoch 84/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8325 - val_loss: 0.3503 - val_accuracy: 0.8390\n",
            "Epoch 85/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8325 - val_loss: 0.3502 - val_accuracy: 0.8390\n",
            "Epoch 86/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8325 - val_loss: 0.3506 - val_accuracy: 0.8390\n",
            "Epoch 87/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8278 - val_loss: 0.3493 - val_accuracy: 0.8305\n",
            "Epoch 88/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8349 - val_loss: 0.3494 - val_accuracy: 0.8390\n",
            "Epoch 89/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8337 - val_loss: 0.3495 - val_accuracy: 0.8390\n",
            "Epoch 90/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8302 - val_loss: 0.3492 - val_accuracy: 0.8305\n",
            "Epoch 91/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8325 - val_loss: 0.3492 - val_accuracy: 0.8390\n",
            "Epoch 92/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8337 - val_loss: 0.3489 - val_accuracy: 0.8475\n",
            "Epoch 93/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8325 - val_loss: 0.3480 - val_accuracy: 0.8305\n",
            "Epoch 94/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8302 - val_loss: 0.3485 - val_accuracy: 0.8305\n",
            "Epoch 95/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8361 - val_loss: 0.3484 - val_accuracy: 0.8390\n",
            "Epoch 96/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8325 - val_loss: 0.3478 - val_accuracy: 0.8305\n",
            "Epoch 97/200\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.3980 - accuracy: 0.8349 - val_loss: 0.3481 - val_accuracy: 0.8305\n",
            "Epoch 98/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8349 - val_loss: 0.3475 - val_accuracy: 0.8305\n",
            "Epoch 99/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8373 - val_loss: 0.3476 - val_accuracy: 0.8390\n",
            "Epoch 100/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8361 - val_loss: 0.3483 - val_accuracy: 0.8390\n",
            "Epoch 101/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8349 - val_loss: 0.3482 - val_accuracy: 0.8390\n",
            "Epoch 102/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8361 - val_loss: 0.3469 - val_accuracy: 0.8305\n",
            "Epoch 103/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8384 - val_loss: 0.3469 - val_accuracy: 0.8390\n",
            "Epoch 104/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8349 - val_loss: 0.3471 - val_accuracy: 0.8305\n",
            "Epoch 105/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8384 - val_loss: 0.3476 - val_accuracy: 0.8305\n",
            "Epoch 106/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8349 - val_loss: 0.3468 - val_accuracy: 0.8390\n",
            "Epoch 107/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8384 - val_loss: 0.3476 - val_accuracy: 0.8305\n",
            "Epoch 108/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8408 - val_loss: 0.3482 - val_accuracy: 0.8305\n",
            "Epoch 109/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8361 - val_loss: 0.3477 - val_accuracy: 0.8305\n",
            "Epoch 110/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8373 - val_loss: 0.3479 - val_accuracy: 0.8305\n",
            "Epoch 111/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8373 - val_loss: 0.3474 - val_accuracy: 0.8305\n",
            "Epoch 112/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8384 - val_loss: 0.3468 - val_accuracy: 0.8305\n",
            "Epoch 113/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8384 - val_loss: 0.3474 - val_accuracy: 0.8305\n",
            "Epoch 114/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8373 - val_loss: 0.3483 - val_accuracy: 0.8305\n",
            "Epoch 115/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8373 - val_loss: 0.3491 - val_accuracy: 0.8390\n",
            "Epoch 116/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8384 - val_loss: 0.3483 - val_accuracy: 0.8305\n",
            "Epoch 117/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8361 - val_loss: 0.3498 - val_accuracy: 0.8305\n",
            "Epoch 118/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8384 - val_loss: 0.3491 - val_accuracy: 0.8305\n",
            "Epoch 119/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8384 - val_loss: 0.3496 - val_accuracy: 0.8305\n",
            "Epoch 120/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8408 - val_loss: 0.3486 - val_accuracy: 0.8305\n",
            "Epoch 121/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8384 - val_loss: 0.3497 - val_accuracy: 0.8390\n",
            "Epoch 122/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8396 - val_loss: 0.3496 - val_accuracy: 0.8305\n",
            "Epoch 123/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8396 - val_loss: 0.3495 - val_accuracy: 0.8390\n",
            "Epoch 124/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8373 - val_loss: 0.3490 - val_accuracy: 0.8305\n",
            "Epoch 125/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8349 - val_loss: 0.3494 - val_accuracy: 0.8390\n",
            "Epoch 126/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8396 - val_loss: 0.3503 - val_accuracy: 0.8390\n",
            "Epoch 127/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8349 - val_loss: 0.3503 - val_accuracy: 0.8305\n",
            "Epoch 128/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8384 - val_loss: 0.3504 - val_accuracy: 0.8390\n",
            "Epoch 129/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.8384 - val_loss: 0.3510 - val_accuracy: 0.8305\n",
            "Epoch 130/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8408 - val_loss: 0.3499 - val_accuracy: 0.8390\n",
            "Epoch 131/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8384 - val_loss: 0.3511 - val_accuracy: 0.8305\n",
            "Epoch 132/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8384 - val_loss: 0.3501 - val_accuracy: 0.8390\n",
            "Epoch 133/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8408 - val_loss: 0.3506 - val_accuracy: 0.8390\n",
            "Epoch 134/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8408 - val_loss: 0.3506 - val_accuracy: 0.8305\n",
            "Epoch 135/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8373 - val_loss: 0.3507 - val_accuracy: 0.8305\n",
            "Epoch 136/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8396 - val_loss: 0.3501 - val_accuracy: 0.8390\n",
            "Epoch 137/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.8384 - val_loss: 0.3501 - val_accuracy: 0.8390\n",
            "Epoch 138/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8373 - val_loss: 0.3504 - val_accuracy: 0.8305\n",
            "Epoch 139/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.8373 - val_loss: 0.3508 - val_accuracy: 0.8390\n",
            "Epoch 140/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8396 - val_loss: 0.3502 - val_accuracy: 0.8305\n",
            "Epoch 141/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8384 - val_loss: 0.3500 - val_accuracy: 0.8390\n",
            "Epoch 142/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8396 - val_loss: 0.3493 - val_accuracy: 0.8305\n",
            "Epoch 143/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8396 - val_loss: 0.3511 - val_accuracy: 0.8390\n",
            "Epoch 144/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8361 - val_loss: 0.3504 - val_accuracy: 0.8390\n",
            "Epoch 145/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8384 - val_loss: 0.3513 - val_accuracy: 0.8390\n",
            "Epoch 146/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8384 - val_loss: 0.3516 - val_accuracy: 0.8390\n",
            "Epoch 147/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8396 - val_loss: 0.3512 - val_accuracy: 0.8390\n",
            "Epoch 148/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8384 - val_loss: 0.3511 - val_accuracy: 0.8390\n",
            "Epoch 149/200\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8373 - val_loss: 0.3515 - val_accuracy: 0.8390\n",
            "Epoch 150/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8373 - val_loss: 0.3511 - val_accuracy: 0.8390\n",
            "Epoch 151/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8361 - val_loss: 0.3494 - val_accuracy: 0.8305\n",
            "Epoch 152/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.8373 - val_loss: 0.3496 - val_accuracy: 0.8390\n",
            "Epoch 153/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8396 - val_loss: 0.3494 - val_accuracy: 0.8305\n",
            "Epoch 154/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3851 - accuracy: 0.8373 - val_loss: 0.3505 - val_accuracy: 0.8390\n",
            "Epoch 155/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8373 - val_loss: 0.3512 - val_accuracy: 0.8305\n",
            "Epoch 156/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3849 - accuracy: 0.8396 - val_loss: 0.3512 - val_accuracy: 0.8390\n",
            "Epoch 157/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8396 - val_loss: 0.3511 - val_accuracy: 0.8390\n",
            "Epoch 158/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3849 - accuracy: 0.8396 - val_loss: 0.3514 - val_accuracy: 0.8305\n",
            "Epoch 159/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8396 - val_loss: 0.3505 - val_accuracy: 0.8390\n",
            "Epoch 160/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.8396 - val_loss: 0.3517 - val_accuracy: 0.8390\n",
            "Epoch 161/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.8373 - val_loss: 0.3509 - val_accuracy: 0.8390\n",
            "Epoch 162/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8373 - val_loss: 0.3514 - val_accuracy: 0.8390\n",
            "Epoch 163/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8384 - val_loss: 0.3515 - val_accuracy: 0.8390\n",
            "Epoch 164/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3834 - accuracy: 0.8396 - val_loss: 0.3515 - val_accuracy: 0.8390\n",
            "Epoch 165/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8384 - val_loss: 0.3515 - val_accuracy: 0.8390\n",
            "Epoch 166/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.8373 - val_loss: 0.3514 - val_accuracy: 0.8390\n",
            "Epoch 167/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8408 - val_loss: 0.3519 - val_accuracy: 0.8390\n",
            "Epoch 168/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.8384 - val_loss: 0.3521 - val_accuracy: 0.8390\n",
            "Epoch 169/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3826 - accuracy: 0.8373 - val_loss: 0.3522 - val_accuracy: 0.8390\n",
            "Epoch 170/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.8396 - val_loss: 0.3534 - val_accuracy: 0.8390\n",
            "Epoch 171/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3824 - accuracy: 0.8396 - val_loss: 0.3522 - val_accuracy: 0.8390\n",
            "Epoch 172/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.8384 - val_loss: 0.3526 - val_accuracy: 0.8390\n",
            "Epoch 173/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8373 - val_loss: 0.3532 - val_accuracy: 0.8390\n",
            "Epoch 174/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.8373 - val_loss: 0.3537 - val_accuracy: 0.8390\n",
            "Epoch 175/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3816 - accuracy: 0.8384 - val_loss: 0.3523 - val_accuracy: 0.8390\n",
            "Epoch 176/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3815 - accuracy: 0.8396 - val_loss: 0.3531 - val_accuracy: 0.8390\n",
            "Epoch 177/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8396 - val_loss: 0.3525 - val_accuracy: 0.8390\n",
            "Epoch 178/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.8384 - val_loss: 0.3522 - val_accuracy: 0.8390\n",
            "Epoch 179/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8396 - val_loss: 0.3524 - val_accuracy: 0.8390\n",
            "Epoch 180/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8384 - val_loss: 0.3529 - val_accuracy: 0.8390\n",
            "Epoch 181/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8396 - val_loss: 0.3523 - val_accuracy: 0.8390\n",
            "Epoch 182/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3803 - accuracy: 0.8408 - val_loss: 0.3525 - val_accuracy: 0.8390\n",
            "Epoch 183/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8396 - val_loss: 0.3529 - val_accuracy: 0.8390\n",
            "Epoch 184/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8408 - val_loss: 0.3530 - val_accuracy: 0.8390\n",
            "Epoch 185/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.8420 - val_loss: 0.3532 - val_accuracy: 0.8390\n",
            "Epoch 186/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8396 - val_loss: 0.3516 - val_accuracy: 0.8390\n",
            "Epoch 187/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8384 - val_loss: 0.3531 - val_accuracy: 0.8390\n",
            "Epoch 188/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8396 - val_loss: 0.3514 - val_accuracy: 0.8390\n",
            "Epoch 189/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8373 - val_loss: 0.3536 - val_accuracy: 0.8390\n",
            "Epoch 190/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.8384 - val_loss: 0.3526 - val_accuracy: 0.8390\n",
            "Epoch 191/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8432 - val_loss: 0.3520 - val_accuracy: 0.8390\n",
            "Epoch 192/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8396 - val_loss: 0.3527 - val_accuracy: 0.8390\n",
            "Epoch 193/200\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8384 - val_loss: 0.3520 - val_accuracy: 0.8390\n",
            "Epoch 194/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3789 - accuracy: 0.8396 - val_loss: 0.3529 - val_accuracy: 0.8390\n",
            "Epoch 195/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.8408 - val_loss: 0.3523 - val_accuracy: 0.8390\n",
            "Epoch 196/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8420 - val_loss: 0.3531 - val_accuracy: 0.8390\n",
            "Epoch 197/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3782 - accuracy: 0.8408 - val_loss: 0.3524 - val_accuracy: 0.8390\n",
            "Epoch 198/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3782 - accuracy: 0.8420 - val_loss: 0.3519 - val_accuracy: 0.8390\n",
            "Epoch 199/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8420 - val_loss: 0.3516 - val_accuracy: 0.8390\n",
            "Epoch 200/200\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8408 - val_loss: 0.3511 - val_accuracy: 0.8390\n",
            "7/7 [==============================] - 0s 6ms/step\n",
            "Epoch 1/100\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.7043 - accuracy: 0.4236 - val_loss: 0.6850 - val_accuracy: 0.5763\n",
            "Epoch 2/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.6739 - accuracy: 0.6274 - val_loss: 0.6597 - val_accuracy: 0.7458\n",
            "Epoch 3/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.6504 - accuracy: 0.7123 - val_loss: 0.6372 - val_accuracy: 0.7373\n",
            "Epoch 4/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.6290 - accuracy: 0.7255 - val_loss: 0.6147 - val_accuracy: 0.7458\n",
            "Epoch 5/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.6082 - accuracy: 0.7462 - val_loss: 0.5898 - val_accuracy: 0.7797\n",
            "Epoch 6/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.5868 - accuracy: 0.7670 - val_loss: 0.5643 - val_accuracy: 0.7966\n",
            "Epoch 7/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.5654 - accuracy: 0.7774 - val_loss: 0.5371 - val_accuracy: 0.8305\n",
            "Epoch 8/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.5448 - accuracy: 0.7877 - val_loss: 0.5117 - val_accuracy: 0.8305\n",
            "Epoch 9/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.5260 - accuracy: 0.8028 - val_loss: 0.4889 - val_accuracy: 0.8390\n",
            "Epoch 10/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.5100 - accuracy: 0.8113 - val_loss: 0.4700 - val_accuracy: 0.8390\n",
            "Epoch 11/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.8094 - val_loss: 0.4534 - val_accuracy: 0.8390\n",
            "Epoch 12/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4865 - accuracy: 0.8104 - val_loss: 0.4401 - val_accuracy: 0.8475\n",
            "Epoch 13/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.8132 - val_loss: 0.4297 - val_accuracy: 0.8559\n",
            "Epoch 14/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.8160 - val_loss: 0.4212 - val_accuracy: 0.8644\n",
            "Epoch 15/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.8160 - val_loss: 0.4132 - val_accuracy: 0.8644\n",
            "Epoch 16/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.8189 - val_loss: 0.4070 - val_accuracy: 0.8644\n",
            "Epoch 17/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.8179 - val_loss: 0.4015 - val_accuracy: 0.8644\n",
            "Epoch 18/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.4542 - accuracy: 0.8179 - val_loss: 0.3967 - val_accuracy: 0.8644\n",
            "Epoch 19/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.8208 - val_loss: 0.3919 - val_accuracy: 0.8644\n",
            "Epoch 20/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.8208 - val_loss: 0.3890 - val_accuracy: 0.8729\n",
            "Epoch 21/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.8217 - val_loss: 0.3854 - val_accuracy: 0.8729\n",
            "Epoch 22/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.8208 - val_loss: 0.3814 - val_accuracy: 0.8729\n",
            "Epoch 23/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.8217 - val_loss: 0.3791 - val_accuracy: 0.8729\n",
            "Epoch 24/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.8208 - val_loss: 0.3773 - val_accuracy: 0.8729\n",
            "Epoch 25/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.8198 - val_loss: 0.3760 - val_accuracy: 0.8729\n",
            "Epoch 26/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.8170 - val_loss: 0.3735 - val_accuracy: 0.8729\n",
            "Epoch 27/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.8226 - val_loss: 0.3716 - val_accuracy: 0.8729\n",
            "Epoch 28/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.8208 - val_loss: 0.3702 - val_accuracy: 0.8729\n",
            "Epoch 29/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.8226 - val_loss: 0.3692 - val_accuracy: 0.8729\n",
            "Epoch 30/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.8217 - val_loss: 0.3673 - val_accuracy: 0.8729\n",
            "Epoch 31/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.8217 - val_loss: 0.3668 - val_accuracy: 0.8729\n",
            "Epoch 32/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.8245 - val_loss: 0.3657 - val_accuracy: 0.8814\n",
            "Epoch 33/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.8226 - val_loss: 0.3631 - val_accuracy: 0.8559\n",
            "Epoch 34/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8236 - val_loss: 0.3630 - val_accuracy: 0.8559\n",
            "Epoch 35/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.8255 - val_loss: 0.3628 - val_accuracy: 0.8559\n",
            "Epoch 36/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8226 - val_loss: 0.3601 - val_accuracy: 0.8644\n",
            "Epoch 37/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.8245 - val_loss: 0.3603 - val_accuracy: 0.8475\n",
            "Epoch 38/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.8255 - val_loss: 0.3606 - val_accuracy: 0.8644\n",
            "Epoch 39/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.4187 - accuracy: 0.8255 - val_loss: 0.3590 - val_accuracy: 0.8644\n",
            "Epoch 40/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8264 - val_loss: 0.3571 - val_accuracy: 0.8644\n",
            "Epoch 41/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8226 - val_loss: 0.3573 - val_accuracy: 0.8644\n",
            "Epoch 42/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8264 - val_loss: 0.3559 - val_accuracy: 0.8644\n",
            "Epoch 43/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8283 - val_loss: 0.3571 - val_accuracy: 0.8729\n",
            "Epoch 44/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8292 - val_loss: 0.3566 - val_accuracy: 0.8644\n",
            "Epoch 45/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8274 - val_loss: 0.3554 - val_accuracy: 0.8644\n",
            "Epoch 46/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8292 - val_loss: 0.3548 - val_accuracy: 0.8644\n",
            "Epoch 47/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8292 - val_loss: 0.3546 - val_accuracy: 0.8559\n",
            "Epoch 48/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8292 - val_loss: 0.3541 - val_accuracy: 0.8559\n",
            "Epoch 49/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8292 - val_loss: 0.3541 - val_accuracy: 0.8644\n",
            "Epoch 50/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8311 - val_loss: 0.3535 - val_accuracy: 0.8559\n",
            "Epoch 51/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8311 - val_loss: 0.3534 - val_accuracy: 0.8390\n",
            "Epoch 52/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8302 - val_loss: 0.3538 - val_accuracy: 0.8305\n",
            "Epoch 53/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8321 - val_loss: 0.3526 - val_accuracy: 0.8559\n",
            "Epoch 54/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8340 - val_loss: 0.3521 - val_accuracy: 0.8305\n",
            "Epoch 55/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8358 - val_loss: 0.3513 - val_accuracy: 0.8390\n",
            "Epoch 56/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8358 - val_loss: 0.3523 - val_accuracy: 0.8390\n",
            "Epoch 57/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8340 - val_loss: 0.3508 - val_accuracy: 0.8475\n",
            "Epoch 58/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8340 - val_loss: 0.3515 - val_accuracy: 0.8390\n",
            "Epoch 59/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8321 - val_loss: 0.3506 - val_accuracy: 0.8390\n",
            "Epoch 60/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8321 - val_loss: 0.3508 - val_accuracy: 0.8390\n",
            "Epoch 61/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8340 - val_loss: 0.3519 - val_accuracy: 0.8475\n",
            "Epoch 62/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.8349 - val_loss: 0.3513 - val_accuracy: 0.8390\n",
            "Epoch 63/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8330 - val_loss: 0.3517 - val_accuracy: 0.8390\n",
            "Epoch 64/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8330 - val_loss: 0.3501 - val_accuracy: 0.8475\n",
            "Epoch 65/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8330 - val_loss: 0.3500 - val_accuracy: 0.8390\n",
            "Epoch 66/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8349 - val_loss: 0.3498 - val_accuracy: 0.8390\n",
            "Epoch 67/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8368 - val_loss: 0.3505 - val_accuracy: 0.8390\n",
            "Epoch 68/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8368 - val_loss: 0.3501 - val_accuracy: 0.8390\n",
            "Epoch 69/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8368 - val_loss: 0.3498 - val_accuracy: 0.8390\n",
            "Epoch 70/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8340 - val_loss: 0.3502 - val_accuracy: 0.8305\n",
            "Epoch 71/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8358 - val_loss: 0.3515 - val_accuracy: 0.8305\n",
            "Epoch 72/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8330 - val_loss: 0.3497 - val_accuracy: 0.8390\n",
            "Epoch 73/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8377 - val_loss: 0.3507 - val_accuracy: 0.8305\n",
            "Epoch 74/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8396 - val_loss: 0.3510 - val_accuracy: 0.8220\n",
            "Epoch 75/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8349 - val_loss: 0.3500 - val_accuracy: 0.8305\n",
            "Epoch 76/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8358 - val_loss: 0.3503 - val_accuracy: 0.8220\n",
            "Epoch 77/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8321 - val_loss: 0.3483 - val_accuracy: 0.8475\n",
            "Epoch 78/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8415 - val_loss: 0.3504 - val_accuracy: 0.8305\n",
            "Epoch 79/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8368 - val_loss: 0.3499 - val_accuracy: 0.8305\n",
            "Epoch 80/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8358 - val_loss: 0.3500 - val_accuracy: 0.8220\n",
            "Epoch 81/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8358 - val_loss: 0.3498 - val_accuracy: 0.8305\n",
            "Epoch 82/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8368 - val_loss: 0.3484 - val_accuracy: 0.8390\n",
            "Epoch 83/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8377 - val_loss: 0.3484 - val_accuracy: 0.8220\n",
            "Epoch 84/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8330 - val_loss: 0.3484 - val_accuracy: 0.8390\n",
            "Epoch 85/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8358 - val_loss: 0.3499 - val_accuracy: 0.8305\n",
            "Epoch 86/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8358 - val_loss: 0.3494 - val_accuracy: 0.8390\n",
            "Epoch 87/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8349 - val_loss: 0.3490 - val_accuracy: 0.8390\n",
            "Epoch 88/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8321 - val_loss: 0.3504 - val_accuracy: 0.8390\n",
            "Epoch 89/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8302 - val_loss: 0.3489 - val_accuracy: 0.8390\n",
            "Epoch 90/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8349 - val_loss: 0.3481 - val_accuracy: 0.8220\n",
            "Epoch 91/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8349 - val_loss: 0.3479 - val_accuracy: 0.8390\n",
            "Epoch 92/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8340 - val_loss: 0.3495 - val_accuracy: 0.8390\n",
            "Epoch 93/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8330 - val_loss: 0.3481 - val_accuracy: 0.8390\n",
            "Epoch 94/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8340 - val_loss: 0.3487 - val_accuracy: 0.8390\n",
            "Epoch 95/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8311 - val_loss: 0.3474 - val_accuracy: 0.8305\n",
            "Epoch 96/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8349 - val_loss: 0.3467 - val_accuracy: 0.8305\n",
            "Epoch 97/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8358 - val_loss: 0.3478 - val_accuracy: 0.8390\n",
            "Epoch 98/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8349 - val_loss: 0.3481 - val_accuracy: 0.8390\n",
            "Epoch 99/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8340 - val_loss: 0.3463 - val_accuracy: 0.8305\n",
            "Epoch 100/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8368 - val_loss: 0.3474 - val_accuracy: 0.8390\n"
          ]
        }
      ],
      "source": [
        "param_grid = dict(optimizer = ['adam', 'rmsprop'],\n",
        "                  epochs=[50, 100, 200],\n",
        "                  batch_size=[5, 10, 20])\n",
        "grid = GridSearchCV(estimator=classifier, param_grid=param_grid, scoring='accuracy')\n",
        "grid_result = grid.fit(X_train, y_train, validation_data = (X_valid, y_valid), shuffle=True)\n",
        "best_parameters = grid.best_params_\n",
        "best_accuracy = grid.best_score_"
      ],
      "id": "7GLU15LyES43"
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "id": "7rJpLP249lb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a26ec0-f492-4e94-8d00-b2d7f45731ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 1s 4ms/step - loss: 0.6693 - accuracy: 0.6160\n",
            "Epoch 2/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.6509 - accuracy: 0.6160\n",
            "Epoch 3/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.6328 - accuracy: 0.6160\n",
            "Epoch 4/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.6130 - accuracy: 0.6170\n",
            "Epoch 5/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.5912 - accuracy: 0.6585\n",
            "Epoch 6/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.7292\n",
            "Epoch 7/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7642\n",
            "Epoch 8/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7925\n",
            "Epoch 9/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7981\n",
            "Epoch 10/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.8028\n",
            "Epoch 11/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.8028\n",
            "Epoch 12/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.8057\n",
            "Epoch 13/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.8028\n",
            "Epoch 14/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.8066\n",
            "Epoch 15/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.8104\n",
            "Epoch 16/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.8113\n",
            "Epoch 17/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.8123\n",
            "Epoch 18/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.8104\n",
            "Epoch 19/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.8132\n",
            "Epoch 20/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.8123\n",
            "Epoch 21/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.8123\n",
            "Epoch 22/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.8142\n",
            "Epoch 23/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.8151\n",
            "Epoch 24/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.8160\n",
            "Epoch 25/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.8151\n",
            "Epoch 26/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.8179\n",
            "Epoch 27/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.8179\n",
            "Epoch 28/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.8189\n",
            "Epoch 29/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.8189\n",
            "Epoch 30/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8217\n",
            "Epoch 31/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8217\n",
            "Epoch 32/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8217\n",
            "Epoch 33/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.8236\n",
            "Epoch 34/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8208\n",
            "Epoch 35/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8226\n",
            "Epoch 36/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8226\n",
            "Epoch 37/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8245\n",
            "Epoch 38/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8255\n",
            "Epoch 39/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8236\n",
            "Epoch 40/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8236\n",
            "Epoch 41/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8274\n",
            "Epoch 42/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8283\n",
            "Epoch 43/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8274\n",
            "Epoch 44/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8264\n",
            "Epoch 45/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8274\n",
            "Epoch 46/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8226\n",
            "Epoch 47/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8226\n",
            "Epoch 48/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8255\n",
            "Epoch 49/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8274\n",
            "Epoch 50/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8283\n",
            "Epoch 51/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8274\n",
            "Epoch 52/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8245\n",
            "Epoch 53/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8264\n",
            "Epoch 54/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8255\n",
            "Epoch 55/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8283\n",
            "Epoch 56/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8255\n",
            "Epoch 57/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8255\n",
            "Epoch 58/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8264\n",
            "Epoch 59/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8264\n",
            "Epoch 60/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8245\n",
            "Epoch 61/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8226\n",
            "Epoch 62/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8255\n",
            "Epoch 63/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8264\n",
            "Epoch 64/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8245\n",
            "Epoch 65/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8292\n",
            "Epoch 66/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8274\n",
            "Epoch 67/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8283\n",
            "Epoch 68/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8264\n",
            "Epoch 69/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.3988 - accuracy: 0.8292\n",
            "Epoch 70/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8283\n",
            "Epoch 71/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.8264\n",
            "Epoch 72/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8274\n",
            "Epoch 73/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8302\n",
            "Epoch 74/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8311\n",
            "Epoch 75/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8302\n",
            "Epoch 76/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8283\n",
            "Epoch 77/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8311\n",
            "Epoch 78/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8283\n",
            "Epoch 79/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8274\n",
            "Epoch 80/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8311\n",
            "Epoch 81/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8274\n",
            "Epoch 82/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8302\n",
            "Epoch 83/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8321\n",
            "Epoch 84/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8321\n",
            "Epoch 85/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8321\n",
            "Epoch 86/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8302\n",
            "Epoch 87/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8292\n",
            "Epoch 88/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8283\n",
            "Epoch 89/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.3927 - accuracy: 0.8302\n",
            "Epoch 90/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8311\n",
            "Epoch 91/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8321\n",
            "Epoch 92/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.8340\n",
            "Epoch 93/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8302\n",
            "Epoch 94/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8340\n",
            "Epoch 95/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8311\n",
            "Epoch 96/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8321\n",
            "Epoch 97/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8311\n",
            "Epoch 98/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8321\n",
            "Epoch 99/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8302\n",
            "Epoch 100/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8311\n",
            "5/5 [==============================] - 0s 6ms/step\n"
          ]
        }
      ],
      "source": [
        "classifier = KerasClassifier(build_fn = build_classifier,\n",
        "                             optimizer=best_parameters['optimizer'],\n",
        "                             batch_size=best_parameters['batch_size'],\n",
        "                             epochs=best_parameters['epochs'])\n",
        "\n",
        "classifier.fit(X_train,y_train)\n",
        "preds = classifier.predict(X_test)"
      ],
      "id": "7rJpLP249lb1"
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "qfoprFu-g3O1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc5c76fc-4599-4e47-828a-8defa2d0a181"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(131,), (131,)]"
            ]
          },
          "execution_count": 244,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction = preds.tolist()\n",
        "se = pd.Series(prediction)\n",
        "y_test_pred = se.str.get(0)\n",
        "[y_test.shape, y_test_pred.shape]"
      ],
      "id": "qfoprFu-g3O1"
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "P96BJKUMiT-3"
      },
      "outputs": [],
      "source": [
        "y_test_pred = choose_class(y_test_pred)"
      ],
      "id": "P96BJKUMiT-3"
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "id": "zzV3Q44lxZxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1be9ca1-2c89-412a-8836-c0ac2c101236"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy на тестовой выборке 0.7938931297709924\n",
            " \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85        84\n",
            "           1       0.79      0.57      0.67        47\n",
            "\n",
            "    accuracy                           0.79       131\n",
            "   macro avg       0.79      0.75      0.76       131\n",
            "weighted avg       0.79      0.79      0.78       131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy на тестовой выборке', accuracy_score(y_test, y_test_pred, normalize=True))\n",
        "print(' ')\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "id": "zzV3Q44lxZxL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод**: Предсказания на тестовых данных чуть хуже. Но ничего. Живем-живем"
      ],
      "metadata": {
        "id": "ysJWVmdM_qS9"
      },
      "id": "ysJWVmdM_qS9"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eVQBe6bh_0Rz"
      },
      "id": "eVQBe6bh_0Rz",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "f9f0f099-9236-41e6-a985-69758dbae2dd",
        "56moUUS_R5p1",
        "iaFq2thOCrzs",
        "SnBHRHI7EZ6e",
        "Jz6RSv6NFwyn",
        "LwgJhAXmrgfQ",
        "hkeZ7y6meks5",
        "4qxpaQ9b_-bj",
        "BnIFRizSW4BB",
        "b6Kwvg8lUYaT",
        "FnnKapRpWeyk"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}